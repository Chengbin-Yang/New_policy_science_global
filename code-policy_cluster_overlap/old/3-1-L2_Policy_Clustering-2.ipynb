{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304585c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Cell 1: 聚类分析 (Clustering)\n",
    "# ==========================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Dict\n",
    "import warnings\n",
    "\n",
    "# 忽略警告\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. 核心聚类算法\n",
    "def auto_select_k_and_cluster(X_data: np.ndarray, max_k: int = 10) -> np.ndarray:\n",
    "    \"\"\"自动选择最佳K值并返回聚类标签 (基于肘部法则-最大降幅)\"\"\"\n",
    "    n_samples = len(X_data)\n",
    "    if n_samples < 3:\n",
    "        return np.zeros(n_samples, dtype=int)\n",
    "\n",
    "    Z = linkage(X_data, method='ward')\n",
    "    \n",
    "    wcss_list = []\n",
    "    valid_ks = list(range(2, min(max_k, n_samples) + 1))\n",
    "    \n",
    "    for k in valid_ks:\n",
    "        labels = fcluster(Z, k, criterion='maxclust')\n",
    "        wcss = 0\n",
    "        for i in range(1, k + 1):\n",
    "            cluster_points = X_data[labels == i]\n",
    "            if len(cluster_points) > 0:\n",
    "                center = cluster_points.mean(axis=0)\n",
    "                wcss += np.sum((cluster_points - center) ** 2)\n",
    "        wcss_list.append(wcss)\n",
    "    \n",
    "    if len(wcss_list) < 2:\n",
    "        best_k = valid_ks[0]\n",
    "    else:\n",
    "        deltas = [wcss_list[i] - wcss_list[i+1] for i in range(len(wcss_list)-1)]\n",
    "        best_idx = np.argmax(deltas)\n",
    "        best_k = valid_ks[best_idx + 1]\n",
    "    \n",
    "    return fcluster(Z, best_k, criterion='maxclust') - 1\n",
    "\n",
    "def run_clustering_single_metric(df_source: pd.DataFrame, l2_name: str, need_scale: bool = False) -> pd.Series:\n",
    "    \"\"\"处理单条L2政策\"\"\"\n",
    "    # === 修改点1：严格限制年份 2005-2023 ===\n",
    "    df = df_source[(df_source['TIME_PERIOD'] >= 2005) & (df_source['TIME_PERIOD'] <= 2023)]\n",
    "    \n",
    "    X = df.set_index(['REF_AREA', 'TIME_PERIOD'])[l2_name].unstack().fillna(0)\n",
    "    \n",
    "    if X.empty:\n",
    "        return pd.Series(dtype=int)\n",
    "\n",
    "    if need_scale:\n",
    "        scaler = MinMaxScaler()\n",
    "        if X.values.max() == X.values.min():\n",
    "            X_vals = X.values\n",
    "        else:\n",
    "            X_vals = scaler.fit_transform(X)\n",
    "    else:\n",
    "        X_vals = X.values\n",
    "        \n",
    "    labels = auto_select_k_and_cluster(X_vals)\n",
    "    return pd.Series(labels, index=X.index, name='ClusterID')\n",
    "\n",
    "# 2. 数据 IO\n",
    "def load_data(data_dir: Path):\n",
    "    df_b = pd.read_parquet(data_dir / \"2-1-country_breadth.parquet\")\n",
    "    df_i = pd.read_parquet(data_dir / \"2-1-country_intensity.parquet\")\n",
    "    l2_list = [c for c in df_b.columns if c not in {'REF_AREA', 'TIME_PERIOD'}]\n",
    "    return df_b, df_i, l2_list\n",
    "\n",
    "def save_clustered_data(cluster_results: Dict[str, pd.Series], df_source: pd.DataFrame, output_path: Path):\n",
    "    records = []\n",
    "    # 同样确保源数据也是 2005-2023，以便保存时一致\n",
    "    df_source_filtered = df_source[(df_source['TIME_PERIOD'] >= 2005) & (df_source['TIME_PERIOD'] <= 2023)]\n",
    "    \n",
    "    for l2, clusters in cluster_results.items():\n",
    "        if clusters.empty: continue\n",
    "        \n",
    "        sub = df_source_filtered[['REF_AREA', 'TIME_PERIOD', l2]].copy()\n",
    "        sub.columns = ['国家', '年份', '占比'] # 统一列名\n",
    "        sub['聚类ID'] = sub['国家'].map(clusters)\n",
    "        sub['L2政策'] = l2\n",
    "        sub['L2政策中文名'] = l2 # 占位，确保列存在\n",
    "        \n",
    "        sub = sub.dropna(subset=['聚类ID'])\n",
    "        sub['聚类ID'] = sub['聚类ID'].astype(int)\n",
    "        records.append(sub)\n",
    "        \n",
    "    if records:\n",
    "        final_df = pd.concat(records)\n",
    "        final_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"✅ 已保存: {output_path.name}\")\n",
    "\n",
    "# 3. 执行\n",
    "base_dir = Path.cwd().parent\n",
    "data_dir = base_dir / \"data\" if (base_dir / \"data\").exists() else Path.cwd() / \"data\"\n",
    "print(f\"数据目录: {data_dir}\")\n",
    "\n",
    "df_b, df_i, l2_list = load_data(data_dir)\n",
    "\n",
    "print(\"正在执行 Breadth 聚类 (2005-2023)...\")\n",
    "b_results = {l2: run_clustering_single_metric(df_b, l2, need_scale=False) for l2 in l2_list}\n",
    "save_clustered_data(b_results, df_b, data_dir / \"3-1-L2_Policy_Clustering_Breadth.csv\")\n",
    "\n",
    "print(\"正在执行 Intensity 聚类 (2005-2023)...\")\n",
    "i_results = {l2: run_clustering_single_metric(df_i, l2, need_scale=True) for l2 in l2_list}\n",
    "save_clustered_data(i_results, df_i, data_dir / \"3-1-L2_Policy_Clustering_Intensity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43bc818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> 开始绘图: Breadth\n",
      "  -> 保存: Buildings_–_market-based_instruments_Breadth_Sorted.png\n",
      "  -> 保存: Buildings_–_non_market-based_instruments_Breadth_Sorted.png\n",
      "  -> 保存: Climate_governance_Breadth_Sorted.png\n",
      "  -> 保存: Electricity_–_market-based_instruments_Breadth_Sorted.png\n",
      "  -> 保存: Electricity_–_non_market-based_instruments_Breadth_Sorted.png\n",
      "  -> 保存: Fossil_fuel_production_policies_Breadth_Sorted.png\n",
      "  -> 保存: GHG_emissions_data_and_reporting_Breadth_Sorted.png\n",
      "  -> 保存: GHG_emissions_targets_Breadth_Sorted.png\n",
      "  -> 保存: Industry_–_market-based_instruments_Breadth_Sorted.png\n",
      "  -> 保存: Industry_–_non_market-based_instruments_Breadth_Sorted.png\n",
      "  -> 保存: International_climate_co-operation_Breadth_Sorted.png\n",
      "  -> 保存: International_public_finance_Breadth_Sorted.png\n",
      "  -> 保存: Public_Research,_Development_and_Demonstration_Breadth_Sorted.png\n",
      "  -> 保存: Transport_–_market-based_instruments_Breadth_Sorted.png\n",
      "  -> 保存: Transport_–_non_market-based_instruments_Breadth_Sorted.png\n",
      "✅ 完成。输出: f:\\Desktop\\科研项目\\1.负责科研项目\\Climate Policy\\CAMPF_Supplementary\\data\\3-1-(3-2)Sorted_L2_Policy_Clustering_pic\\Plots_Breadth\n",
      "\n",
      ">>> 开始绘图: Intensity\n",
      "  -> 保存: Buildings_–_market-based_instruments_Intensity_Sorted.png\n",
      "  -> 保存: Buildings_–_non_market-based_instruments_Intensity_Sorted.png\n",
      "  -> 保存: Climate_governance_Intensity_Sorted.png\n",
      "  -> 保存: Electricity_–_market-based_instruments_Intensity_Sorted.png\n",
      "  -> 保存: Electricity_–_non_market-based_instruments_Intensity_Sorted.png\n",
      "  -> 保存: Fossil_fuel_production_policies_Intensity_Sorted.png\n",
      "  -> 保存: GHG_emissions_data_and_reporting_Intensity_Sorted.png\n",
      "  -> 保存: GHG_emissions_targets_Intensity_Sorted.png\n",
      "  -> 保存: Industry_–_market-based_instruments_Intensity_Sorted.png\n",
      "  -> 保存: Industry_–_non_market-based_instruments_Intensity_Sorted.png\n",
      "  -> 保存: International_climate_co-operation_Intensity_Sorted.png\n",
      "  -> 保存: International_public_finance_Intensity_Sorted.png\n",
      "  -> 保存: Public_Research,_Development_and_Demonstration_Intensity_Sorted.png\n",
      "  -> 保存: Transport_–_market-based_instruments_Intensity_Sorted.png\n",
      "  -> 保存: Transport_–_non_market-based_instruments_Intensity_Sorted.png\n",
      "✅ 完成。输出: f:\\Desktop\\科研项目\\1.负责科研项目\\Climate Policy\\CAMPF_Supplementary\\data\\3-1-(3-2)Sorted_L2_Policy_Clustering_pic\\Plots_Intensity\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 直接画图并排序\n",
    "# ==========================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.ticker import MaxNLocator, MultipleLocator\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Any\n",
    "import matplotlib as mpl\n",
    "\n",
    "# === 配置与样式 ===\n",
    "def setup_mpl_single2() -> None:\n",
    "    mpl.rc('font', size=25)\n",
    "    mpl.rcParams.update({\n",
    "        'legend.fontsize': 'small',\n",
    "        'xtick.labelsize': 'small', 'ytick.labelsize': 'small',\n",
    "        'lines.linewidth': 2, 'axes.linewidth': 2,\n",
    "        'xtick.major.pad': '12', 'ytick.major.pad': '12',\n",
    "        'xtick.direction': 'in', 'ytick.direction': 'in',\n",
    "        'xtick.top': False, 'ytick.right': False,\n",
    "        'mathtext.default': 'regular', 'axes.titlesize': 'small'\n",
    "    })\n",
    "\n",
    "setup_mpl_single2()\n",
    "\n",
    "NATURE_COLORS = [\n",
    "    '#E64B35', \"#6917C2\", '#00A087', '#3C5488', '#F39B7F', \n",
    "    '#8491B4', '#91D1C2', '#DC0000', '#7E6148', '#B09C85', \n",
    "    '#E18727', '#20854E', '#0072B5', '#BC3C29', '#6F99AD'\n",
    "]\n",
    "\n",
    "def lighten_color(color: Any, amount: float = 0.7) -> Tuple[float, float, float]:\n",
    "    c = mcolors.to_rgb(color)\n",
    "    return tuple([c[i] + (1 - c[i]) * amount for i in range(3)])\n",
    "\n",
    "# === 排序与辅助逻辑 ===\n",
    "def sort_clusters(sort_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"根据 Starting > Ending > Trend 规则对元数据进行排序\"\"\"\n",
    "    orders = {\n",
    "        'Starting': {'Low': 0, 'Medium': 1, 'High': 2},\n",
    "        'Ending': {'Low': 0, 'Medium': 1, 'High': 2},\n",
    "        'Trend': {'Rise': 0, 'Stable': 1, 'Fluctuate': 2, 'Decline': 3}\n",
    "    }\n",
    "    \n",
    "    df = sort_df.copy()\n",
    "    df['sort_key'] = df.apply(lambda r: (\n",
    "        orders['Starting'].get(r['Starting'], 99),\n",
    "        orders['Ending'].get(r['Ending'], 99),\n",
    "        orders['Trend'].get(r['Trend'], 99),\n",
    "        r.get('MeanStart', 0)\n",
    "    ), axis=1)\n",
    "    \n",
    "    return df.sort_values('sort_key')\n",
    "\n",
    "def get_plot_title(sort_df: pd.DataFrame, l2_name: str, cid: int) -> str:\n",
    "    \"\"\"构建标题字符串\"\"\"\n",
    "    row = sort_df[(sort_df['L2政策中文名'] == l2_name) & (sort_df['聚类ID'] == cid)]\n",
    "    if row.empty: return f\"Cluster {cid}\"\n",
    "    r = row.iloc[0]\n",
    "    return f\"{r['Starting']}+{r['Trend']}+{r['Ending'].replace(' Share', '')}\"\n",
    "\n",
    "# === 核心绘图逻辑 ===\n",
    "def plot_policy_trends(l2_name: str, l2_data: pd.DataFrame, sort_df: pd.DataFrame, \n",
    "                       metric_label: str, output_dir: Path) -> None:\n",
    "    # 1. 严格筛选年份\n",
    "    df_plot = l2_data[(l2_data['年份'] >= 2005) & (l2_data['年份'] <= 2023)]\n",
    "    if df_plot.empty: return\n",
    "\n",
    "    # 2. 获取排序后的 Cluster ID\n",
    "    l2_sort_info = sort_df[sort_df['L2政策中文名'] == l2_name]\n",
    "    if l2_sort_info.empty: return\n",
    "    sorted_cids = l2_sort_info.sort_values('sort_key')['聚类ID'].unique()\n",
    "\n",
    "    # 3. 准备绘图数据\n",
    "    years = sorted(df_plot['年份'].unique())\n",
    "    matrix = df_plot.pivot(index='年份', columns='国家', values='占比').reindex(years)\n",
    "    overall_mean = matrix.mean(axis=1)\n",
    "    y_max = matrix.max().max() * 1.15\n",
    "\n",
    "    # 4. 布局设置\n",
    "    n_clusters = len(sorted_cids)\n",
    "    n_cols, n_rows = 3, (n_clusters + 2) // 3\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 3.5 * n_rows), squeeze=False)\n",
    "\n",
    "    for idx, cid in enumerate(sorted_cids):\n",
    "        ax = axes[idx // n_cols, idx % n_cols]\n",
    "        countries = [c for c in l2_sort_info[l2_sort_info['聚类ID'] == cid]['国家'].values if c in matrix.columns]\n",
    "        if not countries: continue\n",
    "\n",
    "        # 样式参数\n",
    "        color = NATURE_COLORS[idx % len(NATURE_COLORS)]\n",
    "        fill_color = lighten_color(color, 0.7)\n",
    "        sub_matrix = matrix[countries]\n",
    "        c_mean = sub_matrix.mean(axis=1)\n",
    "\n",
    "        # 绘图\n",
    "        ax.plot(sub_matrix.index, sub_matrix.values, color=color, alpha=0.25, lw=1.2, zorder=1)\n",
    "        ax.plot(c_mean.index, c_mean, marker='o', color=color, lw=2.5, ms=7,\n",
    "                mfc=fill_color, mec=color, mew=1.8, label='Cluster Average',\n",
    "                markevery=max(1, len(years)//10), zorder=10)\n",
    "        ax.plot(overall_mean.index, overall_mean, color='#000000', ls='--', lw=2.5,\n",
    "                label='Overall Average', alpha=0.85, zorder=9, dashes=(3, 2))\n",
    "\n",
    "        # 文本与轴设置\n",
    "        title = get_plot_title(l2_sort_info, l2_name, cid)\n",
    "        ax.set_title(f\"{title}\\n({len(countries)} countries)\", pad=15, ha='center')\n",
    "        \n",
    "        # === 修改点：Y轴向下延伸 4% ===\n",
    "        y_neg_padding = y_max * 0.04\n",
    "        ax.set_ylim(bottom=-y_neg_padding, top=y_max)\n",
    "        \n",
    "        ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(nbins=6))\n",
    "        ax.tick_params(axis='x', rotation=90, labelsize=15, pad=5.5)\n",
    "        ax.tick_params(axis='y')\n",
    "        \n",
    "        if idx % n_cols == 0: ax.set_ylabel(metric_label)\n",
    "        else: ax.set_ylabel('')\n",
    "            \n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        # 图例 (所有子图均显示)\n",
    "        ax.legend(loc='best', frameon=False, fontsize=12, handlelength=2.0, markerscale=0.8)\n",
    "\n",
    "    # 隐藏空子图\n",
    "    for j in range(n_clusters, n_rows * n_cols):\n",
    "        axes[j // n_cols, j % n_cols].axis('off')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.25, top=0.85, bottom=0.15, hspace=0.45)\n",
    "    \n",
    "    safe_name = l2_name.replace(\"/\", \"_\").replace(\" \", \"_\").replace(\":\", \"\")\n",
    "    out_path = output_dir / f\"{safe_name}_{metric_label}_Sorted.png\"\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()\n",
    "    print(f\"  -> 保存: {out_path.name}\")\n",
    "\n",
    "# === 执行流程 ===\n",
    "def process_file_plotting(file_name: str, metric_label: str) -> None:\n",
    "    base_dir = Path.cwd().parent\n",
    "    data_dir = base_dir / \"data\" if (base_dir / \"data\").exists() else Path.cwd() / \"data\"\n",
    "    feature_file = data_dir / \"3-2-Automated_Recognition_Mode.csv\"\n",
    "    input_file = data_dir / file_name\n",
    "\n",
    "    if not input_file.exists() or not feature_file.exists():\n",
    "        print(f\"❌ 缺少必要文件: {input_file.name} 或特征文件\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n>>> 开始绘图: {metric_label}\")\n",
    "    df_data = pd.read_csv(input_file, encoding='utf-8-sig')\n",
    "    df_meta = pd.read_csv(feature_file, encoding='utf-8-sig')\n",
    "    \n",
    "    # 筛选对应类型的元数据并排序\n",
    "    df_meta = sort_clusters(df_meta[df_meta['Type'] == metric_label])\n",
    "    \n",
    "    out_dir = data_dir / \"3-1-(3-2)Sorted_L2_Policy_Clustering_pic\" / f\"Plots_{metric_label}\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for l2 in df_data['L2政策中文名'].dropna().unique():\n",
    "        plot_policy_trends(l2, df_data[df_data['L2政策中文名'] == l2], df_meta, metric_label, out_dir)\n",
    "    print(f\"✅ 完成。输出: {out_dir}\")\n",
    "\n",
    "# 运行\n",
    "process_file_plotting(\"3-1-L2_Policy_Clustering_Breadth.csv\", \"Breadth\")\n",
    "process_file_plotting(\"3-1-L2_Policy_Clustering_Intensity.csv\", \"Intensity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99905b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate_policy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
