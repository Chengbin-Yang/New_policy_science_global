{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a68e2efb",
   "metadata": {},
   "source": [
    "### 重叠聚类图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b16e03",
   "metadata": {},
   "source": [
    "#### 文件保存-后续网络分析需要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f637dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# 路径配置\n",
    "current_dir = Path.cwd()\n",
    "data_dir = current_dir if (current_dir / \"3-1-L2_Policy_Clustering_Breadth.csv\").exists() else current_dir.parent / \"data\"\n",
    "\n",
    "def compute_overlap_matrix(input_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    计算国家间在相同政策下聚类ID一致的重叠数量矩阵。\n",
    "\n",
    "    Args:\n",
    "        input_path (Path): 输入CSV文件路径。\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 索引和列均为国家名的对称矩阵（共现次数）。\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_path, encoding='utf-8-sig')\n",
    "\n",
    "    # 统一列名\n",
    "    if 'L2政策' not in df.columns and 'L2政策中文名' in df.columns:\n",
    "        df.rename(columns={'L2政策中文名': 'L2政策'}, inplace=True)\n",
    "\n",
    "    # 提取核心字段 (政策, 国家, 聚类ID)\n",
    "    data = df[['L2政策', '国家', '聚类ID']].drop_duplicates()\n",
    "    data.columns = ['P', 'C', 'G']  # 简化列名引用\n",
    "\n",
    "    policies = sorted(data['P'].unique())\n",
    "    countries = sorted(data['C'].unique())\n",
    "    n = len(countries)\n",
    "\n",
    "    # 构建查询表: {政策: {国家: 聚类ID}}\n",
    "    policy_map = {\n",
    "        p: dict(zip(\n",
    "            data[data['P'] == p]['C'],\n",
    "            data[data['P'] == p]['G']\n",
    "        )) for p in policies\n",
    "    }\n",
    "\n",
    "    # 计算矩阵\n",
    "    matrix = np.zeros((n, n), dtype=int)\n",
    "    for i, c1 in enumerate(countries):\n",
    "        for j in range(i, n):\n",
    "            c2 = countries[j]\n",
    "            # 统计两者拥有相同聚类ID的政策数量\n",
    "            count = sum(\n",
    "                1 for p in policies\n",
    "                if c1 in policy_map[p] and c2 in policy_map[p]\n",
    "                and policy_map[p][c1] == policy_map[p][c2]\n",
    "            )\n",
    "            matrix[i, j] = matrix[j, i] = count\n",
    "\n",
    "    return pd.DataFrame(matrix, index=countries, columns=countries)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tasks = [\n",
    "        (\"3-1-L2_Policy_Clustering_Breadth.csv\", \"_Breadth\"),\n",
    "        (\"3-1-L2_Policy_Clustering_Intensity.csv\", \"_Intensity\")\n",
    "    ]\n",
    "\n",
    "    for filename, suffix in tasks:\n",
    "        file_path = data_dir / filename\n",
    "        if file_path.exists():\n",
    "            # 计算并保存\n",
    "            matrix_df = compute_overlap_matrix(file_path)\n",
    "            output_path = data_dir / f\"4-1-overlapping_cluster_heatmap{suffix}.csv\"\n",
    "            matrix_df.to_csv(output_path, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469add5",
   "metadata": {},
   "source": [
    "#### 分部门（生成overlap文件）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99787f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存: Y_All.csv\n",
      "已保存: Y_Commitment-based.csv\n",
      "已保存: Y_Incentive-based.csv\n",
      "已保存: Y_Regulatory.csv\n",
      "已保存: Y_Research and Development (R&D).csv\n",
      "已保存: Y_All.csv\n",
      "已保存: Y_Commitment-based.csv\n",
      "已保存: Y_Incentive-based.csv\n",
      "已保存: Y_Regulatory.csv\n",
      "已保存: Y_Research and Development (R&D).csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. 简化的环境配置\n",
    "# 优先查找 ../data (假设脚本在 code 目录)，否则用当前目录\n",
    "data_dir = Path.cwd().parent / \"data\"\n",
    "if not (data_dir / \"config_mappings.json\").exists():\n",
    "    data_dir = Path.cwd()\n",
    "\n",
    "# 2. 加载 L2->L1 映射\n",
    "with open(data_dir / \"config_mappings.json\", 'r', encoding='utf-8') as f:\n",
    "    # 提取 json 中的 {\"L2\": ..., \"L1\": ...} 结构\n",
    "    l2_to_l1_map = {item['L2']: item['L1'] for item in json.load(f).get('level_mapping', {}).values()}\n",
    "\n",
    "def compute_and_save(df_input, output_path):\n",
    "    \"\"\"核心计算函数：计算共现矩阵并保存\"\"\"\n",
    "    # 提取必要列去重\n",
    "    data = df_input[['L2政策', '国家', '聚类ID']].drop_duplicates()\n",
    "    \n",
    "    # 准备国家索引，确保矩阵行列顺序固定\n",
    "    countries = sorted(data['国家'].unique())\n",
    "    c_idx = {c: i for i, c in enumerate(countries)}\n",
    "    n = len(countries)\n",
    "    matrix = np.zeros((n, n), dtype=int)\n",
    "    \n",
    "    # 按政策遍历，计算每项政策下的贡献\n",
    "    for policy, group in data.groupby('L2政策'):\n",
    "        # 将该政策下的国家按聚类ID分组: {ID: [Country1, Country2...]}\n",
    "        clusters = {}\n",
    "        for _, row in group.iterrows():\n",
    "            clusters.setdefault(row['聚类ID'], []).append(row['国家'])\n",
    "            \n",
    "        # 同一个聚类ID下的所有国家，两两重叠度+1\n",
    "        for members in clusters.values():\n",
    "            idxs = [c_idx[m] for m in members]\n",
    "            for i in range(len(idxs)):\n",
    "                for j in range(i, len(idxs)):\n",
    "                    r, c = idxs[i], idxs[j]\n",
    "                    matrix[r, c] += 1\n",
    "                    if r != c: matrix[c, r] += 1\n",
    "\n",
    "    # 保存\n",
    "    pd.DataFrame(matrix, index=countries, columns=countries).to_csv(output_path, encoding='utf-8-sig')\n",
    "    print(f\"已保存: {output_path.name}\")\n",
    "\n",
    "# 3. 主流程\n",
    "tasks = [(\"3-1-L2_Policy_Clustering_Breadth.csv\", \"Breadth\"), \n",
    "         (\"3-1-L2_Policy_Clustering_Intensity.csv\", \"Intensity\")]\n",
    "\n",
    "for fname, folder_name in tasks:\n",
    "    fpath = data_dir / fname\n",
    "    if not fpath.exists(): continue\n",
    "    \n",
    "    # 读取数据\n",
    "    df = pd.read_csv(fpath, encoding='utf-8-sig')\n",
    "    if 'L2政策' not in df.columns: df.rename(columns={'L2政策中文名': 'L2政策'}, inplace=True)\n",
    "    \n",
    "    # 创建输出目录\n",
    "    out_dir = data_dir / \"4-1-overlapping_cluster_heatmap\" / folder_name\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Task A: 计算全量矩阵 (所有政策)\n",
    "    compute_and_save(df, out_dir / \"Y_All.csv\")\n",
    "    \n",
    "    # Task B: 按 L1 分组计算\n",
    "    df['L1_Category'] = df['L2政策'].map(l2_to_l1_map)\n",
    "    for l1_name, sub_df in df.groupby('L1_Category'):\n",
    "        safe_name = l1_name.replace('/', '_').replace('\\\\', '_') # 防止路径报错\n",
    "        compute_and_save(sub_df, out_dir / f\"Y_{safe_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530263c9",
   "metadata": {},
   "source": [
    "#### 相同布局分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4994382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 保存成功: 4-1-aligned_by_intensity_INTENSITY.png\n",
      "✅ 保存成功: 4-1-aligned_by_intensity_BREADTH.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from pathlib import Path\n",
    "import colorsys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==========================================\n",
    "# 1. 基础配置 (Times New Roman + 极致粗度)\n",
    "# ==========================================\n",
    "current_dir = Path.cwd()\n",
    "data_dir = current_dir if (current_dir / \"3-1-L2_Policy_Clustering_Breadth.csv\").exists() else current_dir.parent / \"data\"\n",
    "\n",
    "def get_times_black_font():\n",
    "    \"\"\"锁定新罗马并强制开启极致加粗\"\"\"\n",
    "    return FontProperties(family='Times New Roman', size=26, weight='black')\n",
    "\n",
    "T_BLACK = get_times_black_font()\n",
    "\n",
    "# 全局环境设置\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times New Roman'],\n",
    "    'font.weight': 'black',\n",
    "    'axes.labelweight': 'black',\n",
    "    'axes.titleweight': 'black',\n",
    "    'axes.unicode_minus': False,\n",
    "    'figure.dpi': 300\n",
    "})\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# 关键：Seaborn 经常会把 axisbelow 打开，导致刻度线/网格永远画在下面\n",
    "plt.rcParams['axes.axisbelow'] = False\n",
    "\n",
    "def lighten_color_slightly(hex_color: str) -> str:\n",
    "    r, g, b = plt.cm.colors.to_rgb(hex_color)\n",
    "    h, l, s = colorsys.rgb_to_hls(r, g, b)\n",
    "    return plt.cm.colors.to_hex(colorsys.hls_to_rgb(h, min(1.0, l + 0.12), s * 0.88))\n",
    "\n",
    "def get_palette(k: int) -> list:\n",
    "    colors = ['#1f77b4', '#2ca02c', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "    return (colors * (k // len(colors) + 1))[:k]\n",
    "\n",
    "# ==========================================\n",
    "# 2. 数据处理辅助函数\n",
    "# ==========================================\n",
    "def build_overlap_matrix(input_file: Path) -> (pd.DataFrame, int):\n",
    "    if not input_file.exists():\n",
    "        raise FileNotFoundError(f\"找不到文件: {input_file}\")\n",
    "\n",
    "    df = pd.read_csv(input_file, encoding='utf-8-sig')\n",
    "\n",
    "    if 'L2政策' not in df.columns and 'L2政策中文名' in df.columns:\n",
    "        df.rename(columns={'L2政策中文名': 'L2政策'}, inplace=True)\n",
    "\n",
    "    def safe_col(d, name):\n",
    "        return d[name].iloc[:, 0] if isinstance(d[name], pd.DataFrame) else d[name]\n",
    "\n",
    "    df_clean = pd.DataFrame({\n",
    "        'P': safe_col(df, 'L2政策').astype(str),\n",
    "        'C': safe_col(df, '国家').astype(str),\n",
    "        'G': safe_col(df, '聚类ID')\n",
    "    }).drop_duplicates()\n",
    "\n",
    "    policies = sorted(df_clean['P'].unique())\n",
    "    countries = sorted(df_clean['C'].unique())\n",
    "\n",
    "    res_map = {p: dict(zip(df_clean[df_clean['P'] == p]['C'],\n",
    "                           df_clean[df_clean['P'] == p]['G'])) for p in policies}\n",
    "\n",
    "    n = len(countries)\n",
    "    matrix = np.zeros((n, n), dtype=int)\n",
    "    for i, c1 in enumerate(countries):\n",
    "        for j in range(i, n):\n",
    "            c2 = countries[j]\n",
    "            common = sum(\n",
    "                1 for p in policies\n",
    "                if c1 in res_map[p] and c2 in res_map[p]\n",
    "                and (res_map[p][c1] == res_map[p][c2] if i != j else True)\n",
    "            )\n",
    "            matrix[i, j] = matrix[j, i] = common\n",
    "\n",
    "    return pd.DataFrame(matrix, index=countries, columns=countries), len(policies)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 核心绘图逻辑\n",
    "# ==========================================\n",
    "def draw_heatmap(data_df: pd.DataFrame, Z_master, row_colors, common_countries,\n",
    "                 filename: str, title: str, v_max: int):\n",
    "\n",
    "    # 画布大小调整\n",
    "    size = max(18, len(common_countries) * 0.72)\n",
    "\n",
    "    g = sns.clustermap(\n",
    "        data_df, row_linkage=Z_master, col_linkage=Z_master,\n",
    "        cmap='RdYlBu_r', row_colors=row_colors, col_colors=row_colors,\n",
    "        dendrogram_ratio=0.1, linewidths=0.5, figsize=(size, size),\n",
    "        annot=True, fmt='d', vmin=0, vmax=v_max,\n",
    "        # 内部数字极致加粗\n",
    "        annot_kws={'fontsize': 28, 'weight': 'black', 'fontproperties': T_BLACK},\n",
    "        cbar_kws={'ticks': [0, 5, 10, 15, 20]},\n",
    "        tree_kws={'linewidths': 6}\n",
    "    )\n",
    "\n",
    "    # =========================================================\n",
    "    # A. 色条位置：根据热图 bbox 动态放到右侧（解决“太往左”）\n",
    "    # =========================================================\n",
    "    hm_pos = g.ax_heatmap.get_position()\n",
    "    pad = 0.04        # 与热图的水平间距\n",
    "    cbar_w = 0.018    # 色条宽度\n",
    "    cbar_h = hm_pos.height * 0.78\n",
    "    cbar_y = hm_pos.y0 + hm_pos.height * 0.11\n",
    "\n",
    "    g.cax.set_position([hm_pos.x1 + pad, cbar_y, cbar_w, cbar_h])\n",
    "    g.cax.yaxis.set_label_position('right')  # 标题放右侧更舒服\n",
    "\n",
    "    # =========================================================\n",
    "    # B. 关键修复：刻度线/双向指针压在色块之上（非 zorder 玄学）\n",
    "    # =========================================================\n",
    "    # 1) 禁止 axisbelow（否则 ticks 永远在下面）\n",
    "    g.cax.set_axisbelow(False)\n",
    "\n",
    "    # 2) 把色条色块的 collection 压到更底层\n",
    "    for coll in g.cax.collections:\n",
    "        coll.set_zorder(0)\n",
    "\n",
    "    # 3) 双侧刻度线\n",
    "    g.cax.yaxis.set_ticks_position('both')\n",
    "\n",
    "    # 4) 刻度线“别太长太粗”，但要能盖住色块边缘\n",
    "    g.cax.tick_params(\n",
    "        axis='y',\n",
    "        direction='in',   # 内向指针\n",
    "        length=12,\n",
    "        width=3,\n",
    "        colors='black',\n",
    "        left=True,\n",
    "        right=True,\n",
    "        pad=6\n",
    "    )\n",
    "\n",
    "    # 5) 让 tickline 真正到最上层，并取消裁剪（避免被色条区域裁掉）\n",
    "    for t in g.cax.yaxis.get_major_ticks():\n",
    "        for ln in (t.tick1line, t.tick2line):\n",
    "            ln.set_zorder(10)\n",
    "            ln.set_clip_on(False)\n",
    "\n",
    "    # tick label 也提一下\n",
    "    for lab in g.cax.get_yticklabels():\n",
    "        lab.set_zorder(11)\n",
    "\n",
    "    # 色条标题和刻度文字\n",
    "    g.cax.set_ylabel(f'Overlap Count ({title})', fontproperties=T_BLACK,\n",
    "                     fontsize=32, weight='black', labelpad=20)\n",
    "    plt.setp(g.cax.get_yticklabels(), fontproperties=T_BLACK, fontsize=28, weight='black')\n",
    "\n",
    "    # =========================================================\n",
    "    # C. 坐标轴标签 (X/Y轴)\n",
    "    # =========================================================\n",
    "    for lab in g.ax_heatmap.get_xticklabels():\n",
    "        lab.set_fontproperties(T_BLACK)\n",
    "        lab.set_rotation(45)\n",
    "        lab.set_ha('right')\n",
    "\n",
    "    for lab in g.ax_heatmap.get_yticklabels():\n",
    "        lab.set_fontproperties(T_BLACK)\n",
    "        lab.set_rotation(0)\n",
    "\n",
    "    # =========================================================\n",
    "    # D. 热图边框极致加粗\n",
    "    # =========================================================\n",
    "    ax = g.ax_heatmap\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_linewidth(4)\n",
    "        spine.set_edgecolor('black')\n",
    "\n",
    "    # 保存\n",
    "    plt.savefig(data_dir / filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"✅ 保存成功: {filename}\")\n",
    "    plt.close('all')\n",
    "\n",
    "def plot_intensity_based_comparison(breadth_file: Path, intensity_file: Path) -> None:\n",
    "    df_b, max_b = build_overlap_matrix(breadth_file)\n",
    "    df_i, max_i = build_overlap_matrix(intensity_file)\n",
    "\n",
    "    common_countries = sorted(list(set(df_b.index) & set(df_i.index)))\n",
    "    df_b, df_i = df_b.loc[common_countries, common_countries], df_i.loc[common_countries, common_countries]\n",
    "\n",
    "    # 层次聚类排序\n",
    "    Z_master = linkage(df_i.values, method='ward')\n",
    "    weights = df_i.sum(axis=1).values\n",
    "    w_map = {i: v for i, v in enumerate(weights)}\n",
    "    for i, (c1, c2, d, cnt) in enumerate(Z_master):\n",
    "        c1, c2 = int(c1), int(c2)\n",
    "        if w_map[c1] < w_map[c2]:\n",
    "            Z_master[i, 0], Z_master[i, 1] = c2, c1\n",
    "        w_map[len(weights) + i] = w_map[c1] + w_map[c2]\n",
    "\n",
    "    k = min(11, len(common_countries))\n",
    "    labels = fcluster(Z_master, t=k, criterion='maxclust') - 1\n",
    "    row_colors = pd.Series([lighten_color_slightly(get_palette(k)[l]) for l in labels], index=common_countries)\n",
    "\n",
    "    # 绘制两张图\n",
    "    draw_heatmap(df_i, Z_master, row_colors, common_countries,\n",
    "                 \"4-1-aligned_by_intensity_INTENSITY.png\", \"Intensity\", max_i)\n",
    "    draw_heatmap(df_b, Z_master, row_colors, common_countries,\n",
    "                 \"4-1-aligned_by_intensity_BREADTH.png\", \"Breadth\", max_b)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    plot_intensity_based_comparison(\n",
    "        data_dir / \"3-1-L2_Policy_Clustering_Breadth.csv\",\n",
    "        data_dir / \"3-1-L2_Policy_Clustering_Intensity.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd0ad5",
   "metadata": {},
   "source": [
    "#### 重心左上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f78c045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- 处理 Intensity ---------\n",
      "   [重心检测] 左侧权重: 8066 | 右侧权重: 7731\n",
      "   >>> ✅ 重心已在左侧，无需调整。\n",
      "✅ 保存成功: 4-1-independent_ForceLeft_INTENSITY.png\n",
      "\n",
      "--------- 处理 Breadth ---------\n",
      "   [重心检测] 左侧权重: 6977 | 右侧权重: 8088\n",
      "   >>> ⚠️ 检测到重心在右侧，正在强制执行全树镜像翻转 (Mirror Flip)...\n",
      "   >>> 翻转完成，大数值已移至左侧。\n",
      "✅ 保存成功: 4-1-independent_ForceLeft_BREADTH.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, leaves_list\n",
    "from pathlib import Path\n",
    "import colorsys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==========================================\n",
    "# 1. 基础配置\n",
    "# ==========================================\n",
    "current_dir = Path.cwd()\n",
    "data_dir = current_dir if (current_dir / \"3-1-L2_Policy_Clustering_Breadth.csv\").exists() else current_dir.parent / \"data\"\n",
    "\n",
    "def get_times_black_font():\n",
    "    return FontProperties(family='Times New Roman', size=26, weight='black')\n",
    "\n",
    "T_BLACK = get_times_black_font()\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times New Roman'],\n",
    "    'font.weight': 'black',\n",
    "    'axes.labelweight': 'black',\n",
    "    'axes.titleweight': 'black',\n",
    "    'axes.unicode_minus': False,\n",
    "    'figure.dpi': 300\n",
    "})\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.rcParams['axes.axisbelow'] = False\n",
    "\n",
    "def lighten_color_slightly(hex_color: str) -> str:\n",
    "    r, g, b = plt.cm.colors.to_rgb(hex_color)\n",
    "    h, l, s = colorsys.rgb_to_hls(r, g, b)\n",
    "    return plt.cm.colors.to_hex(colorsys.hls_to_rgb(h, min(1.0, l + 0.12), s * 0.88))\n",
    "\n",
    "def get_palette(k: int) -> list:\n",
    "    colors = ['#1f77b4', '#2ca02c', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "    return (colors * (k // len(colors) + 1))[:k]\n",
    "\n",
    "# ==========================================\n",
    "# 2. 数据处理辅助函数\n",
    "# ==========================================\n",
    "def build_overlap_matrix(input_file: Path) -> (pd.DataFrame, int):\n",
    "    if not input_file.exists():\n",
    "        raise FileNotFoundError(f\"找不到文件: {input_file}\")\n",
    "\n",
    "    df = pd.read_csv(input_file, encoding='utf-8-sig')\n",
    "\n",
    "    if 'L2政策' not in df.columns and 'L2政策中文名' in df.columns:\n",
    "        df.rename(columns={'L2政策中文名': 'L2政策'}, inplace=True)\n",
    "\n",
    "    def safe_col(d, name):\n",
    "        return d[name].iloc[:, 0] if isinstance(d[name], pd.DataFrame) else d[name]\n",
    "\n",
    "    df_clean = pd.DataFrame({\n",
    "        'P': safe_col(df, 'L2政策').astype(str),\n",
    "        'C': safe_col(df, '国家').astype(str),\n",
    "        'G': safe_col(df, '聚类ID')\n",
    "    }).drop_duplicates()\n",
    "\n",
    "    policies = sorted(df_clean['P'].unique())\n",
    "    countries = sorted(df_clean['C'].unique())\n",
    "\n",
    "    res_map = {p: dict(zip(df_clean[df_clean['P'] == p]['C'],\n",
    "                           df_clean[df_clean['P'] == p]['G'])) for p in policies}\n",
    "\n",
    "    n = len(countries)\n",
    "    matrix = np.zeros((n, n), dtype=int)\n",
    "    for i, c1 in enumerate(countries):\n",
    "        for j in range(i, n):\n",
    "            c2 = countries[j]\n",
    "            common = sum(\n",
    "                1 for p in policies\n",
    "                if c1 in res_map[p] and c2 in res_map[p]\n",
    "                and (res_map[p][c1] == res_map[p][c2] if i != j else True)\n",
    "            )\n",
    "            matrix[i, j] = matrix[j, i] = common\n",
    "\n",
    "    return pd.DataFrame(matrix, index=countries, columns=countries), len(policies)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 核心绘图逻辑\n",
    "# ==========================================\n",
    "def draw_heatmap(data_df: pd.DataFrame, Z_linkage, row_colors, common_countries,\n",
    "                 filename: str, title: str, v_max: int):\n",
    "\n",
    "    size = max(18, len(common_countries) * 0.72)\n",
    "\n",
    "    g = sns.clustermap(\n",
    "        data_df, \n",
    "        row_linkage=Z_linkage, \n",
    "        col_linkage=Z_linkage, \n",
    "        cmap='RdYlBu_r', \n",
    "        row_colors=row_colors, \n",
    "        col_colors=row_colors,\n",
    "        dendrogram_ratio=0.1, linewidths=0.5, figsize=(size, size),\n",
    "        annot=True, fmt='d', vmin=0, vmax=v_max,\n",
    "        annot_kws={'fontsize': 28, 'weight': 'black', 'fontproperties': T_BLACK},\n",
    "        cbar_kws={'ticks': [0, 5, 10, 15, 20]},\n",
    "        tree_kws={'linewidths': 6}\n",
    "    )\n",
    "\n",
    "    # 色条和轴标签调整\n",
    "    hm_pos = g.ax_heatmap.get_position()\n",
    "    pad = 0.04; cbar_w = 0.018; cbar_h = hm_pos.height * 0.78\n",
    "    cbar_y = hm_pos.y0 + hm_pos.height * 0.11\n",
    "    g.cax.set_position([hm_pos.x1 + pad, cbar_y, cbar_w, cbar_h])\n",
    "    g.cax.yaxis.set_label_position('right')\n",
    "\n",
    "    g.cax.set_axisbelow(False)\n",
    "    for coll in g.cax.collections: coll.set_zorder(0)\n",
    "    g.cax.yaxis.set_ticks_position('both')\n",
    "    g.cax.tick_params(axis='y', direction='in', length=12, width=3, colors='black', left=True, right=True, pad=6)\n",
    "\n",
    "    for t in g.cax.yaxis.get_major_ticks():\n",
    "        for ln in (t.tick1line, t.tick2line):\n",
    "            ln.set_zorder(10); ln.set_clip_on(False)\n",
    "    for lab in g.cax.get_yticklabels(): lab.set_zorder(11)\n",
    "\n",
    "    g.cax.set_ylabel(f'Overlap Count ({title})', fontproperties=T_BLACK, fontsize=32, weight='black', labelpad=20)\n",
    "    plt.setp(g.cax.get_yticklabels(), fontproperties=T_BLACK, fontsize=28, weight='black')\n",
    "\n",
    "    for lab in g.ax_heatmap.get_xticklabels():\n",
    "        lab.set_fontproperties(T_BLACK); lab.set_rotation(45); lab.set_ha('right')\n",
    "    for lab in g.ax_heatmap.get_yticklabels():\n",
    "        lab.set_fontproperties(T_BLACK); lab.set_rotation(0)\n",
    "\n",
    "    ax = g.ax_heatmap\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(True); spine.set_linewidth(4); spine.set_edgecolor('black')\n",
    "\n",
    "    plt.savefig(data_dir / filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"✅ 保存成功: {filename}\")\n",
    "    plt.close('all')\n",
    "\n",
    "# ==========================================\n",
    "# 4. 关键：强制左侧排序 (Left-Heavy Sort)\n",
    "# ==========================================\n",
    "def compute_left_heavy_clustering(df: pd.DataFrame, k: int):\n",
    "    \"\"\"\n",
    "    独立计算聚类，并进行物理检查：\n",
    "    如果聚类结果显示重心在右侧（大数值国家在后面），则强制镜像翻转，确保大数值在左侧。\n",
    "    \"\"\"\n",
    "    # 1. 计算基础聚类\n",
    "    Z = linkage(df.values, method='ward')\n",
    "    weights = df.sum(axis=1).values\n",
    "    \n",
    "    # 2. 初步排序：尝试将大权重排在左子节点 (Index 0)\n",
    "    #    (虽然这步可能不够，后面的步骤4会做最终兜底)\n",
    "    w_map = {i: v for i, v in enumerate(weights)}\n",
    "    for i, (c1, c2, d, cnt) in enumerate(Z):\n",
    "        c1, c2 = int(c1), int(c2)\n",
    "        if w_map[c1] < w_map[c2]: # 如果左 < 右，则交换，让左边大\n",
    "            Z[i, 0], Z[i, 1] = c2, c1\n",
    "        w_map[len(weights) + i] = w_map[c1] + w_map[c2]\n",
    "\n",
    "    # 3. 获取叶子节点顺序 (Leaves Order)\n",
    "    current_leaves = leaves_list(Z)\n",
    "    \n",
    "    # 4. 【核心修正】重心检测与强制翻转\n",
    "    #    计算左半边和右半边的总权重\n",
    "    mid_point = len(current_leaves) // 2\n",
    "    left_mass = weights[current_leaves[:mid_point]].sum()\n",
    "    right_mass = weights[current_leaves[mid_point:]].sum()\n",
    "    \n",
    "    print(f\"   [重心检测] 左侧权重: {left_mass:.0f} | 右侧权重: {right_mass:.0f}\")\n",
    "\n",
    "    if right_mass > left_mass:\n",
    "        print(\"   >>> ⚠️ 检测到重心在右侧，正在强制执行全树镜像翻转 (Mirror Flip)...\")\n",
    "        # 翻转 Z 矩阵的所有左右子节点引用，这会直接导致 dendrogram 镜像翻转\n",
    "        Z[:, [0, 1]] = Z[:, [1, 0]]\n",
    "        print(\"   >>> 翻转完成，大数值已移至左侧。\")\n",
    "    else:\n",
    "        print(\"   >>> ✅ 重心已在左侧，无需调整。\")\n",
    "\n",
    "    # 5. 生成颜色\n",
    "    labels = fcluster(Z, t=k, criterion='maxclust') - 1\n",
    "    palette = get_palette(k)\n",
    "    row_colors = pd.Series(\n",
    "        [lighten_color_slightly(palette[l % len(palette)]) for l in labels], \n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    return Z, row_colors\n",
    "\n",
    "# ==========================================\n",
    "# 5. 主流程\n",
    "# ==========================================\n",
    "def plot_independent_comparison(breadth_file: Path, intensity_file: Path) -> None:\n",
    "    # 1. 读取数据\n",
    "    df_b, max_b = build_overlap_matrix(breadth_file)\n",
    "    df_i, max_i = build_overlap_matrix(intensity_file)\n",
    "\n",
    "    # 2. 统一国家范围\n",
    "    common_countries = sorted(list(set(df_b.index) & set(df_i.index)))\n",
    "    df_b = df_b.loc[common_countries, common_countries]\n",
    "    df_i = df_i.loc[common_countries, common_countries]\n",
    "    \n",
    "    k = min(11, len(common_countries))\n",
    "\n",
    "    # 3. 处理 Intensity\n",
    "    print(\"\\n--------- 处理 Intensity ---------\")\n",
    "    Z_i, colors_i = compute_left_heavy_clustering(df_i, k)\n",
    "    draw_heatmap(\n",
    "        df_i, Z_i, colors_i, common_countries,\n",
    "        \"4-1-independent_ForceLeft_INTENSITY.png\", \"Intensity\", max_i\n",
    "    )\n",
    "\n",
    "    # 4. 处理 Breadth\n",
    "    print(\"\\n--------- 处理 Breadth ---------\")\n",
    "    Z_b, colors_b = compute_left_heavy_clustering(df_b, k)\n",
    "    draw_heatmap(\n",
    "        df_b, Z_b, colors_b, common_countries,\n",
    "        \"4-1-independent_ForceLeft_BREADTH.png\", \"Breadth\", max_b\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    plot_independent_comparison(\n",
    "        data_dir / \"3-1-L2_Policy_Clustering_Breadth.csv\",\n",
    "        data_dir / \"3-1-L2_Policy_Clustering_Intensity.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "617fd3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 处理 Intensity (左下角模式) ---------\n",
      "   [重心检测] 左侧权重: 8066 | 右侧权重: 7731\n",
      "   >>> ✅ 重心已在左侧，无需调整。\n",
      "✅ 保存成功: 4-1-independent_ForceLeft_INTENSITY.png\n",
      "\n",
      "--------- 处理 Breadth (左下角模式) ---------\n",
      "   [重心检测] 左侧权重: 6977 | 右侧权重: 8088\n",
      "   >>> ⚠️ 检测到重心在右侧，正在强制执行全树镜像翻转 (Mirror Flip -> Left)...\n",
      "   >>> 翻转完成，大数值已移至左下角。\n",
      "✅ 保存成功: 4-1-independent_ForceLeft_BREADTH.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, leaves_list\n",
    "from pathlib import Path\n",
    "import colorsys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==========================================\n",
    "# 1. 基础配置\n",
    "# ==========================================\n",
    "current_dir = Path.cwd()\n",
    "data_dir = current_dir if (current_dir / \"3-1-L2_Policy_Clustering_Breadth.csv\").exists() else current_dir.parent / \"data\"\n",
    "\n",
    "\n",
    "def get_times_black_font() -> FontProperties:\n",
    "    return FontProperties(family='Times New Roman', size=26, weight='black')\n",
    "\n",
    "\n",
    "T_BLACK = get_times_black_font()\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times New Roman'],\n",
    "    'font.weight': 'black',\n",
    "    'axes.labelweight': 'black',\n",
    "    'axes.titleweight': 'black',\n",
    "    'axes.unicode_minus': False,\n",
    "    'figure.dpi': 300\n",
    "})\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.rcParams['axes.axisbelow'] = False\n",
    "\n",
    "\n",
    "def lighten_color_slightly(hex_color: str) -> str:\n",
    "    r, g, b = plt.cm.colors.to_rgb(hex_color)\n",
    "    h, l, s = colorsys.rgb_to_hls(r, g, b)\n",
    "    return plt.cm.colors.to_hex(\n",
    "        colorsys.hls_to_rgb(h, min(1.0, l + 0.12), s * 0.88)\n",
    "    )\n",
    "\n",
    "\n",
    "def get_palette(k: int) -> list:\n",
    "    colors = [\n",
    "        '#1f77b4', '#2ca02c', '#9467bd', '#8c564b',\n",
    "        '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'\n",
    "    ]\n",
    "    return (colors * (k // len(colors) + 1))[:k]\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 2. 数据处理\n",
    "# ==========================================\n",
    "def build_overlap_matrix(input_file: Path) -> tuple[pd.DataFrame, int]:\n",
    "    df = pd.read_csv(input_file, encoding='utf-8-sig')\n",
    "\n",
    "    if 'L2政策' not in df.columns and 'L2政策中文名' in df.columns:\n",
    "        df.rename(columns={'L2政策中文名': 'L2政策'}, inplace=True)\n",
    "\n",
    "    def safe_col(d: pd.DataFrame, name: str) -> pd.Series:\n",
    "        return d[name].iloc[:, 0] if isinstance(d[name], pd.DataFrame) else d[name]\n",
    "\n",
    "    df_clean = pd.DataFrame({\n",
    "        'P': safe_col(df, 'L2政策').astype(str),\n",
    "        'C': safe_col(df, '国家').astype(str),\n",
    "        'G': safe_col(df, '聚类ID')\n",
    "    }).drop_duplicates()\n",
    "\n",
    "    policies = sorted(df_clean['P'].unique())\n",
    "    countries = sorted(df_clean['C'].unique())\n",
    "\n",
    "    res_map = {\n",
    "        p: dict(zip(\n",
    "            df_clean[df_clean['P'] == p]['C'],\n",
    "            df_clean[df_clean['P'] == p]['G']\n",
    "        ))\n",
    "        for p in policies\n",
    "    }\n",
    "\n",
    "    n = len(countries)\n",
    "    matrix = np.zeros((n, n), dtype=int)\n",
    "\n",
    "    for i, c1 in enumerate(countries):\n",
    "        for j in range(i, n):\n",
    "            c2 = countries[j]\n",
    "            common = sum(\n",
    "                1 for p in policies\n",
    "                if c1 in res_map[p]\n",
    "                and c2 in res_map[p]\n",
    "                and (res_map[p][c1] == res_map[p][c2] if i != j else True)\n",
    "            )\n",
    "            matrix[i, j] = matrix[j, i] = common\n",
    "\n",
    "    return pd.DataFrame(matrix, index=countries, columns=countries), len(policies)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. 绘图\n",
    "# ==========================================\n",
    "def draw_heatmap(\n",
    "    data_df: pd.DataFrame,\n",
    "    Z_linkage,\n",
    "    row_colors: pd.Series,\n",
    "    filename: str,\n",
    "    title: str,\n",
    "    v_max: int\n",
    ") -> None:\n",
    "\n",
    "    size = max(18, len(data_df) * 0.72)\n",
    "\n",
    "    g = sns.clustermap(\n",
    "        data_df,\n",
    "        row_linkage=Z_linkage,\n",
    "        col_linkage=Z_linkage,\n",
    "        cmap='RdYlBu_r',\n",
    "        row_colors=row_colors,\n",
    "        col_colors=row_colors,\n",
    "        dendrogram_ratio=0.1,\n",
    "        linewidths=0.5,\n",
    "        figsize=(size, size),\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        vmin=0,\n",
    "        vmax=v_max,\n",
    "        annot_kws={'fontsize': 28, 'weight': 'black', 'fontproperties': T_BLACK},\n",
    "        tree_kws={'linewidths': 6}\n",
    "    )\n",
    "\n",
    "    save_path = data_dir / filename\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close('all')\n",
    "\n",
    "    print(f\"✅ 保存成功: {filename}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 4. 强制左下角重心聚类\n",
    "# ==========================================\n",
    "def compute_force_left_clustering(\n",
    "    df: pd.DataFrame,\n",
    "    k: int\n",
    ") -> tuple[np.ndarray, pd.Series, dict]:\n",
    "\n",
    "    Z = linkage(df.values, method='ward')\n",
    "    weights = df.sum(axis=1).values\n",
    "\n",
    "    # 局部：保证大权重在左子树\n",
    "    w_map = {i: v for i, v in enumerate(weights)}\n",
    "    for i, (c1, c2, _, _) in enumerate(Z):\n",
    "        c1, c2 = int(c1), int(c2)\n",
    "        if w_map[c1] < w_map[c2]:\n",
    "            Z[i, 0], Z[i, 1] = c2, c1\n",
    "        w_map[len(weights) + i] = w_map[c1] + w_map[c2]\n",
    "\n",
    "    leaves = leaves_list(Z)\n",
    "    mid = len(leaves) // 2\n",
    "    left_weight = int(weights[leaves[:mid]].sum())\n",
    "    right_weight = int(weights[leaves[mid:]].sum())\n",
    "\n",
    "    flipped = False\n",
    "    if right_weight > left_weight:\n",
    "        Z[:, [0, 1]] = Z[:, [1, 0]]\n",
    "        flipped = True\n",
    "\n",
    "    labels = fcluster(Z, t=k, criterion='maxclust') - 1\n",
    "    palette = get_palette(k)\n",
    "    row_colors = pd.Series(\n",
    "        [lighten_color_slightly(palette[l % len(palette)]) for l in labels],\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    info = {\n",
    "        \"left_weight\": left_weight,\n",
    "        \"right_weight\": right_weight,\n",
    "        \"flipped\": flipped\n",
    "    }\n",
    "\n",
    "    return Z, row_colors, info\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 5. 主流程\n",
    "# ==========================================\n",
    "def plot_independent_comparison(\n",
    "    breadth_file: Path,\n",
    "    intensity_file: Path\n",
    ") -> None:\n",
    "\n",
    "    df_b, max_b = build_overlap_matrix(breadth_file)\n",
    "    df_i, max_i = build_overlap_matrix(intensity_file)\n",
    "\n",
    "    common_countries = sorted(set(df_b.index) & set(df_i.index))\n",
    "    df_b = df_b.loc[common_countries, common_countries]\n",
    "    df_i = df_i.loc[common_countries, common_countries]\n",
    "\n",
    "    k = min(11, len(common_countries))\n",
    "\n",
    "    # -------- Intensity --------\n",
    "    print(\"--------- 处理 Intensity (左下角模式) ---------\")\n",
    "\n",
    "    Z_i, colors_i, info_i = compute_force_left_clustering(df_i, k)\n",
    "    print(f\"   [重心检测] 左侧权重: {info_i['left_weight']} | 右侧权重: {info_i['right_weight']}\")\n",
    "\n",
    "    if info_i[\"flipped\"]:\n",
    "        print(\"   >>> ⚠️ 检测到重心在右侧，正在强制执行全树镜像翻转 (Mirror Flip -> Left)...\")\n",
    "        print(\"   >>> 翻转完成，大数值已移至左下角。\")\n",
    "    else:\n",
    "        print(\"   >>> ✅ 重心已在左侧，无需调整。\")\n",
    "\n",
    "    draw_heatmap(\n",
    "        df_i, Z_i, colors_i,\n",
    "        \"4-1-independent_ForceLeft_INTENSITY.png\",\n",
    "        \"Intensity\",\n",
    "        max_i\n",
    "    )\n",
    "\n",
    "    # -------- Breadth --------\n",
    "    print(\"\\n--------- 处理 Breadth (左下角模式) ---------\")\n",
    "\n",
    "    Z_b, colors_b, info_b = compute_force_left_clustering(df_b, k)\n",
    "    print(f\"   [重心检测] 左侧权重: {info_b['left_weight']} | 右侧权重: {info_b['right_weight']}\")\n",
    "\n",
    "    if info_b[\"flipped\"]:\n",
    "        print(\"   >>> ⚠️ 检测到重心在右侧，正在强制执行全树镜像翻转 (Mirror Flip -> Left)...\")\n",
    "        print(\"   >>> 翻转完成，大数值已移至左下角。\")\n",
    "    else:\n",
    "        print(\"   >>> ✅ 重心已在左侧，无需调整。\")\n",
    "\n",
    "    draw_heatmap(\n",
    "        df_b, Z_b, colors_b,\n",
    "        \"4-1-independent_ForceLeft_BREADTH.png\",\n",
    "        \"Breadth\",\n",
    "        max_b\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    plot_independent_comparison(\n",
    "        data_dir / \"3-1-L2_Policy_Clustering_Breadth.csv\",\n",
    "        data_dir / \"3-1-L2_Policy_Clustering_Intensity.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ed2c02",
   "metadata": {},
   "source": [
    "#### 重心右下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5916a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------- 处理 Intensity (右下角模式) ---------\n",
      "   [重心检测] 左侧权重: 7357 | 右侧权重: 8440\n",
      "   >>> ✅ 重心已在右侧，无需调整。\n",
      "✅ 保存成功: 4-1-independent_ForceRight_INTENSITY.png\n",
      "\n",
      "--------- 处理 Breadth (右下角模式) ---------\n",
      "   [重心检测] 左侧权重: 7844 | 右侧权重: 7221\n",
      "   >>> ⚠️ 检测到重心在左侧，正在强制执行全树镜像翻转 (Mirror Flip -> Right)...\n",
      "   >>> 翻转完成，大数值已移至右下角。\n",
      "✅ 保存成功: 4-1-independent_ForceRight_BREADTH.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, leaves_list\n",
    "from pathlib import Path\n",
    "import colorsys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==========================================\n",
    "# 1. 基础配置\n",
    "# ==========================================\n",
    "current_dir = Path.cwd()\n",
    "data_dir = current_dir if (current_dir / \"3-1-L2_Policy_Clustering_Breadth.csv\").exists() else current_dir.parent / \"data\"\n",
    "\n",
    "\n",
    "def get_times_black_font() -> FontProperties:\n",
    "    return FontProperties(family='Times New Roman', size=26, weight='black')\n",
    "\n",
    "\n",
    "T_BLACK = get_times_black_font()\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times New Roman'],\n",
    "    'font.weight': 'black',\n",
    "    'axes.labelweight': 'black',\n",
    "    'axes.titleweight': 'black',\n",
    "    'axes.unicode_minus': False,\n",
    "    'figure.dpi': 300\n",
    "})\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.rcParams['axes.axisbelow'] = False\n",
    "\n",
    "\n",
    "def lighten_color_slightly(hex_color: str) -> str:\n",
    "    r, g, b = plt.cm.colors.to_rgb(hex_color)\n",
    "    h, l, s = colorsys.rgb_to_hls(r, g, b)\n",
    "    return plt.cm.colors.to_hex(\n",
    "        colorsys.hls_to_rgb(h, min(1.0, l + 0.12), s * 0.88)\n",
    "    )\n",
    "\n",
    "\n",
    "def get_palette(k: int) -> list:\n",
    "    colors = [\n",
    "        '#1f77b4', '#2ca02c', '#9467bd', '#8c564b',\n",
    "        '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'\n",
    "    ]\n",
    "    return (colors * (k // len(colors) + 1))[:k]\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 2. 数据处理\n",
    "# ==========================================\n",
    "def build_overlap_matrix(input_file: Path) -> tuple[pd.DataFrame, int]:\n",
    "    df = pd.read_csv(input_file, encoding='utf-8-sig')\n",
    "\n",
    "    if 'L2政策' not in df.columns and 'L2政策中文名' in df.columns:\n",
    "        df.rename(columns={'L2政策中文名': 'L2政策'}, inplace=True)\n",
    "\n",
    "    def safe_col(d: pd.DataFrame, name: str) -> pd.Series:\n",
    "        return d[name].iloc[:, 0] if isinstance(d[name], pd.DataFrame) else d[name]\n",
    "\n",
    "    df_clean = pd.DataFrame({\n",
    "        'P': safe_col(df, 'L2政策').astype(str),\n",
    "        'C': safe_col(df, '国家').astype(str),\n",
    "        'G': safe_col(df, '聚类ID')\n",
    "    }).drop_duplicates()\n",
    "\n",
    "    policies = sorted(df_clean['P'].unique())\n",
    "    countries = sorted(df_clean['C'].unique())\n",
    "\n",
    "    res_map = {\n",
    "        p: dict(zip(\n",
    "            df_clean[df_clean['P'] == p]['C'],\n",
    "            df_clean[df_clean['P'] == p]['G']\n",
    "        ))\n",
    "        for p in policies\n",
    "    }\n",
    "\n",
    "    n = len(countries)\n",
    "    matrix = np.zeros((n, n), dtype=int)\n",
    "\n",
    "    for i, c1 in enumerate(countries):\n",
    "        for j in range(i, n):\n",
    "            c2 = countries[j]\n",
    "            common = sum(\n",
    "                1 for p in policies\n",
    "                if c1 in res_map[p]\n",
    "                and c2 in res_map[p]\n",
    "                and (res_map[p][c1] == res_map[p][c2] if i != j else True)\n",
    "            )\n",
    "            matrix[i, j] = matrix[j, i] = common\n",
    "\n",
    "    return pd.DataFrame(matrix, index=countries, columns=countries), len(policies)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. 绘图\n",
    "# ==========================================\n",
    "def draw_heatmap(\n",
    "    data_df: pd.DataFrame,\n",
    "    Z_linkage,\n",
    "    row_colors: pd.Series,\n",
    "    filename: str,\n",
    "    title: str,\n",
    "    v_max: int\n",
    ") -> None:\n",
    "\n",
    "    size = max(18, len(data_df) * 0.72)\n",
    "\n",
    "    g = sns.clustermap(\n",
    "        data_df,\n",
    "        row_linkage=Z_linkage,\n",
    "        col_linkage=Z_linkage,\n",
    "        cmap='RdYlBu_r',\n",
    "        row_colors=row_colors,\n",
    "        col_colors=row_colors,\n",
    "        dendrogram_ratio=0.1,\n",
    "        linewidths=0.5,\n",
    "        figsize=(size, size),\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        vmin=0,\n",
    "        vmax=v_max,\n",
    "        annot_kws={'fontsize': 28, 'weight': 'black', 'fontproperties': T_BLACK},\n",
    "        cbar_kws={'ticks': [0, 5, 10, 15, 20]},\n",
    "        tree_kws={'linewidths': 6}\n",
    "    )\n",
    "\n",
    "    for lab in g.ax_heatmap.get_xticklabels():\n",
    "        lab.set_fontproperties(T_BLACK)\n",
    "        lab.set_rotation(45)\n",
    "        lab.set_ha('right')\n",
    "\n",
    "    for lab in g.ax_heatmap.get_yticklabels():\n",
    "        lab.set_fontproperties(T_BLACK)\n",
    "\n",
    "    save_path = data_dir / filename\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close('all')\n",
    "\n",
    "    print(f\"✅ 保存成功: {filename}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 4. 强制右下角重心的聚类\n",
    "# ==========================================\n",
    "def compute_force_right_clustering(\n",
    "    df: pd.DataFrame,\n",
    "    k: int\n",
    ") -> tuple[np.ndarray, pd.Series, dict]:\n",
    "\n",
    "    Z = linkage(df.values, method='ward')\n",
    "    weights = df.sum(axis=1).values\n",
    "\n",
    "    # 局部：保证高权重在右子树（不打印）\n",
    "    w_map = {i: v for i, v in enumerate(weights)}\n",
    "    for i, (c1, c2, _, _) in enumerate(Z):\n",
    "        c1, c2 = int(c1), int(c2)\n",
    "        if w_map[c1] > w_map[c2]:\n",
    "            Z[i, 0], Z[i, 1] = c2, c1\n",
    "        w_map[len(weights) + i] = w_map[c1] + w_map[c2]\n",
    "\n",
    "    # 全局重心检测\n",
    "    leaves = leaves_list(Z)\n",
    "    mid = len(leaves) // 2\n",
    "    left_weight = int(weights[leaves[:mid]].sum())\n",
    "    right_weight = int(weights[leaves[mid:]].sum())\n",
    "\n",
    "    flipped = False\n",
    "    if left_weight > right_weight:\n",
    "        Z[:, [0, 1]] = Z[:, [1, 0]]\n",
    "        flipped = True\n",
    "\n",
    "    labels = fcluster(Z, t=k, criterion='maxclust') - 1\n",
    "    palette = get_palette(k)\n",
    "    row_colors = pd.Series(\n",
    "        [lighten_color_slightly(palette[l % len(palette)]) for l in labels],\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    "    info = {\n",
    "        \"left_weight\": left_weight,\n",
    "        \"right_weight\": right_weight,\n",
    "        \"flipped\": flipped\n",
    "    }\n",
    "\n",
    "    return Z, row_colors, info\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 5. 主流程\n",
    "# ==========================================\n",
    "def plot_independent_comparison(\n",
    "    breadth_file: Path,\n",
    "    intensity_file: Path\n",
    ") -> None:\n",
    "\n",
    "    df_b, max_b = build_overlap_matrix(breadth_file)\n",
    "    df_i, max_i = build_overlap_matrix(intensity_file)\n",
    "\n",
    "    common_countries = sorted(set(df_b.index) & set(df_i.index))\n",
    "    df_b = df_b.loc[common_countries, common_countries]\n",
    "    df_i = df_i.loc[common_countries, common_countries]\n",
    "\n",
    "    k = min(11, len(common_countries))\n",
    "\n",
    "    # -------- Intensity --------\n",
    "    print(\"--------- 处理 Intensity (右下角模式) ---------\")\n",
    "\n",
    "    Z_i, colors_i, info_i = compute_force_right_clustering(df_i, k)\n",
    "    print(f\"   [重心检测] 左侧权重: {info_i['left_weight']} | 右侧权重: {info_i['right_weight']}\")\n",
    "\n",
    "    if info_i[\"flipped\"]:\n",
    "        print(\"   >>> ⚠️ 检测到重心在左侧，正在强制执行全树镜像翻转 (Mirror Flip -> Right)...\")\n",
    "        print(\"   >>> 翻转完成，大数值已移至右下角。\")\n",
    "    else:\n",
    "        print(\"   >>> ✅ 重心已在右侧，无需调整。\")\n",
    "\n",
    "    draw_heatmap(\n",
    "        df_i, Z_i, colors_i,\n",
    "        \"4-1-independent_ForceRight_INTENSITY.png\",\n",
    "        \"Intensity\",\n",
    "        max_i\n",
    "    )\n",
    "\n",
    "    # -------- Breadth --------\n",
    "    print(\"\\n--------- 处理 Breadth (右下角模式) ---------\")\n",
    "\n",
    "    Z_b, colors_b, info_b = compute_force_right_clustering(df_b, k)\n",
    "    print(f\"   [重心检测] 左侧权重: {info_b['left_weight']} | 右侧权重: {info_b['right_weight']}\")\n",
    "\n",
    "    if info_b[\"flipped\"]:\n",
    "        print(\"   >>> ⚠️ 检测到重心在左侧，正在强制执行全树镜像翻转 (Mirror Flip -> Right)...\")\n",
    "        print(\"   >>> 翻转完成，大数值已移至右下角。\")\n",
    "    else:\n",
    "        print(\"   >>> ✅ 重心已在右侧，无需调整。\")\n",
    "\n",
    "    draw_heatmap(\n",
    "        df_b, Z_b, colors_b,\n",
    "        \"4-1-independent_ForceRight_BREADTH.png\",\n",
    "        \"Breadth\",\n",
    "        max_b\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    plot_independent_comparison(\n",
    "        data_dir / \"3-1-L2_Policy_Clustering_Breadth.csv\",\n",
    "        data_dir / \"3-1-L2_Policy_Clustering_Intensity.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc34e92",
   "metadata": {},
   "source": [
    "#### 不强制K值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33be9e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- 处理 Intensity (左下角模式 / 无 k) ---------\n",
      "   [重心检测] 左侧权重: 8066 | 右侧权重: 7731\n",
      "   >>> ✅ 重心已在左侧，无需调整\n",
      "✅ 保存成功: 4-1-independent_ForceLeft_INTENSITY.png\n",
      "\n",
      "--------- 处理 Breadth (左下角模式 / 无 k) ---------\n",
      "   [重心检测] 左侧权重: 6977 | 右侧权重: 8088\n",
      "   >>> ⚠️ 重心在右侧，已执行全树镜像翻转 → 左下角\n",
      "✅ 保存成功: 4-1-independent_ForceLeft_BREADTH.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "from pathlib import Path\n",
    "import colorsys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==========================================\n",
    "# 1. 基础配置\n",
    "# ==========================================\n",
    "current_dir = Path.cwd()\n",
    "data_dir = current_dir if (current_dir / \"3-1-L2_Policy_Clustering_Breadth.csv\").exists() else current_dir.parent / \"data\"\n",
    "\n",
    "\n",
    "def get_times_black_font() -> FontProperties:\n",
    "    return FontProperties(family='Times New Roman', size=26, weight='black')\n",
    "\n",
    "\n",
    "T_BLACK = get_times_black_font()\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Times New Roman'],\n",
    "    'font.weight': 'black',\n",
    "    'axes.labelweight': 'black',\n",
    "    'axes.titleweight': 'black',\n",
    "    'axes.unicode_minus': False,\n",
    "    'figure.dpi': 300\n",
    "})\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.rcParams['axes.axisbelow'] = False\n",
    "\n",
    "\n",
    "def lighten_color_slightly(color) -> str:\n",
    "    r, g, b = plt.cm.colors.to_rgb(color)\n",
    "    h, l, s = colorsys.rgb_to_hls(r, g, b)\n",
    "    return plt.cm.colors.to_hex(\n",
    "        colorsys.hls_to_rgb(h, min(1.0, l + 0.12), s * 0.88)\n",
    "    )\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 2. 数据处理\n",
    "# ==========================================\n",
    "def build_overlap_matrix(input_file: Path) -> tuple[pd.DataFrame, int]:\n",
    "    df = pd.read_csv(input_file, encoding='utf-8-sig')\n",
    "\n",
    "    if 'L2政策' not in df.columns and 'L2政策中文名' in df.columns:\n",
    "        df.rename(columns={'L2政策中文名': 'L2政策'}, inplace=True)\n",
    "\n",
    "    def safe_col(d: pd.DataFrame, name: str) -> pd.Series:\n",
    "        return d[name].iloc[:, 0] if isinstance(d[name], pd.DataFrame) else d[name]\n",
    "\n",
    "    df_clean = pd.DataFrame({\n",
    "        'P': safe_col(df, 'L2政策').astype(str),\n",
    "        'C': safe_col(df, '国家').astype(str),\n",
    "        'G': safe_col(df, '聚类ID')\n",
    "    }).drop_duplicates()\n",
    "\n",
    "    policies = sorted(df_clean['P'].unique())\n",
    "    countries = sorted(df_clean['C'].unique())\n",
    "\n",
    "    res_map = {\n",
    "        p: dict(zip(\n",
    "            df_clean[df_clean['P'] == p]['C'],\n",
    "            df_clean[df_clean['P'] == p]['G']\n",
    "        ))\n",
    "        for p in policies\n",
    "    }\n",
    "\n",
    "    n = len(countries)\n",
    "    matrix = np.zeros((n, n), dtype=int)\n",
    "\n",
    "    for i, c1 in enumerate(countries):\n",
    "        for j in range(i, n):\n",
    "            c2 = countries[j]\n",
    "            common = sum(\n",
    "                1 for p in policies\n",
    "                if c1 in res_map[p]\n",
    "                and c2 in res_map[p]\n",
    "                and (res_map[p][c1] == res_map[p][c2] if i != j else True)\n",
    "            )\n",
    "            matrix[i, j] = matrix[j, i] = common\n",
    "\n",
    "    return pd.DataFrame(matrix, index=countries, columns=countries), len(policies)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. 绘图\n",
    "# ==========================================\n",
    "def draw_heatmap(\n",
    "    data_df: pd.DataFrame,\n",
    "    Z_linkage,\n",
    "    row_colors: pd.Series,\n",
    "    filename: str,\n",
    "    title: str,\n",
    "    v_max: int\n",
    ") -> None:\n",
    "\n",
    "    size = max(18, len(data_df) * 0.72)\n",
    "\n",
    "    g = sns.clustermap(\n",
    "        data_df,\n",
    "        row_linkage=Z_linkage,\n",
    "        col_linkage=Z_linkage,\n",
    "        cmap='RdYlBu_r',\n",
    "        row_colors=row_colors,\n",
    "        col_colors=row_colors,\n",
    "        dendrogram_ratio=0.1,\n",
    "        linewidths=0.5,\n",
    "        figsize=(size, size),\n",
    "        annot=True,\n",
    "        fmt='d',\n",
    "        vmin=0,\n",
    "        vmax=v_max,\n",
    "        annot_kws={'fontsize': 28, 'weight': 'black', 'fontproperties': T_BLACK},\n",
    "        tree_kws={'linewidths': 6}\n",
    "    )\n",
    "\n",
    "    save_path = data_dir / filename\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close('all')\n",
    "\n",
    "    print(f\"✅ 保存成功: {filename}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 4. 左下角重心聚类（不强制 k）\n",
    "# ==========================================\n",
    "def compute_force_left_clustering(\n",
    "    df: pd.DataFrame\n",
    ") -> tuple[np.ndarray, pd.Series, dict]:\n",
    "\n",
    "    Z = linkage(df.values, method='ward')\n",
    "    weights = df.sum(axis=1).values\n",
    "\n",
    "    # ---- 局部：保证大权重在左子树 ----\n",
    "    w_map = {i: v for i, v in enumerate(weights)}\n",
    "    for i, (c1, c2, _, _) in enumerate(Z):\n",
    "        c1, c2 = int(c1), int(c2)\n",
    "        if w_map[c1] < w_map[c2]:\n",
    "            Z[i, 0], Z[i, 1] = c2, c1\n",
    "        w_map[len(weights) + i] = w_map[c1] + w_map[c2]\n",
    "\n",
    "    # ---- 全局：检测左右重心 ----\n",
    "    leaves = leaves_list(Z)\n",
    "    mid = len(leaves) // 2\n",
    "    left_weight = int(weights[leaves[:mid]].sum())\n",
    "    right_weight = int(weights[leaves[mid:]].sum())\n",
    "\n",
    "    flipped = False\n",
    "    if right_weight > left_weight:\n",
    "        Z[:, [0, 1]] = Z[:, [1, 0]]\n",
    "        flipped = True\n",
    "\n",
    "    # ---- 颜色：按叶序渐变（不暗示聚类数） ----\n",
    "    n = len(df)\n",
    "    palette = sns.color_palette(\"husl\", n)\n",
    "    row_colors = pd.Series(\n",
    "        [lighten_color_slightly(palette[i]) for i in range(n)],\n",
    "        index=df.index[leaves]\n",
    "    ).reindex(df.index)\n",
    "\n",
    "    info = {\n",
    "        \"left_weight\": left_weight,\n",
    "        \"right_weight\": right_weight,\n",
    "        \"flipped\": flipped\n",
    "    }\n",
    "\n",
    "    return Z, row_colors, info\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 5. 主流程\n",
    "# ==========================================\n",
    "def plot_independent_comparison(\n",
    "    breadth_file: Path,\n",
    "    intensity_file: Path\n",
    ") -> None:\n",
    "\n",
    "    df_b, max_b = build_overlap_matrix(breadth_file)\n",
    "    df_i, max_i = build_overlap_matrix(intensity_file)\n",
    "\n",
    "    common_countries = sorted(set(df_b.index) & set(df_i.index))\n",
    "    df_b = df_b.loc[common_countries, common_countries]\n",
    "    df_i = df_i.loc[common_countries, common_countries]\n",
    "\n",
    "    # -------- Intensity --------\n",
    "    print(\"--------- 处理 Intensity (左下角模式 / 无 k) ---------\")\n",
    "\n",
    "    Z_i, colors_i, info_i = compute_force_left_clustering(df_i)\n",
    "    print(f\"   [重心检测] 左侧权重: {info_i['left_weight']} | 右侧权重: {info_i['right_weight']}\")\n",
    "\n",
    "    if info_i[\"flipped\"]:\n",
    "        print(\"   >>> ⚠️ 重心在右侧，已执行全树镜像翻转 → 左下角\")\n",
    "    else:\n",
    "        print(\"   >>> ✅ 重心已在左侧，无需调整\")\n",
    "\n",
    "    draw_heatmap(\n",
    "        df_i, Z_i, colors_i,\n",
    "        \"4-1-independent_ForceLeft_INTENSITY.png\",\n",
    "        \"Intensity\",\n",
    "        max_i\n",
    "    )\n",
    "\n",
    "    # -------- Breadth --------\n",
    "    print(\"\\n--------- 处理 Breadth (左下角模式 / 无 k) ---------\")\n",
    "\n",
    "    Z_b, colors_b, info_b = compute_force_left_clustering(df_b)\n",
    "    print(f\"   [重心检测] 左侧权重: {info_b['left_weight']} | 右侧权重: {info_b['right_weight']}\")\n",
    "\n",
    "    if info_b[\"flipped\"]:\n",
    "        print(\"   >>> ⚠️ 重心在右侧，已执行全树镜像翻转 → 左下角\")\n",
    "    else:\n",
    "        print(\"   >>> ✅ 重心已在左侧，无需调整\")\n",
    "\n",
    "    draw_heatmap(\n",
    "        df_b, Z_b, colors_b,\n",
    "        \"4-1-independent_ForceLeft_BREADTH.png\",\n",
    "        \"Breadth\",\n",
    "        max_b\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    plot_independent_comparison(\n",
    "        data_dir / \"3-1-L2_Policy_Clustering_Breadth.csv\",\n",
    "        data_dir / \"3-1-L2_Policy_Clustering_Intensity.csv\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
