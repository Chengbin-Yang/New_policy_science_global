{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304585c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Cell 1: 聚类分析 (Clustering)\n",
    "# ==========================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Dict\n",
    "import warnings\n",
    "\n",
    "# 忽略警告\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. 核心聚类算法\n",
    "def auto_select_k_and_cluster(X_data: np.ndarray, max_k: int = 10) -> np.ndarray:\n",
    "    \"\"\"自动选择最佳K值并返回聚类标签 (基于肘部法则-最大降幅)\"\"\"\n",
    "    n_samples = len(X_data)\n",
    "    if n_samples < 3:\n",
    "        return np.zeros(n_samples, dtype=int)\n",
    "\n",
    "    Z = linkage(X_data, method='ward')\n",
    "    \n",
    "    wcss_list = []\n",
    "    valid_ks = list(range(2, min(max_k, n_samples) + 1))\n",
    "    \n",
    "    for k in valid_ks:\n",
    "        labels = fcluster(Z, k, criterion='maxclust')\n",
    "        wcss = 0\n",
    "        for i in range(1, k + 1):\n",
    "            cluster_points = X_data[labels == i]\n",
    "            if len(cluster_points) > 0:\n",
    "                center = cluster_points.mean(axis=0)\n",
    "                wcss += np.sum((cluster_points - center) ** 2)\n",
    "        wcss_list.append(wcss)\n",
    "    \n",
    "    if len(wcss_list) < 2:\n",
    "        best_k = valid_ks[0]\n",
    "    else:\n",
    "        deltas = [wcss_list[i] - wcss_list[i+1] for i in range(len(wcss_list)-1)]\n",
    "        best_idx = np.argmax(deltas)\n",
    "        best_k = valid_ks[best_idx + 1]\n",
    "    \n",
    "    return fcluster(Z, best_k, criterion='maxclust') - 1\n",
    "\n",
    "def run_clustering_single_metric(df_source: pd.DataFrame, l2_name: str, need_scale: bool = False) -> pd.Series:\n",
    "    \"\"\"处理单条L2政策\"\"\"\n",
    "    # === 修改点1：严格限制年份 2005-2023 ===\n",
    "    df = df_source[(df_source['TIME_PERIOD'] >= 2005) & (df_source['TIME_PERIOD'] <= 2023)]\n",
    "    \n",
    "    X = df.set_index(['REF_AREA', 'TIME_PERIOD'])[l2_name].unstack().fillna(0)\n",
    "    \n",
    "    if X.empty:\n",
    "        return pd.Series(dtype=int)\n",
    "\n",
    "    if need_scale:\n",
    "        scaler = MinMaxScaler()\n",
    "        if X.values.max() == X.values.min():\n",
    "            X_vals = X.values\n",
    "        else:\n",
    "            X_vals = scaler.fit_transform(X)\n",
    "    else:\n",
    "        X_vals = X.values\n",
    "        \n",
    "    labels = auto_select_k_and_cluster(X_vals)\n",
    "    return pd.Series(labels, index=X.index, name='ClusterID')\n",
    "\n",
    "# 2. 数据 IO\n",
    "def load_data(data_dir: Path):\n",
    "    df_b = pd.read_parquet(data_dir / \"2-1-country_breadth.parquet\")\n",
    "    df_i = pd.read_parquet(data_dir / \"2-1-country_intensity.parquet\")\n",
    "    l2_list = [c for c in df_b.columns if c not in {'REF_AREA', 'TIME_PERIOD'}]\n",
    "    return df_b, df_i, l2_list\n",
    "\n",
    "def save_clustered_data(cluster_results: Dict[str, pd.Series], df_source: pd.DataFrame, output_path: Path):\n",
    "    records = []\n",
    "    # 同样确保源数据也是 2005-2023，以便保存时一致\n",
    "    df_source_filtered = df_source[(df_source['TIME_PERIOD'] >= 2005) & (df_source['TIME_PERIOD'] <= 2023)]\n",
    "    \n",
    "    for l2, clusters in cluster_results.items():\n",
    "        if clusters.empty: continue\n",
    "        \n",
    "        sub = df_source_filtered[['REF_AREA', 'TIME_PERIOD', l2]].copy()\n",
    "        sub.columns = ['国家', '年份', '占比'] # 统一列名\n",
    "        sub['聚类ID'] = sub['国家'].map(clusters)\n",
    "        sub['L2政策'] = l2\n",
    "        sub['L2政策中文名'] = l2 # 占位，确保列存在\n",
    "        \n",
    "        sub = sub.dropna(subset=['聚类ID'])\n",
    "        sub['聚类ID'] = sub['聚类ID'].astype(int)\n",
    "        records.append(sub)\n",
    "        \n",
    "    if records:\n",
    "        final_df = pd.concat(records)\n",
    "        final_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"✅ 已保存: {output_path.name}\")\n",
    "\n",
    "# 3. 执行\n",
    "base_dir = Path.cwd().parent\n",
    "data_dir = base_dir / \"data\" if (base_dir / \"data\").exists() else Path.cwd() / \"data\"\n",
    "print(f\"数据目录: {data_dir}\")\n",
    "\n",
    "df_b, df_i, l2_list = load_data(data_dir)\n",
    "\n",
    "print(\"正在执行 Breadth 聚类 (2005-2023)...\")\n",
    "b_results = {l2: run_clustering_single_metric(df_b, l2, need_scale=False) for l2 in l2_list}\n",
    "save_clustered_data(b_results, df_b, data_dir / \"3-1-L2_Policy_Clustering_Breadth.csv\")\n",
    "\n",
    "print(\"正在执行 Intensity 聚类 (2005-2023)...\")\n",
    "i_results = {l2: run_clustering_single_metric(df_i, l2, need_scale=True) for l2 in l2_list}\n",
    "save_clustered_data(i_results, df_i, data_dir / \"3-1-L2_Policy_Clustering_Intensity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "84b78036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理数据并保存至: f:\\Desktop\\科研项目\\1.负责科研项目\\Climate Policy\\CAMPF_Supplementary\\data\\3-2-Automated_Recognition_Mode.csv\n",
      "✅ 成功保存 1470 条特征记录。\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 12: 计算特征并保存文件 (Generate Metadata)\n",
    "# ==========================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# 路径配置\n",
    "BASE_DIR = Path.cwd().parent\n",
    "DATA_DIR = BASE_DIR / \"data\" if (BASE_DIR / \"data\").exists() else Path.cwd() / \"data\"\n",
    "OUTPUT_FILE = DATA_DIR / \"3-2-Automated_Recognition_Mode.csv\"\n",
    "\n",
    "def calculate_cluster_metrics(df_sub: pd.DataFrame, is_intensity: bool) -> Dict[int, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    计算指定L2政策下各聚类的形态特征 (High/Low, Rising/Stable等)。\n",
    "    \"\"\"\n",
    "    # 阈值设定\n",
    "    th_high = 6.0 if is_intensity else 0.6\n",
    "    th_med = 3.0 if is_intensity else 0.3\n",
    "    th_slope = 1.5 if is_intensity else 0.15\n",
    "\n",
    "    # 筛选年份并计算均值曲线\n",
    "    df_calc = df_sub[(df_sub['年份'] >= 2005) & (df_sub['年份'] <= 2023)]\n",
    "    trends = df_calc.groupby(['聚类ID', '年份'])['占比'].mean().unstack()\n",
    "    \n",
    "    features = {}\n",
    "    for cid, row in trends.iterrows():\n",
    "        ts = row.dropna()\n",
    "        if len(ts) < 2:\n",
    "            features[cid] = {'Starting': 'Low', 'Trend': 'Stable', 'Ending': 'Low', 'MeanStart': 0}\n",
    "            continue\n",
    "            \n",
    "        start_val = ts.iloc[:3].mean()\n",
    "        end_val = ts.iloc[-3].mean()\n",
    "        slope = end_val - start_val\n",
    "        std = ts.std()\n",
    "        \n",
    "        # 判定 Starting\n",
    "        if start_val > th_high: s_lbl = 'High'\n",
    "        elif start_val > th_med: s_lbl = 'Medium'\n",
    "        else: s_lbl = 'Low'\n",
    "        \n",
    "        # 判定 Ending\n",
    "        if end_val > th_high: e_lbl = 'High'\n",
    "        elif end_val > th_med: e_lbl = 'Medium'\n",
    "        else: e_lbl = 'Low'\n",
    "        \n",
    "        # 判定 Trend\n",
    "        if slope > th_slope: t_lbl = 'Rise'\n",
    "        elif slope < -0.05: t_lbl = 'Decline'\n",
    "        elif std > (1.0 if is_intensity else 0.1): t_lbl = 'Fluctuate'\n",
    "        else: t_lbl = 'Stable'\n",
    "        \n",
    "        features[cid] = {\n",
    "            'Starting': s_lbl, 'Trend': t_lbl, 'Ending': e_lbl, 'MeanStart': start_val\n",
    "        }\n",
    "    return features\n",
    "\n",
    "def generate_metadata(file_name: str, metric_type: str) -> pd.DataFrame:\n",
    "    \"\"\"读取聚类结果，生成包含特征标签的元数据表\"\"\"\n",
    "    file_path = DATA_DIR / file_name\n",
    "    if not file_path.exists():\n",
    "        print(f\"⚠️ 文件未找到: {file_name}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "    is_intensity = (metric_type == 'Intensity')\n",
    "    records = []\n",
    "\n",
    "    for l2 in df['L2政策中文名'].unique():\n",
    "        l2_data = df[df['L2政策中文名'] == l2]\n",
    "        feats_map = calculate_cluster_metrics(l2_data, is_intensity)\n",
    "        \n",
    "        # 将特征映射回该聚类的所有国家\n",
    "        # 为了去重，我们只需保留 (L2, ClusterID) 的唯一组合即可，\n",
    "        # 但为了后续方便，这里保留国家字段并在返回时去重\n",
    "        for _, row in l2_data.iterrows():\n",
    "            cid = row['聚类ID']\n",
    "            if cid in feats_map:\n",
    "                f = feats_map[cid]\n",
    "                records.append({\n",
    "                    'L2政策中文名': l2,\n",
    "                    '国家': row['国家'],\n",
    "                    '聚类ID': cid,\n",
    "                    'Starting': f['Starting'],\n",
    "                    'Trend': f['Trend'],\n",
    "                    'Ending': f['Ending'],\n",
    "                    'MeanStart': f['MeanStart'],\n",
    "                    'Type': metric_type\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(records).drop_duplicates(subset=['L2政策中文名', '国家', 'Type'])\n",
    "\n",
    "# --- 主执行流程 ---\n",
    "print(f\"正在处理数据并保存至: {OUTPUT_FILE}\")\n",
    "df_breadth = generate_metadata(\"3-1-L2_Policy_Clustering_Breadth.csv\", \"Breadth\")\n",
    "df_intensity = generate_metadata(\"3-1-L2_Policy_Clustering_Intensity.csv\", \"Intensity\")\n",
    "\n",
    "if not df_breadth.empty and not df_intensity.empty:\n",
    "    full_df = pd.concat([df_breadth, df_intensity], ignore_index=True)\n",
    "    full_df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "    print(f\"✅ 成功保存 {len(full_df)} 条特征记录。\")\n",
    "else:\n",
    "    print(\"❌ 生成失败，请检查源文件。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f43bc818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> 开始绘图: Breadth\n",
      "  -> 保存: Buildings_–_market-based_instruments_Breadth_Sorted.png\n",
      "  -> 保存: Buildings_–_non_market-based_instruments_Breadth_Sorted.png\n",
      "  -> 保存: Climate_governance_Breadth_Sorted.png\n",
      "  -> 保存: Electricity_–_market-based_instruments_Breadth_Sorted.png\n",
      "  -> 保存: Electricity_–_non_market-based_instruments_Breadth_Sorted.png\n",
      "  -> 保存: Fossil_fuel_production_policies_Breadth_Sorted.png\n",
      "  -> 保存: GHG_emissions_data_and_reporting_Breadth_Sorted.png\n",
      "  -> 保存: GHG_emissions_targets_Breadth_Sorted.png\n",
      "  -> 保存: Industry_–_market-based_instruments_Breadth_Sorted.png\n",
      "  -> 保存: Industry_–_non_market-based_instruments_Breadth_Sorted.png\n",
      "  -> 保存: International_climate_co-operation_Breadth_Sorted.png\n",
      "  -> 保存: International_public_finance_Breadth_Sorted.png\n",
      "  -> 保存: Public_Research,_Development_and_Demonstration_Breadth_Sorted.png\n",
      "  -> 保存: Transport_–_market-based_instruments_Breadth_Sorted.png\n",
      "  -> 保存: Transport_–_non_market-based_instruments_Breadth_Sorted.png\n",
      "✅ 完成。输出: f:\\Desktop\\科研项目\\1.负责科研项目\\Climate Policy\\CAMPF_Supplementary\\data\\3-1-(3-2)Sorted_L2_Policy_Clustering_pic\\Plots_Breadth\n",
      "\n",
      ">>> 开始绘图: Intensity\n",
      "  -> 保存: Buildings_–_market-based_instruments_Intensity_Sorted.png\n",
      "  -> 保存: Buildings_–_non_market-based_instruments_Intensity_Sorted.png\n",
      "  -> 保存: Climate_governance_Intensity_Sorted.png\n",
      "  -> 保存: Electricity_–_market-based_instruments_Intensity_Sorted.png\n",
      "  -> 保存: Electricity_–_non_market-based_instruments_Intensity_Sorted.png\n",
      "  -> 保存: Fossil_fuel_production_policies_Intensity_Sorted.png\n",
      "  -> 保存: GHG_emissions_data_and_reporting_Intensity_Sorted.png\n",
      "  -> 保存: GHG_emissions_targets_Intensity_Sorted.png\n",
      "  -> 保存: Industry_–_market-based_instruments_Intensity_Sorted.png\n",
      "  -> 保存: Industry_–_non_market-based_instruments_Intensity_Sorted.png\n",
      "  -> 保存: International_climate_co-operation_Intensity_Sorted.png\n",
      "  -> 保存: International_public_finance_Intensity_Sorted.png\n",
      "  -> 保存: Public_Research,_Development_and_Demonstration_Intensity_Sorted.png\n",
      "  -> 保存: Transport_–_market-based_instruments_Intensity_Sorted.png\n",
      "  -> 保存: Transport_–_non_market-based_instruments_Intensity_Sorted.png\n",
      "✅ 完成。输出: f:\\Desktop\\科研项目\\1.负责科研项目\\Climate Policy\\CAMPF_Supplementary\\data\\3-1-(3-2)Sorted_L2_Policy_Clustering_pic\\Plots_Intensity\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 3: 绘图与可视化 (Plotting from File)\n",
    "# ==========================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.ticker import MaxNLocator, MultipleLocator\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Any\n",
    "import matplotlib as mpl\n",
    "\n",
    "# === 配置与样式 ===\n",
    "def setup_mpl_single2() -> None:\n",
    "    mpl.rc('font', size=25)\n",
    "    mpl.rcParams.update({\n",
    "        'legend.fontsize': 'small',\n",
    "        'xtick.labelsize': 'small', 'ytick.labelsize': 'small',\n",
    "        'lines.linewidth': 2, 'axes.linewidth': 2,\n",
    "        'xtick.major.pad': '12', 'ytick.major.pad': '12',\n",
    "        'xtick.direction': 'in', 'ytick.direction': 'in',\n",
    "        'xtick.top': False, 'ytick.right': False,\n",
    "        'mathtext.default': 'regular', 'axes.titlesize': 'small'\n",
    "    })\n",
    "\n",
    "setup_mpl_single2()\n",
    "\n",
    "NATURE_COLORS = [\n",
    "    '#E64B35', \"#6917C2\", '#00A087', '#3C5488', '#F39B7F', \n",
    "    '#8491B4', '#91D1C2', '#DC0000', '#7E6148', '#B09C85', \n",
    "    '#E18727', '#20854E', '#0072B5', '#BC3C29', '#6F99AD'\n",
    "]\n",
    "\n",
    "def lighten_color(color: Any, amount: float = 0.7) -> Tuple[float, float, float]:\n",
    "    c = mcolors.to_rgb(color)\n",
    "    return tuple([c[i] + (1 - c[i]) * amount for i in range(3)])\n",
    "\n",
    "# === 排序与辅助逻辑 ===\n",
    "def sort_clusters(sort_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"根据 Starting > Ending > Trend 规则对元数据进行排序\"\"\"\n",
    "    orders = {\n",
    "        'Starting': {'Low': 0, 'Medium': 1, 'High': 2},\n",
    "        'Ending': {'Low': 0, 'Medium': 1, 'High': 2},\n",
    "        'Trend': {'Rise': 0, 'Stable': 1, 'Fluctuate': 2, 'Decline': 3}\n",
    "    }\n",
    "    \n",
    "    df = sort_df.copy()\n",
    "    df['sort_key'] = df.apply(lambda r: (\n",
    "        orders['Starting'].get(r['Starting'], 99),\n",
    "        orders['Ending'].get(r['Ending'], 99),\n",
    "        orders['Trend'].get(r['Trend'], 99),\n",
    "        r.get('MeanStart', 0)\n",
    "    ), axis=1)\n",
    "    \n",
    "    return df.sort_values('sort_key')\n",
    "\n",
    "def get_plot_title(sort_df: pd.DataFrame, l2_name: str, cid: int) -> str:\n",
    "    \"\"\"构建标题字符串\"\"\"\n",
    "    row = sort_df[(sort_df['L2政策中文名'] == l2_name) & (sort_df['聚类ID'] == cid)]\n",
    "    if row.empty: return f\"Cluster {cid}\"\n",
    "    r = row.iloc[0]\n",
    "    return f\"{r['Starting']}+{r['Trend']}+{r['Ending'].replace(' Share', '')}\"\n",
    "\n",
    "# === 核心绘图逻辑 ===\n",
    "def plot_policy_trends(l2_name: str, l2_data: pd.DataFrame, sort_df: pd.DataFrame, \n",
    "                       metric_label: str, output_dir: Path) -> None:\n",
    "    # 1. 严格筛选年份\n",
    "    df_plot = l2_data[(l2_data['年份'] >= 2005) & (l2_data['年份'] <= 2023)]\n",
    "    if df_plot.empty: return\n",
    "\n",
    "    # 2. 获取排序后的 Cluster ID\n",
    "    l2_sort_info = sort_df[sort_df['L2政策中文名'] == l2_name]\n",
    "    if l2_sort_info.empty: return\n",
    "    sorted_cids = l2_sort_info.sort_values('sort_key')['聚类ID'].unique()\n",
    "\n",
    "    # 3. 准备绘图数据\n",
    "    years = sorted(df_plot['年份'].unique())\n",
    "    matrix = df_plot.pivot(index='年份', columns='国家', values='占比').reindex(years)\n",
    "    overall_mean = matrix.mean(axis=1)\n",
    "    y_max = matrix.max().max() * 1.15\n",
    "\n",
    "    # 4. 布局设置\n",
    "    n_clusters = len(sorted_cids)\n",
    "    n_cols, n_rows = 3, (n_clusters + 2) // 3\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 3.5 * n_rows), squeeze=False)\n",
    "\n",
    "    for idx, cid in enumerate(sorted_cids):\n",
    "        ax = axes[idx // n_cols, idx % n_cols]\n",
    "        countries = [c for c in l2_sort_info[l2_sort_info['聚类ID'] == cid]['国家'].values if c in matrix.columns]\n",
    "        if not countries: continue\n",
    "\n",
    "        # 样式参数\n",
    "        color = NATURE_COLORS[idx % len(NATURE_COLORS)]\n",
    "        fill_color = lighten_color(color, 0.7)\n",
    "        sub_matrix = matrix[countries]\n",
    "        c_mean = sub_matrix.mean(axis=1)\n",
    "\n",
    "        # 绘图\n",
    "        ax.plot(sub_matrix.index, sub_matrix.values, color=color, alpha=0.25, lw=1.2, zorder=1)\n",
    "        ax.plot(c_mean.index, c_mean, marker='o', color=color, lw=2.5, ms=7,\n",
    "                mfc=fill_color, mec=color, mew=1.8, label='Cluster Average',\n",
    "                markevery=max(1, len(years)//10), zorder=10)\n",
    "        ax.plot(overall_mean.index, overall_mean, color='#000000', ls='--', lw=2.5,\n",
    "                label='Overall Average', alpha=0.85, zorder=9, dashes=(3, 2))\n",
    "\n",
    "        # 文本与轴设置\n",
    "        title = get_plot_title(l2_sort_info, l2_name, cid)\n",
    "        ax.set_title(f\"{title}\\n({len(countries)} countries)\", pad=15, ha='center')\n",
    "        \n",
    "        # === 修改点：Y轴向下延伸 4% ===\n",
    "        y_neg_padding = y_max * 0.04\n",
    "        ax.set_ylim(bottom=-y_neg_padding, top=y_max)\n",
    "        \n",
    "        ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(nbins=6))\n",
    "        ax.tick_params(axis='x', rotation=90, labelsize=15, pad=5.5)\n",
    "        ax.tick_params(axis='y')\n",
    "        \n",
    "        if idx % n_cols == 0: ax.set_ylabel(metric_label)\n",
    "        else: ax.set_ylabel('')\n",
    "            \n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        # 图例 (所有子图均显示)\n",
    "        ax.legend(loc='best', frameon=False, fontsize=12, handlelength=2.0, markerscale=0.8)\n",
    "\n",
    "    # 隐藏空子图\n",
    "    for j in range(n_clusters, n_rows * n_cols):\n",
    "        axes[j // n_cols, j % n_cols].axis('off')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.25, top=0.85, bottom=0.15, hspace=0.45)\n",
    "    \n",
    "    safe_name = l2_name.replace(\"/\", \"_\").replace(\" \", \"_\").replace(\":\", \"\")\n",
    "    out_path = output_dir / f\"{safe_name}_{metric_label}_Sorted.png\"\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()\n",
    "    print(f\"  -> 保存: {out_path.name}\")\n",
    "\n",
    "# === 执行流程 ===\n",
    "def process_file_plotting(file_name: str, metric_label: str) -> None:\n",
    "    base_dir = Path.cwd().parent\n",
    "    data_dir = base_dir / \"data\" if (base_dir / \"data\").exists() else Path.cwd() / \"data\"\n",
    "    feature_file = data_dir / \"3-2-Automated_Recognition_Mode.csv\"\n",
    "    input_file = data_dir / file_name\n",
    "\n",
    "    if not input_file.exists() or not feature_file.exists():\n",
    "        print(f\"❌ 缺少必要文件: {input_file.name} 或特征文件\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n>>> 开始绘图: {metric_label}\")\n",
    "    df_data = pd.read_csv(input_file, encoding='utf-8-sig')\n",
    "    df_meta = pd.read_csv(feature_file, encoding='utf-8-sig')\n",
    "    \n",
    "    # 筛选对应类型的元数据并排序\n",
    "    df_meta = sort_clusters(df_meta[df_meta['Type'] == metric_label])\n",
    "    \n",
    "    out_dir = data_dir / \"3-1-(3-2)Sorted_L2_Policy_Clustering_pic\" / f\"Plots_{metric_label}\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for l2 in df_data['L2政策中文名'].dropna().unique():\n",
    "        plot_policy_trends(l2, df_data[df_data['L2政策中文名'] == l2], df_meta, metric_label, out_dir)\n",
    "    print(f\"✅ 完成。输出: {out_dir}\")\n",
    "\n",
    "# 运行\n",
    "process_file_plotting(\"3-1-L2_Policy_Clustering_Breadth.csv\", \"Breadth\")\n",
    "process_file_plotting(\"3-1-L2_Policy_Clustering_Intensity.csv\", \"Intensity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6a965a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> 正在生成 PPT (顺序固定版): Analysis_Report_Breadth_Editable.pptx ...\n",
      "  [15/15] 处理: Transport – non mark...\n",
      "✅ PPT 生成完毕: Analysis_Report_Breadth_Editable.pptx\n",
      "\n",
      ">>> 正在生成 PPT (顺序固定版): Analysis_Report_Intensity_Editable.pptx ...\n",
      "  [15/15] 处理: Transport – non mark...\n",
      "✅ PPT 生成完毕: Analysis_Report_Intensity_Editable.pptx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.ticker import MaxNLocator, MultipleLocator\n",
    "from pathlib import Path\n",
    "import io\n",
    "import matplotlib as mpl\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "from pptx.dml.color import RGBColor\n",
    "from pptx.enum.text import PP_ALIGN\n",
    "import re\n",
    "\n",
    "# ==========================================\n",
    "# 1. 样式与基础配置\n",
    "# ==========================================\n",
    "def setup_mpl_single2():\n",
    "    mpl.rc('font', size=12) \n",
    "    mpl.rcParams.update({\n",
    "        'legend.fontsize': 9, \n",
    "        'xtick.labelsize': 10, \n",
    "        'ytick.labelsize': 10,\n",
    "        'lines.linewidth': 2, \n",
    "        'axes.linewidth': 1.2,\n",
    "        'xtick.major.pad': '3', \n",
    "        'ytick.major.pad': '3',\n",
    "        'xtick.direction': 'in', \n",
    "        'ytick.direction': 'in',\n",
    "        'xtick.top': False, \n",
    "        'ytick.right': False,\n",
    "        'mathtext.default': 'regular', \n",
    "        'axes.titlesize': 11\n",
    "    })\n",
    "setup_mpl_single2()\n",
    "\n",
    "NATURE_COLORS = [\n",
    "    '#E64B35', \"#6917C2\", '#00A087', '#3C5488', '#F39B7F', \n",
    "    '#8491B4', '#91D1C2', '#DC0000', '#7E6148', '#B09C85', \n",
    "    '#E18727', '#20854E', '#0072B5', '#BC3C29', '#6F99AD'\n",
    "]\n",
    "\n",
    "def lighten_color(color, amount=0.7):\n",
    "    try:\n",
    "        c = mcolors.to_rgb(color)\n",
    "        c = tuple([c[i] + (1 - c[i]) * amount for i in range(3)])\n",
    "        return c\n",
    "    except: return color\n",
    "\n",
    "# ==========================================\n",
    "# 2. 核心绘图函数\n",
    "# ==========================================\n",
    "def create_single_cluster_img(l2_data, cid, years, matrix, overall_mean, y_max, metric_label, color_idx, show_ylabel):\n",
    "    countries = l2_data[l2_data['聚类ID'] == cid]['国家'].unique()\n",
    "    countries = [c for c in countries if c in matrix.columns]\n",
    "    \n",
    "    if not countries: return None\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4.2, 2.8))\n",
    "    \n",
    "    color = NATURE_COLORS[color_idx % len(NATURE_COLORS)]\n",
    "    fill_color = lighten_color(color, 0.7)\n",
    "    \n",
    "    sub_matrix = matrix[countries]\n",
    "    c_mean = sub_matrix.mean(axis=1)\n",
    "    \n",
    "    ax.plot(sub_matrix.index, sub_matrix.values, color=color, alpha=0.25, lw=1.0, zorder=1)\n",
    "    ax.plot(c_mean.index, c_mean, marker='o', color=color, lw=2.0, ms=5,\n",
    "            mfc=fill_color, mec=color, mew=1.5, label='Cluster Avg',\n",
    "            markevery=max(1, len(years)//10), zorder=10)\n",
    "    ax.plot(overall_mean.index, overall_mean, color='#000000', ls='--', lw=2.0,\n",
    "            label='Overall Avg', alpha=0.85, zorder=9, dashes=(3, 2))\n",
    "    \n",
    "    y_neg_padding = y_max * 0.04\n",
    "    ax.set_ylim(bottom=-y_neg_padding, top=y_max)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(MultipleLocator(2))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(nbins=5))\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "    \n",
    "    if show_ylabel:\n",
    "        ax.set_ylabel(metric_label)\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.legend(loc='best', frameon=False, fontsize=8, handlelength=1.5, markerscale=0.8)\n",
    "    \n",
    "    plt.subplots_adjust(left=0.18, right=0.97, top=0.95, bottom=0.25)\n",
    "    \n",
    "    img_stream = io.BytesIO()\n",
    "    plt.savefig(img_stream, format='png', dpi=200, transparent=True)\n",
    "    plt.close()\n",
    "    img_stream.seek(0)\n",
    "    return img_stream\n",
    "\n",
    "# ==========================================\n",
    "# 3. 数据加载与排序 (关键修改：锁定顺序)\n",
    "# ==========================================\n",
    "def load_features_and_stable_sort(feature_file: Path, metric_type: str):\n",
    "    \"\"\"\n",
    "    【修改版】使用绝对稳定的数值排序，而非文字排序。\n",
    "    这样即使你修改了 Starting 的文字，图表的位置也不会变。\n",
    "    \"\"\"\n",
    "    if not feature_file.exists(): return pd.DataFrame()\n",
    "    \n",
    "    df = pd.read_csv(feature_file, encoding='utf-8-sig')\n",
    "    df = df[df['Type'] == metric_type].copy()\n",
    "    \n",
    "    # 设定阈值 (与生成特征时一致)\n",
    "    if metric_type == 'Intensity':\n",
    "        th_high, th_med = 6.0, 3.0\n",
    "    else: # Breadth\n",
    "        th_high, th_med = 0.6, 0.3\n",
    "\n",
    "    # === 关键：现场计算等级，不依赖 CSV 里可能被改过的 Starting 文本 ===\n",
    "    def get_rank_from_value(val):\n",
    "        if val > th_high: return 2 # High\n",
    "        if val > th_med: return 1  # Medium\n",
    "        return 0                   # Low\n",
    "\n",
    "    # 辅助排序 (Ending 和 Trend 暂时还依赖文本，因为它们比较难直接反推数值)\n",
    "    # 但由于 Starting 是第一优先级，通常位置能保住\n",
    "    orders = {\n",
    "        'Ending': {'Low': 0, 'Medium': 1, 'High': 2},\n",
    "        'Trend': {'Rise': 0, 'Stable': 1, 'Fluctuate': 2, 'Decline': 3}\n",
    "    }\n",
    "    def clean_end(val): return str(val).replace(' Share', '')\n",
    "\n",
    "    df['sort_key'] = df.apply(lambda r: (\n",
    "        get_rank_from_value(r.get('MeanStart', 0)),          # 1. 依据数值计算出的 Starting Rank\n",
    "        orders['Ending'].get(clean_end(r['Ending']), 99),    # 2. Ending\n",
    "        orders['Trend'].get(r['Trend'], 99),                 # 3. Trend\n",
    "        r.get('MeanStart', 0)                                # 4. 数值兜底\n",
    "    ), axis=1)\n",
    "    \n",
    "    # 按照计算出的 Key 排序\n",
    "    return df.sort_values('sort_key')\n",
    "\n",
    "# ==========================================\n",
    "# 4. PPT 生成主程序\n",
    "# ==========================================\n",
    "def generate_ppt_grid(csv_file: Path, feature_file: Path, output_ppt: Path, metric_label: str):\n",
    "    if not csv_file.exists(): return\n",
    "\n",
    "    print(f\"\\n>>> 正在生成 PPT (顺序固定版): {output_ppt.name} ...\")\n",
    "    \n",
    "    df_data = pd.read_csv(csv_file, encoding='utf-8-sig')\n",
    "    df_data = df_data[(df_data['年份'] >= 2005) & (df_data['年份'] <= 2023)]\n",
    "    \n",
    "    # 使用稳定排序加载特征\n",
    "    df_features = load_features_and_stable_sort(feature_file, metric_label)\n",
    "    if df_features.empty: return\n",
    "\n",
    "    prs = Presentation()\n",
    "    prs.slide_width = Inches(13.333)\n",
    "    prs.slide_height = Inches(7.5)\n",
    "    \n",
    "    # 布局参数\n",
    "    MARGIN_LEFT = 0.5\n",
    "    MARGIN_TOP = 1.1   \n",
    "    COL_GAP = 0.15     \n",
    "    ROW_GAP = 0.4      \n",
    "    PLOT_WIDTH = 4.0\n",
    "    PLOT_HEIGHT = 2.6  \n",
    "    LABEL_HEIGHT = 0.35\n",
    "    \n",
    "    l2_list = df_data['L2政策中文名'].dropna().unique()\n",
    "    \n",
    "    for i, l2 in enumerate(l2_list):\n",
    "        print(f\"\\r  [{i+1}/{len(l2_list)}] 处理: {l2[:20]}...\", end=\"\")\n",
    "        \n",
    "        l2_feats = df_features[df_features['L2政策中文名'] == l2]\n",
    "        if l2_feats.empty: continue\n",
    "        \n",
    "        l2_sub = df_data[df_data['L2政策中文名'] == l2]\n",
    "        years = sorted(l2_sub['年份'].unique())\n",
    "        matrix = l2_sub.pivot(index='年份', columns='国家', values='占比').reindex(years)\n",
    "        overall_mean = matrix.mean(axis=1)\n",
    "        y_max = matrix.max().max() * 1.15\n",
    "        \n",
    "        # 获取排序后的 ID (此时顺序是固定的)\n",
    "        sorted_cids = l2_feats['聚类ID'].unique()\n",
    "        \n",
    "        slide = prs.slides.add_slide(prs.slide_layouts[6])\n",
    "        \n",
    "        # 标题\n",
    "        tb = slide.shapes.add_textbox(Inches(0.5), Inches(0.1), Inches(12), Inches(0.8))\n",
    "        p = tb.text_frame.paragraphs[0]\n",
    "        p.text = l2\n",
    "        p.font.size = Pt(24); p.font.bold = True; p.font.color.rgb = RGBColor(44, 62, 80)\n",
    "        \n",
    "        for idx, cid in enumerate(sorted_cids):\n",
    "            row, col = idx // 3, idx % 3\n",
    "            \n",
    "            curr_x = Inches(MARGIN_LEFT + col * (PLOT_WIDTH + COL_GAP))\n",
    "            curr_y = Inches(MARGIN_TOP + row * (LABEL_HEIGHT + PLOT_HEIGHT + ROW_GAP))\n",
    "            \n",
    "            if curr_y + Inches(3) > prs.slide_height: break \n",
    "            \n",
    "            # --- 关键：虽然位置是按数值排的，但显示的文字要读 CSV 里(你修改过的)内容 ---\n",
    "            feat_row = l2_feats[l2_feats['聚类ID'] == cid].iloc[0]\n",
    "            s_t = feat_row['Starting']  # 这里会读到你修改后的 'Low'\n",
    "            t_t = feat_row['Trend']     # 这里会读到你修改后的内容\n",
    "            e_t = str(feat_row['Ending']).replace(' Share', '') \n",
    "            \n",
    "            countries = l2_sub[l2_sub['聚类ID'] == cid]['国家'].unique()\n",
    "            label_text = f\"{s_t}+{t_t}+{e_t} ({len(countries)} countries)\"\n",
    "            \n",
    "            # 插入文本\n",
    "            tb_sub = slide.shapes.add_textbox(curr_x, curr_y, Inches(PLOT_WIDTH), Inches(LABEL_HEIGHT))\n",
    "            tp = tb_sub.text_frame.paragraphs[0]\n",
    "            tp.text = label_text\n",
    "            tp.font.size = Pt(14); tp.font.bold = True; tp.alignment = PP_ALIGN.CENTER\n",
    "            \n",
    "            # 插入图片\n",
    "            show_y = (col == 0)\n",
    "            img_stream = create_single_cluster_img(\n",
    "                l2_sub, cid, years, matrix, overall_mean, y_max, metric_label, idx, \n",
    "                show_ylabel=show_y\n",
    "            )\n",
    "            \n",
    "            if img_stream:\n",
    "                pic_y = curr_y + Inches(LABEL_HEIGHT)\n",
    "                slide.shapes.add_picture(img_stream, curr_x, pic_y, width=Inches(PLOT_WIDTH))\n",
    "                \n",
    "    prs.save(output_ppt)\n",
    "    print(f\"\\n✅ PPT 生成完毕: {output_ppt.name}\")\n",
    "\n",
    "# ==========================================\n",
    "# 5. 执行\n",
    "# ==========================================\n",
    "def main():\n",
    "    base_dir = Path.cwd().parent\n",
    "    data_dir = base_dir / \"data\" if (base_dir / \"data\").exists() else Path.cwd() / \"data\"\n",
    "    output_dir = data_dir / \"3-1-(3-2)Sorted_L2_Policy_Clustering_pic\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    feature_csv = data_dir / \"3-2-Automated_Recognition_Mode.csv\"\n",
    "    \n",
    "    # 1. Breadth PPT\n",
    "    generate_ppt_grid(\n",
    "        data_dir / \"3-1-L2_Policy_Clustering_Breadth.csv\",\n",
    "        feature_csv,\n",
    "        output_dir / \"Analysis_Report_Breadth_Editable.pptx\",\n",
    "        \"Breadth\"\n",
    "    )\n",
    "    \n",
    "    # 2. Intensity PPT\n",
    "    generate_ppt_grid(\n",
    "        data_dir / \"3-1-L2_Policy_Clustering_Intensity.csv\",\n",
    "        feature_csv,\n",
    "        output_dir / \"Analysis_Report_Intensity_Editable.pptx\",\n",
    "        \"Intensity\"\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate_policy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
