{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8621084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹æ‰§è¡Œï¼šç”Ÿæˆæ•°æ® -> å…¨é‡æ’åº -> é”å®š ID\n",
      "âœ… CSV å·²ä¿å­˜: 3-2-Automated_Recognition_Mode.csv\n",
      "âœ… é¡ºåºå·²ä¸¥æ ¼é”å®šè‡³ JSON: fixed_ppt_order.json\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 1: ç”Ÿæˆå…¨é‡æ•°æ® -> æ¨¡æ‹Ÿ Cell 3 æ’åº -> é”å®šé¡ºåº\n",
    "# ==========================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# --- è·¯å¾„é…ç½® ---\n",
    "BASE_DIR = Path.cwd().parent\n",
    "DATA_DIR = BASE_DIR / \"data\" if (BASE_DIR / \"data\").exists() else Path.cwd() / \"data\"\n",
    "OUTPUT_CSV = DATA_DIR / \"3-2-Automated_Recognition_Mode.csv\"\n",
    "OUTPUT_JSON = DATA_DIR / \"fixed_ppt_order.json\"\n",
    "\n",
    "# --- 1. ç‰¹å¾è®¡ç®— (æ¥è‡ª Cell 12) ---\n",
    "def calculate_cluster_metrics(df_sub: pd.DataFrame, is_intensity: bool) -> Dict[int, Dict[str, Any]]:\n",
    "    th_high = 6.0 if is_intensity else 0.6\n",
    "    th_med = 3.0 if is_intensity else 0.3\n",
    "    th_slope = 1.5 if is_intensity else 0.15\n",
    "\n",
    "    df_calc = df_sub[(df_sub['å¹´ä»½'] >= 2005) & (df_sub['å¹´ä»½'] <= 2023)]\n",
    "    # æ³¨æ„ï¼šgroupby é»˜è®¤ä¼šæŒ‰ key æ’åºï¼Œè¿™é‡Œä¿è¯äº† trends çš„ index æ˜¯æœ‰åºçš„\n",
    "    trends = df_calc.groupby(['èšç±»ID', 'å¹´ä»½'])['å æ¯”'].mean().unstack()\n",
    "    \n",
    "    features = {}\n",
    "    for cid, row in trends.iterrows():\n",
    "        ts = row.dropna()\n",
    "        if len(ts) < 2:\n",
    "            features[cid] = {'Starting': 'Low', 'Trend': 'Stable', 'Ending': 'Low', 'MeanStart': 0}\n",
    "            continue\n",
    "            \n",
    "        start_val = ts.iloc[:3].mean()\n",
    "        end_val = ts.iloc[-3].mean()\n",
    "        slope = end_val - start_val\n",
    "        std = ts.std()\n",
    "        \n",
    "        if start_val > th_high: s_lbl = 'High'\n",
    "        elif start_val > th_med: s_lbl = 'Medium'\n",
    "        else: s_lbl = 'Low'\n",
    "        \n",
    "        if end_val > th_high: e_lbl = 'High'\n",
    "        elif end_val > th_med: e_lbl = 'Medium'\n",
    "        else: e_lbl = 'Low'\n",
    "        \n",
    "        if slope > th_slope: t_lbl = 'Rise'\n",
    "        elif slope < -0.05: t_lbl = 'Decline'\n",
    "        elif std > (1.0 if is_intensity else 0.1): t_lbl = 'Fluctuate'\n",
    "        else: t_lbl = 'Stable'\n",
    "        \n",
    "        features[cid] = {\n",
    "            'Starting': s_lbl, 'Trend': t_lbl, 'Ending': e_lbl, 'MeanStart': start_val\n",
    "        }\n",
    "    return features\n",
    "\n",
    "# --- 2. æ’åºé€»è¾‘ (100% å¤åˆ» Cell 3) ---\n",
    "def sort_clusters_original_logic(sort_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"å®Œå…¨ä½¿ç”¨ Cell 3 çš„æ’åº Key é€»è¾‘\"\"\"\n",
    "    orders = {\n",
    "        'Starting': {'Low': 0, 'Medium': 1, 'High': 2},\n",
    "        'Ending': {'Low': 0, 'Medium': 1, 'High': 2},\n",
    "        'Trend': {'Rise': 0, 'Stable': 1, 'Fluctuate': 2, 'Decline': 3}\n",
    "    }\n",
    "    \n",
    "    df = sort_df.copy()\n",
    "    df['sort_key'] = df.apply(lambda r: (\n",
    "        orders['Starting'].get(r['Starting'], 99),\n",
    "        orders['Ending'].get(r['Ending'], 99),\n",
    "        orders['Trend'].get(r['Trend'], 99),\n",
    "        r.get('MeanStart', 0)\n",
    "    ), axis=1)\n",
    "    \n",
    "    return df.sort_values('sort_key')\n",
    "\n",
    "# --- 3. ä¸»æ‰§è¡Œæµç¨‹ ---\n",
    "def process_and_lock_strict():\n",
    "    print(\"ğŸš€ å¼€å§‹æ‰§è¡Œï¼šç”Ÿæˆæ•°æ® -> å…¨é‡æ’åº -> é”å®š ID\")\n",
    "    \n",
    "    all_records = []\n",
    "    \n",
    "    # === æ­¥éª¤ A: ç”Ÿæˆæ‰€æœ‰æ•°æ® (æ¨¡æ‹Ÿ Cell 12 çš„å†™å…¥è¿‡ç¨‹) ===\n",
    "    tasks = [\n",
    "        (\"3-1-L2_Policy_Clustering_Breadth.csv\", \"Breadth\", False),\n",
    "        (\"3-1-L2_Policy_Clustering_Intensity.csv\", \"Intensity\", True)\n",
    "    ]\n",
    "\n",
    "    for fname, m_type, is_intensity in tasks:\n",
    "        fpath = DATA_DIR / fname\n",
    "        if not fpath.exists():\n",
    "            print(f\"âš ï¸ è·³è¿‡æ–‡ä»¶: {fname}\")\n",
    "            continue\n",
    "\n",
    "        df_raw = pd.read_csv(fpath, encoding='utf-8-sig')\n",
    "        \n",
    "        # ä¸¥æ ¼æŒ‰ç…§ Cell 12 çš„å¾ªç¯é¡ºåºç”Ÿæˆè®°å½•\n",
    "        for l2 in df_raw['L2æ”¿ç­–ä¸­æ–‡å'].dropna().unique():\n",
    "            l2_data = df_raw[df_raw['L2æ”¿ç­–ä¸­æ–‡å'] == l2]\n",
    "            feats_map = calculate_cluster_metrics(l2_data, is_intensity)\n",
    "            \n",
    "            # æ¨¡æ‹Ÿ Cell 12 çš„ iterrows å±•å¼€\n",
    "            for _, row in l2_data.iterrows():\n",
    "                cid = row['èšç±»ID']\n",
    "                if cid in feats_map:\n",
    "                    f = feats_map[cid]\n",
    "                    all_records.append({\n",
    "                        'L2æ”¿ç­–ä¸­æ–‡å': l2,\n",
    "                        'å›½å®¶': row['å›½å®¶'],\n",
    "                        'èšç±»ID': cid,\n",
    "                        'Starting': f['Starting'],\n",
    "                        'Trend': f['Trend'],\n",
    "                        'Ending': f['Ending'],\n",
    "                        'MeanStart': f['MeanStart'],\n",
    "                        'Type': m_type\n",
    "                    })\n",
    "\n",
    "    if not all_records:\n",
    "        print(\"âŒ æ²¡æœ‰ç”Ÿæˆä»»ä½•æ•°æ®\")\n",
    "        return\n",
    "\n",
    "    # === æ­¥éª¤ B: æ„å»º DataFrame å¹¶å»é‡ (æ¨¡æ‹Ÿ Cell 12 çš„è¾“å‡º) ===\n",
    "    df_full = pd.DataFrame(all_records).drop_duplicates(subset=['L2æ”¿ç­–ä¸­æ–‡å', 'å›½å®¶', 'Type'])\n",
    "    \n",
    "    # ä¿å­˜ CSV (è¿™æ˜¯ Cell 3 è¯»å–çš„å¯¹è±¡)\n",
    "    df_full.to_csv(OUTPUT_CSV, index=False, encoding='utf-8-sig')\n",
    "    print(f\"âœ… CSV å·²ä¿å­˜: {OUTPUT_CSV.name}\")\n",
    "\n",
    "    # === æ­¥éª¤ C: æ¨¡æ‹Ÿ Cell 3 çš„è¯»å–å’Œæ’åºè¿‡ç¨‹ ===\n",
    "    # ä¸ºäº†ç»å¯¹ä¸¥è°¨ï¼Œæˆ‘ä»¬ç›´æ¥å¯¹ df_full è¿›è¡Œæ“ä½œï¼Œå°±åƒ Cell 3 è¯»è¿›æ¥ä¸€æ ·\n",
    "    order_map = {}\n",
    "    \n",
    "    # 1. ç­›é€‰ metric (Cell 3 æ˜¯åˆ†å¼€è·‘çš„ï¼Œè¿™é‡Œæˆ‘ä»¬å¾ªç¯è·‘)\n",
    "    for m_type in ['Breadth', 'Intensity']:\n",
    "        df_metric = df_full[df_full['Type'] == m_type].copy()\n",
    "        if df_metric.empty: continue\n",
    "        \n",
    "        # 2. å…¨é‡æ’åº (Cell 3 çš„å…³é”®æ­¥éª¤: sort_clusters(df_meta))\n",
    "        # è¿™ä¼šæ ¹æ® Starting/Ending ç­‰å¯¹æ•´ä¸ªè¡¨æ’åº\n",
    "        df_metric_sorted = sort_clusters_original_logic(df_metric)\n",
    "        \n",
    "        # 3. å¾ªç¯ L2 æå– ID (Cell 3 çš„ç»˜å›¾å¾ªç¯)\n",
    "        for l2 in df_metric_sorted['L2æ”¿ç­–ä¸­æ–‡å'].unique():\n",
    "            # æå–è¯¥ L2 ä¸‹çš„æ‰€æœ‰è¡Œ\n",
    "            l2_sort_info = df_metric_sorted[df_metric_sorted['L2æ”¿ç­–ä¸­æ–‡å'] == l2]\n",
    "            \n",
    "            # Cell 3 é‡Œçš„é€»è¾‘: l2_sort_info.sort_values('sort_key')['èšç±»ID'].unique()\n",
    "            # è™½ç„¶ df_metric_sorted å·²ç»æ˜¯æ’å¥½åºçš„ï¼Œä½† Cell 3 é‡Œä¸ºäº†ä¿é™©åˆ sort äº†ä¸€æ¬¡\n",
    "            # æˆ‘ä»¬è¿™é‡Œä¹Ÿç…§åšï¼Œç¡®ä¿è¡Œä¸ºä¸€è‡´\n",
    "            final_sorted_df = sort_clusters_original_logic(l2_sort_info)\n",
    "            sorted_ids = final_sorted_df['èšç±»ID'].unique().tolist()\n",
    "            \n",
    "            order_map[f\"{m_type}_{l2}\"] = sorted_ids\n",
    "\n",
    "    # === æ­¥éª¤ D: é”å®š JSON ===\n",
    "    with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:\n",
    "        json.dump(order_map, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"âœ… é¡ºåºå·²ä¸¥æ ¼é”å®šè‡³ JSON: {OUTPUT_JSON.name}\")\n",
    "\n",
    "# è¿è¡Œ\n",
    "process_and_lock_strict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1cd8c2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> å¼€å§‹ç»˜å›¾: Breadth\n",
      "  -> Saved: Buildings_â€“_market-based_instruments_Breadth_Sorted.png\n",
      "  -> Saved: Buildings_â€“_non_market-based_instruments_Breadth_Sorted.png\n",
      "  -> Saved: Climate_governance_Breadth_Sorted.png\n",
      "  -> Saved: Electricity_â€“_market-based_instruments_Breadth_Sorted.png\n",
      "  -> Saved: Electricity_â€“_non_market-based_instruments_Breadth_Sorted.png\n",
      "  -> Saved: Fossil_fuel_production_policies_Breadth_Sorted.png\n",
      "  -> Saved: GHG_emissions_data_and_reporting_Breadth_Sorted.png\n",
      "  -> Saved: GHG_emissions_targets_Breadth_Sorted.png\n",
      "  -> Saved: Industry_â€“_market-based_instruments_Breadth_Sorted.png\n",
      "  -> Saved: Industry_â€“_non_market-based_instruments_Breadth_Sorted.png\n",
      "  -> Saved: International_climate_co-operation_Breadth_Sorted.png\n",
      "  -> Saved: International_public_finance_Breadth_Sorted.png\n",
      "  -> Saved: Public_Research,_Development_and_Demonstration_Breadth_Sorted.png\n",
      "  -> Saved: Transport_â€“_market-based_instruments_Breadth_Sorted.png\n",
      "  -> Saved: Transport_â€“_non_market-based_instruments_Breadth_Sorted.png\n",
      "\n",
      ">>> å¼€å§‹ç»˜å›¾: Intensity\n",
      "  -> Saved: Buildings_â€“_market-based_instruments_Intensity_Sorted.png\n",
      "  -> Saved: Buildings_â€“_non_market-based_instruments_Intensity_Sorted.png\n",
      "  -> Saved: Climate_governance_Intensity_Sorted.png\n",
      "  -> Saved: Electricity_â€“_market-based_instruments_Intensity_Sorted.png\n",
      "  -> Saved: Electricity_â€“_non_market-based_instruments_Intensity_Sorted.png\n",
      "  -> Saved: Fossil_fuel_production_policies_Intensity_Sorted.png\n",
      "  -> Saved: GHG_emissions_data_and_reporting_Intensity_Sorted.png\n",
      "  -> Saved: GHG_emissions_targets_Intensity_Sorted.png\n",
      "  -> Saved: Industry_â€“_market-based_instruments_Intensity_Sorted.png\n",
      "  -> Saved: Industry_â€“_non_market-based_instruments_Intensity_Sorted.png\n",
      "  -> Saved: International_climate_co-operation_Intensity_Sorted.png\n",
      "  -> Saved: International_public_finance_Intensity_Sorted.png\n",
      "  -> Saved: Public_Research,_Development_and_Demonstration_Intensity_Sorted.png\n",
      "  -> Saved: Transport_â€“_market-based_instruments_Intensity_Sorted.png\n",
      "  -> Saved: Transport_â€“_non_market-based_instruments_Intensity_Sorted.png\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 2: è¯»å– JSON é¡ºåºç»˜å›¾\n",
    "# ==========================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.ticker import MaxNLocator, MultipleLocator\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "\n",
    "# --- åŸºç¡€é…ç½® ---\n",
    "BASE_DIR = Path.cwd().parent\n",
    "DATA_DIR = BASE_DIR / \"data\" if (BASE_DIR / \"data\").exists() else Path.cwd() / \"data\"\n",
    "ORDER_FILE = DATA_DIR / \"fixed_ppt_order.json\"\n",
    "FEATURE_FILE = DATA_DIR / \"3-2-Automated_Recognition_Mode.csv\"\n",
    "OUTPUT_DIR = DATA_DIR / \"3-1-(3-2)Sorted_L2_Policy_Clustering_pic\"\n",
    "\n",
    "# --- æ ·å¼è®¾ç½® ---\n",
    "def setup_mpl_single2():\n",
    "    mpl.rc('font', size=25)\n",
    "    mpl.rcParams.update({\n",
    "        'legend.fontsize': 'small', 'xtick.labelsize': 'small', 'ytick.labelsize': 'small',\n",
    "        'lines.linewidth': 2, 'axes.linewidth': 2, 'xtick.major.pad': '12', 'ytick.major.pad': '12',\n",
    "        'xtick.direction': 'in', 'ytick.direction': 'in', 'xtick.top': False, 'ytick.right': False,\n",
    "        'mathtext.default': 'regular', 'axes.titlesize': 'small'\n",
    "    })\n",
    "setup_mpl_single2()\n",
    "\n",
    "NATURE_COLORS = [\n",
    "    '#E64B35', \"#6917C2\", '#00A087', '#3C5488', '#F39B7F', \n",
    "    '#8491B4', '#91D1C2', '#DC0000', '#7E6148', '#B09C85', \n",
    "    '#E18727', '#20854E', '#0072B5', '#BC3C29', '#6F99AD'\n",
    "]\n",
    "\n",
    "def lighten_color(color, amount=0.7):\n",
    "    try:\n",
    "        c = mcolors.to_rgb(color)\n",
    "        return tuple([c[i] + (1 - c[i]) * amount for i in range(3)])\n",
    "    except: return (0.5, 0.5, 0.5)\n",
    "\n",
    "# --- ç»˜å›¾æ ¸å¿ƒ ---\n",
    "def plot_fixed_order(l2_name, df_data, df_feats, sorted_ids, metric_label):\n",
    "    # æ•°æ®å‡†å¤‡\n",
    "    df_plot = df_data[(df_data['å¹´ä»½'] >= 2005) & (df_data['å¹´ä»½'] <= 2023)]\n",
    "    years = sorted(df_plot['å¹´ä»½'].unique())\n",
    "    matrix = df_plot.pivot(index='å¹´ä»½', columns='å›½å®¶', values='å æ¯”').reindex(years)\n",
    "    overall_mean = matrix.mean(axis=1)\n",
    "    y_max = matrix.max().max() * 1.15\n",
    "\n",
    "    # ç”»å¸ƒè®¾ç½®\n",
    "    n_clusters = len(sorted_ids)\n",
    "    n_cols, n_rows = 3, (n_clusters + 2) // 3\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 3.5 * n_rows), squeeze=False)\n",
    "    \n",
    "    # --- ä¸¥æ ¼æŒ‰ç…§ JSON ç»™å®šçš„ ID é¡ºåºå¾ªç¯ ---\n",
    "    for idx, cid in enumerate(sorted_ids):\n",
    "        ax = axes[idx // n_cols, idx % n_cols]\n",
    "        \n",
    "        # æ‰¾å¯¹åº”çš„å›½å®¶\n",
    "        countries = [c for c in df_plot[df_plot['èšç±»ID'] == cid]['å›½å®¶'].unique() if c in matrix.columns]\n",
    "        if not countries: continue\n",
    "\n",
    "        # æ‰¾æ ‡é¢˜ (ä»ç‰¹å¾æ–‡ä»¶é‡Œè¯»)\n",
    "        feat_row = df_feats[(df_feats['L2æ”¿ç­–ä¸­æ–‡å'] == l2_name) & (df_feats['èšç±»ID'] == cid)]\n",
    "        if not feat_row.empty:\n",
    "            r = feat_row.iloc[0]\n",
    "            title_str = f\"{r['Starting']}+{r['Trend']}+{str(r['Ending']).replace(' Share', '')}\"\n",
    "        else:\n",
    "            title_str = f\"Cluster {cid}\"\n",
    "\n",
    "        # ç»˜å›¾æ“ä½œ\n",
    "        color = NATURE_COLORS[idx % len(NATURE_COLORS)] # é¢œè‰²åªè·Ÿé¡ºåºæœ‰å…³\n",
    "        fill_color = lighten_color(color, 0.7)\n",
    "        sub_matrix = matrix[countries]\n",
    "        c_mean = sub_matrix.mean(axis=1)\n",
    "\n",
    "        ax.plot(sub_matrix.index, sub_matrix.values, color=color, alpha=0.25, lw=1.2, zorder=1)\n",
    "        ax.plot(c_mean.index, c_mean, marker='o', color=color, lw=2.5, ms=7,\n",
    "                mfc=fill_color, mec=color, mew=1.8, label='Cluster Average',\n",
    "                markevery=max(1, len(years)//10), zorder=10)\n",
    "        ax.plot(overall_mean.index, overall_mean, color='#000000', ls='--', lw=2.5,\n",
    "                label='Overall Average', alpha=0.85, zorder=9, dashes=(3, 2))\n",
    "\n",
    "        ax.set_title(f\"{title_str}\\n({len(countries)} countries)\", pad=15, ha='center')\n",
    "        ax.set_ylim(bottom=-(y_max * 0.04), top=y_max)\n",
    "        ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(nbins=6))\n",
    "        ax.tick_params(axis='x', rotation=90, labelsize=15, pad=5.5)\n",
    "        \n",
    "        if idx % n_cols == 0: ax.set_ylabel(metric_label)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.legend(loc='best', frameon=False, fontsize=12)\n",
    "\n",
    "    # æ¸…ç†å¤šä½™å­å›¾\n",
    "    for j in range(n_clusters, n_rows * n_cols): axes[j // n_cols, j % n_cols].axis('off')\n",
    "    plt.subplots_adjust(wspace=0.25, top=0.85, bottom=0.15, hspace=0.45)\n",
    "    \n",
    "    # ä¿å­˜\n",
    "    safe_name = l2_name.replace(\"/\", \"_\").replace(\" \", \"_\").replace(\":\", \"\")\n",
    "    out_dir_m = OUTPUT_DIR / f\"Plots_{metric_label}\"\n",
    "    out_dir_m.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = out_dir_m / f\"{safe_name}_{metric_label}_Sorted.png\"\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()\n",
    "    print(f\"  -> Saved: {out_path.name}\")\n",
    "\n",
    "# --- ä¸»æ‰§è¡Œ ---\n",
    "def main_plot(fname, m_label):\n",
    "    print(f\"\\n>>> å¼€å§‹ç»˜å›¾: {m_label}\")\n",
    "    if not ORDER_FILE.exists() or not FEATURE_FILE.exists():\n",
    "        print(\"âŒ è¯·å…ˆè¿è¡Œ Cell 1\")\n",
    "        return\n",
    "        \n",
    "    with open(ORDER_FILE, 'r', encoding='utf-8') as f:\n",
    "        order_map = json.load(f)\n",
    "    df_feats = pd.read_csv(FEATURE_FILE, encoding='utf-8-sig')\n",
    "    \n",
    "    fpath = DATA_DIR / fname\n",
    "    if not fpath.exists(): return\n",
    "    df_data = pd.read_csv(fpath, encoding='utf-8-sig')\n",
    "    \n",
    "    for l2 in df_data['L2æ”¿ç­–ä¸­æ–‡å'].dropna().unique():\n",
    "        key = f\"{m_label}_{l2}\"\n",
    "        if key in order_map:\n",
    "            plot_fixed_order(l2, df_data[df_data['L2æ”¿ç­–ä¸­æ–‡å']==l2], df_feats, order_map[key], m_label)\n",
    "\n",
    "# è¿è¡Œ\n",
    "main_plot(\"3-1-L2_Policy_Clustering_Breadth.csv\", \"Breadth\")\n",
    "main_plot(\"3-1-L2_Policy_Clustering_Intensity.csv\", \"Intensity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d6b9e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> æ­£åœ¨ç”Ÿæˆ PPT: Breadth\n",
      "âœ… PPT å·²ä¿å­˜ (15 é¡µ): Report_Breadth_Sorted.pptx\n",
      "\n",
      ">>> æ­£åœ¨ç”Ÿæˆ PPT: Intensity\n",
      "âœ… PPT å·²ä¿å­˜ (15 é¡µ): Report_Intensity_Sorted.pptx\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 3: ç”Ÿæˆ PPT (Strict Order Matching)\n",
    "# ==========================================\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "from pptx.dml.color import RGBColor\n",
    "from pptx.enum.text import PP_ALIGN\n",
    "\n",
    "# --- è·¯å¾„é…ç½® (éœ€ä¸ Cell 1 & 2 ä¿æŒä¸€è‡´) ---\n",
    "BASE_DIR = Path.cwd().parent\n",
    "DATA_DIR = BASE_DIR / \"data\" if (BASE_DIR / \"data\").exists() else Path.cwd() / \"data\"\n",
    "ORDER_FILE = DATA_DIR / \"fixed_ppt_order.json\"\n",
    "FEATURE_FILE = DATA_DIR / \"3-2-Automated_Recognition_Mode.csv\"\n",
    "IMG_BASE_DIR = DATA_DIR / \"3-1-(3-2)Sorted_L2_Policy_Clustering_pic\"\n",
    "OUTPUT_PPT_DIR = DATA_DIR / \"3-3-PPT_Reports\"\n",
    "OUTPUT_PPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- è¾…åŠ©å‡½æ•°ï¼šåˆ›å»ºè¡¨æ ¼ ---\n",
    "def create_table(slide, df_policy, sorted_ids, l2_name):\n",
    "    \"\"\"\n",
    "    åœ¨å¹»ç¯ç‰‡åº•éƒ¨åˆ›å»ºä¸€ä¸ªè¡¨æ ¼ï¼Œä¸¥æ ¼æŒ‰ç…§ sorted_ids çš„é¡ºåºæ˜¾ç¤ºç‰¹å¾\n",
    "    \"\"\"\n",
    "    # ç­›é€‰å¹¶æŒ‰ç…§ locked order æ’åºæ•°æ®\n",
    "    rows = []\n",
    "    for cid in sorted_ids:\n",
    "        # æ‰¾åˆ°å¯¹åº” Cluster çš„å…ƒæ•°æ®\n",
    "        row_data = df_policy[df_policy['èšç±»ID'] == cid]\n",
    "        if row_data.empty: continue\n",
    "        \n",
    "        # å–ç¬¬ä¸€è¡Œï¼ˆå› ä¸ºå…ƒæ•°æ®é‡Œæœ‰å¤šä¸ªå›½å®¶ï¼Œç‰¹å¾æ˜¯ä¸€æ ·çš„ï¼‰\n",
    "        r = row_data.iloc[0]\n",
    "        \n",
    "        # ç»Ÿè®¡è¯¥èšç±»ä¸‹çš„å›½å®¶æ•°é‡\n",
    "        countries = df_policy[df_policy['èšç±»ID'] == cid]['å›½å®¶'].unique()\n",
    "        country_count = len(countries)\n",
    "        country_str = \", \".join(countries)\n",
    "        if len(country_str) > 50: country_str = country_str[:47] + \"...\" # æˆªæ–­è¿‡é•¿æ–‡æœ¬\n",
    "        \n",
    "        rows.append([\n",
    "            f\"Cluster {cid}\",\n",
    "            f\"{r['Starting']} -> {r['Trend']} -> {r['Ending']}\",\n",
    "            f\"{r['MeanStart']:.3f}\",\n",
    "            f\"{country_count} ({country_str})\"\n",
    "        ])\n",
    "\n",
    "    # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œç›´æ¥è¿”å›\n",
    "    if not rows: return\n",
    "\n",
    "    # è¡¨æ ¼ä½ç½®ä¸å°ºå¯¸\n",
    "    rows_count = len(rows) + 1 # +1 for header\n",
    "    cols_count = 4\n",
    "    left = Inches(0.5)\n",
    "    top = Inches(4.5) # å›¾ç‰‡é€šå¸¸åœ¨ä¸Šæ–¹ï¼Œè¡¨æ ¼æ”¾ä¸‹é¢\n",
    "    width = Inches(9.0)\n",
    "    height = Inches(0.8)\n",
    "\n",
    "    table = slide.shapes.add_table(rows_count, cols_count, left, top, width, height).table\n",
    "\n",
    "    # è®¾ç½®åˆ—å®½\n",
    "    table.columns[0].width = Inches(1.2) # Cluster ID\n",
    "    table.columns[1].width = Inches(2.5) # Features\n",
    "    table.columns[2].width = Inches(1.2) # Mean Start\n",
    "    table.columns[3].width = Inches(4.1) # Countries\n",
    "\n",
    "    # è¡¨å¤´\n",
    "    headers = [\"ID\", \"Trajectory Features\", \"Mean Start\", \"Countries\"]\n",
    "    for i, h in enumerate(headers):\n",
    "        cell = table.cell(0, i)\n",
    "        cell.text = h\n",
    "        cell.fill.solid()\n",
    "        cell.fill.fore_color.rgb = RGBColor(220, 220, 220)\n",
    "        cell.text_frame.paragraphs[0].font.bold = True\n",
    "        cell.text_frame.paragraphs[0].font.size = Pt(10)\n",
    "\n",
    "    # å¡«å……å†…å®¹\n",
    "    for r_idx, row_content in enumerate(rows):\n",
    "        for c_idx, text in enumerate(row_content):\n",
    "            cell = table.cell(r_idx + 1, c_idx)\n",
    "            cell.text = str(text)\n",
    "            cell.text_frame.paragraphs[0].font.size = Pt(9)\n",
    "            cell.vertical_anchor = 3 # Middle\n",
    "\n",
    "# --- ä¸» PPT ç”Ÿæˆé€»è¾‘ ---\n",
    "def generate_ppt_for_metric(metric_label: str):\n",
    "    print(f\"\\n>>> æ­£åœ¨ç”Ÿæˆ PPT: {metric_label}\")\n",
    "    \n",
    "    # 1. æ£€æŸ¥æ–‡ä»¶\n",
    "    if not ORDER_FILE.exists() or not FEATURE_FILE.exists():\n",
    "        print(\"âŒ ç¼ºå°‘ JSON æˆ– CSV æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ Cell 1\")\n",
    "        return\n",
    "\n",
    "    # 2. è¯»å–æ•°æ®\n",
    "    with open(ORDER_FILE, 'r', encoding='utf-8') as f:\n",
    "        order_map = json.load(f)\n",
    "    \n",
    "    df_all_feats = pd.read_csv(FEATURE_FILE, encoding='utf-8-sig')\n",
    "    df_feats = df_all_feats[df_all_feats['Type'] == metric_label]\n",
    "\n",
    "    # 3. åˆå§‹åŒ– PPT\n",
    "    prs = Presentation()\n",
    "    \n",
    "    # è®¾ç½®å®½å± (16:9)\n",
    "    prs.slide_width = Inches(13.333)\n",
    "    prs.slide_height = Inches(7.5)\n",
    "\n",
    "    # 4. éå†æ‰€æœ‰åœ¨è¯¥ metric ä¸‹çš„æ”¿ç­–\n",
    "    #    æˆ‘ä»¬ç›´æ¥ä» DataFrame ä¸­è·å–æ”¿ç­–åˆ—è¡¨ï¼Œç¡®ä¿ä¸æ¼\n",
    "    policy_list = df_feats['L2æ”¿ç­–ä¸­æ–‡å'].unique()\n",
    "    \n",
    "    count = 0\n",
    "    for l2 in policy_list:\n",
    "        key = f\"{metric_label}_{l2}\"\n",
    "        \n",
    "        # å¦‚æœè¿™ä¸ªæ”¿ç­–ä¸åœ¨æˆ‘ä»¬çš„é”å®šåˆ—è¡¨ä¸­ï¼ˆå¯èƒ½æ˜¯æ•°æ®å¤ªå°‘è¢«è¿‡æ»¤äº†ï¼‰ï¼Œè·³è¿‡\n",
    "        if key not in order_map:\n",
    "            continue\n",
    "            \n",
    "        sorted_ids = order_map[key] # è·å–é”å®šçš„ ID é¡ºåº\n",
    "        \n",
    "        # --- æ–°å»ºå¹»ç¯ç‰‡ ---\n",
    "        slide = prs.slides.add_slide(prs.slide_layouts[6]) # ç©ºç™½å¸ƒå±€\n",
    "        \n",
    "        # --- æ ‡é¢˜ ---\n",
    "        title_box = slide.shapes.add_textbox(Inches(0.5), Inches(0.2), Inches(12), Inches(0.5))\n",
    "        tf = title_box.text_frame\n",
    "        tf.text = f\"{l2} ({metric_label})\"\n",
    "        tf.paragraphs[0].font.bold = True\n",
    "        tf.paragraphs[0].font.size = Pt(24)\n",
    "        \n",
    "        # --- æ’å…¥å›¾ç‰‡ ---\n",
    "        # å›¾ç‰‡è·¯å¾„å¿…é¡»å’Œ Cell 2 ç”Ÿæˆçš„å®Œå…¨ä¸€è‡´\n",
    "        safe_name = l2.replace(\"/\", \"_\").replace(\" \", \"_\").replace(\":\", \"\")\n",
    "        img_path = IMG_BASE_DIR / f\"Plots_{metric_label}\" / f\"{safe_name}_{metric_label}_Sorted.png\"\n",
    "        \n",
    "        if img_path.exists():\n",
    "            # æ”¾ç½®å›¾ç‰‡ (å±…ä¸­é ä¸Š)\n",
    "            # åŸå›¾å¾ˆå¤§ï¼Œæˆ‘ä»¬ç¼©å°ä¸€ç‚¹æ”¾ä¸Šé¢\n",
    "            slide.shapes.add_picture(str(img_path), Inches(0.5), Inches(0.8), width=Inches(12.3))\n",
    "        else:\n",
    "            # å¦‚æœæ²¡æ‰¾åˆ°å›¾ï¼Œæ”¾ä¸ªæç¤º\n",
    "            err_box = slide.shapes.add_textbox(Inches(4), Inches(3), Inches(5), Inches(1))\n",
    "            err_box.text_frame.text = \"Image Not Found (Check Cell 2 Output)\"\n",
    "\n",
    "        # --- æ’å…¥æ•°æ®è¡¨æ ¼ (å…³é”®ï¼šæŒ‰é”å®šé¡ºåº) ---\n",
    "        # ç­›é€‰å½“å‰æ”¿ç­–çš„æ•°æ®\n",
    "        df_policy = df_feats[df_feats['L2æ”¿ç­–ä¸­æ–‡å'] == l2]\n",
    "        create_table(slide, df_policy, sorted_ids, l2)\n",
    "        \n",
    "        count += 1\n",
    "\n",
    "    # 5. ä¿å­˜\n",
    "    output_path = OUTPUT_PPT_DIR / f\"Report_{metric_label}_Sorted.pptx\"\n",
    "    prs.save(output_path)\n",
    "    print(f\"âœ… PPT å·²ä¿å­˜ ({count} é¡µ): {output_path.name}\")\n",
    "\n",
    "# --- æ‰§è¡Œ ---\n",
    "generate_ppt_for_metric(\"Breadth\")\n",
    "generate_ppt_for_metric(\"Intensity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c332a21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ“‚ å¤„ç†æ–‡ä»¶: Analysis_Report_Breadth_Editable.pptx\n",
      "ğŸ¯ ç›®æ ‡ç±»å‹: Breadth\n",
      "ğŸ” é¡ºåºå‚ç…§: fixed_ppt_order.json\n",
      "==================================================\n",
      "âœ¨ æ–‡ä»¶å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°ã€‚\n",
      "\n",
      "==================================================\n",
      "ğŸ“‚ å¤„ç†æ–‡ä»¶: Analysis_Report_Intensity_Editable.pptx\n",
      "ğŸ¯ ç›®æ ‡ç±»å‹: Intensity\n",
      "ğŸ” é¡ºåºå‚ç…§: fixed_ppt_order.json\n",
      "==================================================\n",
      "âœ¨ æ–‡ä»¶å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°ã€‚\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pptx import Presentation\n",
    "from pathlib import Path\n",
    "from pptx.util import Inches\n",
    "from typing import List, Optional, Dict\n",
    "import re\n",
    "import json\n",
    "\n",
    "# ==========================================\n",
    "# 1. å¼ºåŠ›æ¸…æ´—å‡½æ•° (ä¿ç•™åŸé€»è¾‘)\n",
    "# ==========================================\n",
    "def normalize_title_robust(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ç»ˆææ¸…æ´—ï¼šè½¬å°å†™ã€æ›¿æ¢æ‰€æœ‰ç±»å‹æ¨ªæ ã€å»å¤šä½™ç©ºæ ¼\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str): return str(text) if text is not None else \"\"\n",
    "    text = text.replace('\\u2013', '-').replace('\\u2014', '-').replace('â€“', '-')\n",
    "    text = text.replace('\\xa0', ' ').replace('\\n', ' ')\n",
    "    text = re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "    return text\n",
    "\n",
    "def normalize_spaces(text: str) -> str:\n",
    "    \"\"\"æ¸…ç†æ–‡æœ¬æ¡†å†…å®¹ä¸­çš„ç‰¹æ®Šç©ºæ ¼\"\"\"\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "def get_slide_title(slide) -> Optional[str]:\n",
    "    \"\"\"è·å–å¹»ç¯ç‰‡æ ‡é¢˜\"\"\"\n",
    "    if slide.shapes.title and slide.shapes.title.text.strip():\n",
    "        return slide.shapes.title.text.strip()\n",
    "    \n",
    "    candidates = []\n",
    "    for shape in slide.shapes:\n",
    "        if shape.has_text_frame and shape.text_frame.text.strip():\n",
    "            candidates.append((shape.top, shape.text_frame.text.strip()))\n",
    "    \n",
    "    if candidates:\n",
    "        candidates.sort(key=lambda x: x[0])\n",
    "        if candidates[0][0] < Inches(2.0):\n",
    "            return candidates[0][1]\n",
    "    return None\n",
    "\n",
    "# ==========================================\n",
    "# 2. æ ¸å¿ƒï¼šåŠ è½½ JSON é”å®šé¡ºåº\n",
    "# ==========================================\n",
    "def load_fixed_order(json_path: Path) -> Dict[str, List[int]]:\n",
    "    if not json_path.exists():\n",
    "        print(f\"âŒ JSON é¡ºåºæ–‡ä»¶æœªæ‰¾åˆ°: {json_path}\")\n",
    "        return {}\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# ==========================================\n",
    "# 3. æ ¸å¿ƒåŒæ­¥é€»è¾‘ (åˆ©ç”¨ JSON å›å¡«)\n",
    "# ==========================================\n",
    "def sync_ppt_with_json(ppt_path: Path, csv_path: Path, json_path: Path, target_type: str) -> None:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ğŸ“‚ å¤„ç†æ–‡ä»¶: {ppt_path.name}\")\n",
    "    print(f\"ğŸ¯ ç›®æ ‡ç±»å‹: {target_type}\")\n",
    "    print(f\"ğŸ” é¡ºåºå‚ç…§: {json_path.name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    if not ppt_path.exists():\n",
    "        print(f\"âŒ PPTæ–‡ä»¶ä¸å­˜åœ¨: {ppt_path}\")\n",
    "        return\n",
    "\n",
    "    prs = Presentation(ppt_path)\n",
    "    df = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
    "    order_map = load_fixed_order(json_path)\n",
    "    \n",
    "    if not order_map:\n",
    "        print(\"âŒ æ— æ³•åŠ è½½é¡ºåºæ˜ å°„ï¼Œç»ˆæ­¢æ“ä½œã€‚\")\n",
    "        return\n",
    "    \n",
    "    # === å…³é”®1ï¼šåˆ›å»ºåŒ¹é…åˆ— ===\n",
    "    df['Match_Title'] = df['L2æ”¿ç­–ä¸­æ–‡å'].apply(normalize_title_robust)\n",
    "    \n",
    "    # åŒæ—¶ä¹ŸæŠŠ JSON çš„ key å¤„ç†ä¸€ä¸‹ï¼Œæ–¹ä¾¿æŸ¥æ‰¾\n",
    "    # JSON key æ ¼å¼: \"Breadth_PolicyName\" -> æˆ‘ä»¬å­˜ä¸€ä¸ªæ˜ å°„: clean_policy_name -> [ids]\n",
    "    json_lookup = {}\n",
    "    prefix = f\"{target_type}_\"\n",
    "    for key, ids in order_map.items():\n",
    "        if key.startswith(prefix):\n",
    "            raw_policy_name = key[len(prefix):] # å»æ‰ \"Breadth_\" å‰ç¼€\n",
    "            clean_name = normalize_title_robust(raw_policy_name)\n",
    "            json_lookup[clean_name] = ids\n",
    "\n",
    "    update_count = 0\n",
    "    \n",
    "    for slide_idx, slide in enumerate(prs.slides):\n",
    "        raw_ppt_title = get_slide_title(slide)\n",
    "        if not raw_ppt_title: continue\n",
    "        \n",
    "        # å¤„ç† PPT æ ‡é¢˜ï¼ˆæœ‰äº›æ ‡é¢˜å¯èƒ½åŒ…å«æ‹¬å·é‡Œçš„ metric typeï¼Œå»æ‰å®ƒï¼‰\n",
    "        title_pure = raw_ppt_title.replace(f\"({target_type})\", \"\").strip()\n",
    "        clean_ppt_title = normalize_title_robust(title_pure)\n",
    "        \n",
    "        # 1. æŸ¥æ‰¾ JSON é‡Œçš„é¡ºåº\n",
    "        if clean_ppt_title not in json_lookup:\n",
    "            # å°è¯•æ¨¡ç³ŠåŒ¹é… (æ¯”å¦‚ PPT æ ‡é¢˜ä¸å®Œæ•´)\n",
    "            found = False\n",
    "            for k in json_lookup.keys():\n",
    "                if k in clean_ppt_title or clean_ppt_title in k:\n",
    "                    clean_ppt_title = k\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                # print(f\"âš ï¸ [æ— é¡ºåºè®°å½•] PPTæ ‡é¢˜: '{raw_ppt_title}' - è·³è¿‡\")\n",
    "                continue\n",
    "        \n",
    "        sorted_cids = json_lookup[clean_ppt_title]\n",
    "        \n",
    "        # 2. è·å– PPT é‡Œçš„æ ‡ç­¾æ¡† (ä»å·¦åˆ°å³æ’åº)\n",
    "        # ç­›é€‰é€»è¾‘ï¼šæœ‰æ–‡æœ¬ï¼Œä¸”æ–‡æœ¬é‡ŒåŒ…å« '+' å· (ç‰¹å¾æ ‡è¯†)\n",
    "        label_shapes = [s for s in slide.shapes if s.has_text_frame and \"+\" in s.text_frame.text]\n",
    "        # æ’åºï¼šå…ˆæŒ‰ Top (è¡Œ)ï¼Œå†æŒ‰ Left (åˆ—)ã€‚å…è®¸å¤šè¡Œå¸ƒå±€ã€‚\n",
    "        # å®¹å·®ï¼šTop å·®å¼‚åœ¨ 0.5 è‹±å¯¸å†…è§†ä¸ºåŒä¸€è¡Œ\n",
    "        label_shapes.sort(key=lambda s: (int(s.top / Inches(0.5)), s.left))\n",
    "        \n",
    "        if len(label_shapes) != len(sorted_cids):\n",
    "            # è¿™ç§æƒ…å†µæ¯”è¾ƒå°‘è§ï¼Œå¯èƒ½æ˜¯ PPT è¢«äººæ‰‹åŠ¨åˆ æ”¹äº†\n",
    "            print(f\"âš ï¸ [æ•°é‡ä¸ç¬¦] {title_pure}: PPTæœ‰{len(label_shapes)}ä¸ªæ¡†, JSONè®°å½•æœ‰{len(sorted_cids)}ä¸ªèšç±»\")\n",
    "            continue\n",
    "            \n",
    "        # 3. é€ä¸€å›å¡«\n",
    "        for shape, cid in zip(label_shapes, sorted_cids):\n",
    "            raw_text = normalize_spaces(shape.text_frame.text)\n",
    "            \n",
    "            # è§£æ PPT æ–‡æœ¬å†…å®¹: \"High + Stable + Low (xx countries)\"\n",
    "            parts = raw_text.split('+')\n",
    "            if len(parts) >= 3:\n",
    "                p1 = parts[0].strip()\n",
    "                p2 = parts[1].strip()\n",
    "                p3_full = parts[2].strip()\n",
    "                \n",
    "                # å¤„ç† Ending éƒ¨åˆ†ï¼Œå»æ‰æ‹¬å·é‡Œçš„å›½å®¶æ•°\n",
    "                final_e = p3_full\n",
    "                last_paren = p3_full.rfind('(')\n",
    "                if last_paren != -1:\n",
    "                    final_e = p3_full[:last_paren].strip()\n",
    "                \n",
    "                # æ¸…æ´— \"Share\" åç¼€\n",
    "                new_s = p1.replace(' Share', '')\n",
    "                new_t = p2\n",
    "                new_e = final_e.replace(' Share', '')\n",
    "                \n",
    "                # 4. æ›´æ–° CSV\n",
    "                # å®šä½æ¡ä»¶ï¼šæ ‡å‡†åŒ–çš„æ”¿ç­–å + ç±»å‹ + èšç±»ID (è¿™ä¸ªIDæ¥è‡ª JSONï¼Œç»å¯¹å‡†ç¡®)\n",
    "                target_idx = df[(df['Match_Title'] == clean_ppt_title) & \n",
    "                                (df['Type'] == target_type) & \n",
    "                                (df['èšç±»ID'] == cid)].index\n",
    "                \n",
    "                if not target_idx.empty:\n",
    "                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°\n",
    "                    old_vals = df.loc[target_idx[0], ['Starting', 'Trend', 'Ending']].values\n",
    "                    new_vals = [new_s, new_t, new_e]\n",
    "                    \n",
    "                    if list(old_vals) != new_vals:\n",
    "                        print(f\" ğŸ”„ [æ›´æ–°] {title_pure[:15]}... (ID:{cid})\")\n",
    "                        print(f\"    æ—§: {old_vals} -> æ–°: {new_vals}\")\n",
    "                        \n",
    "                        df.loc[target_idx, 'Starting'] = new_s\n",
    "                        df.loc[target_idx, 'Trend'] = new_t\n",
    "                        df.loc[target_idx, 'Ending'] = new_e\n",
    "                        update_count += len(target_idx) # å¯èƒ½ä¸€æ¬¡æ›´æ–°å¤šè¡Œ(å¤šä¸ªå›½å®¶)\n",
    "\n",
    "    # æ¸…ç†\n",
    "    if 'Match_Title' in df.columns: del df['Match_Title']\n",
    "    \n",
    "    # ä¿å­˜\n",
    "    if update_count > 0:\n",
    "        try:\n",
    "            df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "            print(f\"âœ… ä¿å­˜æˆåŠŸï¼å…±æ›´æ–°äº† {update_count} è¡Œæ•°æ®ã€‚\")\n",
    "        except PermissionError:\n",
    "            print(\"âŒ ä¿å­˜å¤±è´¥ï¼è¯·å…ˆå…³é—­ CSV æ–‡ä»¶ï¼\")\n",
    "    else:\n",
    "        print(\"âœ¨ æ–‡ä»¶å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°ã€‚\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. ä¸»ç¨‹åº\n",
    "# ==========================================\n",
    "def main():\n",
    "    base_dir = Path.cwd().parent\n",
    "    data_dir = base_dir / \"data\" if (base_dir / \"data\").exists() else Path.cwd() / \"data\"\n",
    "    \n",
    "    # è·¯å¾„é…ç½®\n",
    "    # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ä½ çš„äººå·¥ä¿®æ”¹åçš„ PPT æ”¾åœ¨è¿™ä¸ª Human_catorgy æ–‡ä»¶å¤¹ä¸‹\n",
    "    ppt_dir = data_dir / \"3-1-(3-2)Sorted_L2_Policy_Clustering_pic\" / \"Human_catorgy\"\n",
    "    csv_file = data_dir / \"3-2-Automated_Recognition_Mode.csv\"\n",
    "    json_file = data_dir / \"fixed_ppt_order.json\"\n",
    "    \n",
    "    # 1. æ›´æ–° Breadth\n",
    "    sync_ppt_with_json(ppt_dir / \"Analysis_Report_Breadth_Editable.pptx\", csv_file, json_file, \"Breadth\")\n",
    "    \n",
    "    # 2. æ›´æ–° Intensity\n",
    "    sync_ppt_with_json(ppt_dir / \"Analysis_Report_Intensity_Editable.pptx\", csv_file, json_file, \"Intensity\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate_policy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
