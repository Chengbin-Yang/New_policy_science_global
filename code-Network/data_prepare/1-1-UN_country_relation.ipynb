{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取数据列: ccode1, ccode2, year, IdealPointDistance ...\n",
      "=== Data Hole Report (2005-2023) ===\n",
      "Total interacting pairs: 2352\n",
      "Pairs with full coverage (19 years): 2352\n",
      "Pairs with missing years (Holes): 0\n",
      "\n",
      "已保存反转归一化后的矩阵至: ../../data/1-1-norm_ideal_sim_2005_2023.csv\n",
      "ccode2       ARG       AUS       AUT       BEL       BGR\n",
      "ccode1                                                  \n",
      "ARG     0.000000  0.575784  0.740126  0.664844  0.668624\n",
      "AUS     0.575784  0.000000  0.835766  0.911048  0.907268\n",
      "AUT     0.740126  0.835766  0.000000  0.924826  0.928606\n",
      "BEL     0.664844  0.911048  0.924826  0.000000  0.982361\n",
      "BGR     0.668624  0.907268  0.928606  0.982361  0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# Configuration\n",
    "# ==========================================\n",
    "JSON_PATH = '../country_list.json'\n",
    "CSV_PATH = '../../data_origin/Country_relation_United Nations General Assembly Ideal Points/dataverse_files/AgreementScores.csv'\n",
    "OUTPUT_DIR = '../../data'\n",
    "YEAR_START, YEAR_END = 2005, 2023\n",
    "DIST_COL = 'IdealPointDistance'   \n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def check_data_holes(df: pd.DataFrame, year_range: int) -> None:\n",
    "    pair_counts = df.groupby(['ccode1', 'ccode2'])['year'].count()\n",
    "    total_pairs = len(pair_counts)\n",
    "    incomplete_pairs = pair_counts[pair_counts < year_range]\n",
    "    \n",
    "    print(f\"=== Data Hole Report ({YEAR_START}-{YEAR_END}) ===\")\n",
    "    print(f\"Total interacting pairs: {total_pairs}\")\n",
    "    print(f\"Pairs with full coverage ({year_range} years): {total_pairs - len(incomplete_pairs)}\")\n",
    "    print(f\"Pairs with missing years (Holes): {len(incomplete_pairs)}\")\n",
    "\n",
    "def build_average_matrix(df: pd.DataFrame, target_map: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Computes average distance matrix, performs internal normalization, \n",
    "    and ensures 49x49 symmetry.\n",
    "    \"\"\"\n",
    "    target_ccodes = list(target_map.keys())\n",
    "    \n",
    "    # 1. Symmetrize data\n",
    "    # [注意] 必须保留 'year' 用于后续分组\n",
    "    df_sym = pd.concat([\n",
    "        df[['ccode1', 'ccode2', 'year', DIST_COL]],\n",
    "        df.rename(columns={'ccode1': 'ccode2', 'ccode2': 'ccode1'})[['ccode1', 'ccode2', 'year', DIST_COL]]\n",
    "    ])\n",
    "    \n",
    "    # ================================================================\n",
    "    # [优化步骤] 针对每一个年份都进行归一化 (Yearly Normalization)\n",
    "    # 使用 transform 替代 apply，消除 Warning 并大幅提升速度\n",
    "    # ================================================================\n",
    "    # 1. 计算每一年的最大值和最小值 (广播回原数据维度)\n",
    "    grouped = df_sym.groupby('year')[DIST_COL]\n",
    "    min_vals = grouped.transform('min')\n",
    "    max_vals = grouped.transform('max')\n",
    "    \n",
    "    # 2. 计算分母 (Max - Min)\n",
    "    denominator = max_vals - min_vals\n",
    "    \n",
    "    # 3. 执行反向归一化: (Max - x) / (Max - Min)\n",
    "    # 使用 np.where 处理分母为 0 的极端情况 (即该年所有国家距离都相等)\n",
    "    df_sym['norm_score'] = np.where(\n",
    "        denominator == 0, \n",
    "        1.0,  # 如果 max == min，视为完全一致\n",
    "        (max_vals - df_sym[DIST_COL]) / denominator\n",
    "    )\n",
    "    # ================================================================\n",
    "    \n",
    "    # 2. Calculate mean similarity (Average over years)\n",
    "    # 计算 'norm_score' 的平均值\n",
    "    df_avg = df_sym.groupby(['ccode1', 'ccode2'])['norm_score'].mean().reset_index()\n",
    "    \n",
    "    # 3. Pivot to matrix\n",
    "    matrix = df_avg.pivot(index='ccode1', columns='ccode2', values='norm_score')\n",
    "    matrix = matrix.reindex(index=target_ccodes, columns=target_ccodes)\n",
    "    \n",
    "    # 4. Handle Diagonal\n",
    "    # 重新强制对角线为 0 (适合回归分析/排除自环)\n",
    "    np.fill_diagonal(matrix.values, 0)\n",
    "    \n",
    "    # 5. Map to ISO codes and sort\n",
    "    matrix.index = matrix.index.map(target_map)\n",
    "    matrix.columns = matrix.columns.map(target_map)\n",
    "    matrix.sort_index(axis=0, inplace=True)\n",
    "    matrix.sort_index(axis=1, inplace=True)\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "# ==========================================\n",
    "# Main Execution\n",
    "# ==========================================\n",
    "\n",
    "with open(JSON_PATH, 'r', encoding='utf-8') as f:\n",
    "    target_map = {item['cow']: item['iso'] for item in json.load(f)['countries']}\n",
    "\n",
    "print(f\"读取数据列: ccode1, ccode2, year, {DIST_COL} ...\")\n",
    "df = pd.read_csv(CSV_PATH, usecols=['ccode1', 'ccode2', 'year', DIST_COL])\n",
    "\n",
    "df = df[\n",
    "    (df['year'] >= YEAR_START) & \n",
    "    (df['year'] <= YEAR_END) & \n",
    "    (df['ccode1'].isin(target_map.keys())) & \n",
    "    (df['ccode2'].isin(target_map.keys()))\n",
    "]\n",
    "\n",
    "check_data_holes(df, year_range=(YEAR_END - YEAR_START + 1))\n",
    "\n",
    "avg_matrix = build_average_matrix(df, target_map)\n",
    "\n",
    "# 修改了文件名以体现逻辑变化\n",
    "save_path = f\"{OUTPUT_DIR}/1-1-norm_ideal_sim_{YEAR_START}_{YEAR_END}.csv\"\n",
    "avg_matrix.to_csv(save_path)\n",
    "print(f\"\\n已保存反转归一化后的矩阵至: {save_path}\")\n",
    "print(avg_matrix.iloc[:5, :5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate_policy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
