{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1811a62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Data Report (Target: 49 countries)\n",
      "Year   | GDP_Per | Populat | GHG_Tot | CO2_Tot | Coal_Re | Oil_Ren | Gas_Ren | Fuel_Ex\n",
      "------------------------------------------------------------------------------------------\n",
      "2005   |      ok |      ok |      ok |      ok |      ok |      ok |      ok |      ok\n",
      "2006   |      ok |      ok |      ok |      ok |      ok |      ok |      ok |      ok\n",
      "2007   |      ok |      ok |      ok |      ok |      ok |       1 |      ok |      ok\n",
      "2008   |      ok |      ok |      ok |      ok |      ok |       1 |      ok |      ok\n",
      "2009   |      ok |      ok |      ok |      ok |      ok |       1 |      ok |      ok\n",
      "2010   |      ok |      ok |      ok |      ok |      ok |       1 |      ok |      ok\n",
      "2011   |      ok |      ok |      ok |      ok |      ok |       1 |      ok |      ok\n",
      "2012   |      ok |      ok |      ok |      ok |      ok |       1 |      ok |      ok\n",
      "2013   |      ok |      ok |      ok |      ok |      ok |       1 |      ok |      ok\n",
      "2014   |      ok |      ok |      ok |      ok |      ok |       1 |      ok |      ok\n",
      "2015   |      ok |      ok |      ok |      ok |      ok |       1 |      ok |      ok\n",
      "2016   |      ok |      ok |      ok |      ok |      ok |       1 |      ok |      ok\n",
      "2017   |      ok |      ok |      ok |      ok |      ok |      ok |      ok |      ok\n",
      "2018   |      ok |      ok |      ok |      ok |      ok |      ok |      ok |      ok\n",
      "2019   |      ok |      ok |      ok |      ok |      ok |      ok |      ok |      ok\n",
      "2020   |      ok |      ok |      ok |      ok |      ok |      ok |      ok |       1\n",
      "2021   |      ok |      ok |      ok |      ok |      ok |      ok |      ok |       1\n",
      "2022   |      ok |      ok |      ok |      ok |      !! |      !! |      !! |       1\n",
      "2023   |      ok |      ok |      ok |      ok |      !! |      !! |      !! |       2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict\n",
    "\n",
    "# ================= 配置 =================\n",
    "OUT_FILE = \"../../data_origin/WB_RAW/WB_Raw_Data_Full_Expanded.csv\"\n",
    "JSON_PATH = \"../country_list.json\"\n",
    "START_YEAR, END_YEAR = 2005, 2023\n",
    "\n",
    "INDICATORS = {\n",
    "    \"GDP_PerCap\": \"NY.GDP.PCAP.KD\",\n",
    "    \"Population\": \"SP.POP.TOTL\",\n",
    "    \"GHG_Total\": \"EN.GHG.ALL.MT.CE.AR5\",\n",
    "    \"CO2_Total\": \"EN.GHG.CO2.MT.CE.AR5\",\n",
    "    \"Coal_Rent\": \"NY.GDP.COAL.RT.ZS\",\n",
    "    \"Oil_Rent\":  \"NY.GDP.PETR.RT.ZS\",\n",
    "    \"Gas_Rent\":  \"NY.GDP.NGAS.RT.ZS\",\n",
    "    \"Fuel_Export_Pct\": \"TX.VAL.FUEL.ZS.UN\"\n",
    "}\n",
    "\n",
    "def fetch_wb_data(json_path: str, out_file: str, indicators: Dict[str, str]) -> pd.DataFrame:\n",
    "    \"\"\"批量抓取世行数据并持久化至CSV文件\"\"\"\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        target_isos = [c['iso'] for c in json.load(f)['countries']]\n",
    "\n",
    "    batch_size = 20\n",
    "    batches = [target_isos[i:i + batch_size] for i in range(0, len(target_isos), batch_size)]\n",
    "    records = []\n",
    "\n",
    "    for name, code in indicators.items():\n",
    "        for batch in batches:\n",
    "            url = f\"http://api.worldbank.org/v2/country/{';'.join(batch)}/indicator/{code}\"\n",
    "            params = {\"date\": f\"{START_YEAR}:{END_YEAR}\", \"format\": \"json\", \"per_page\": 20000}\n",
    "            \n",
    "            # 基础重试逻辑，确保网络波动时不丢包\n",
    "            for _ in range(3):\n",
    "                try:\n",
    "                    resp = requests.get(url, params=params, timeout=30)\n",
    "                    if resp.status_code == 200:\n",
    "                        data = resp.json()\n",
    "                        if len(data) > 1 and data[1]:\n",
    "                            records.extend([{\n",
    "                                'indicator': name,\n",
    "                                'iso': e['countryiso3code'],\n",
    "                                'year': int(e['date']),\n",
    "                                'value': float(e['value'])\n",
    "                            } for e in data[1] if e['value'] is not None])\n",
    "                        break\n",
    "                except Exception:\n",
    "                    time.sleep(2)\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    if not df.empty:\n",
    "        os.makedirs(os.path.dirname(out_file), exist_ok=True)\n",
    "        df.to_csv(out_file, index=False)\n",
    "    return df\n",
    "\n",
    "def diagnose_gaps(df: pd.DataFrame, json_path: str) -> None:\n",
    "    \"\"\"扫描下载数据，识别指标与年份的缺失覆盖情况\"\"\"\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        target_isos = [c['iso'] for c in json.load(f)['countries']]\n",
    "        \n",
    "    all_years = list(range(START_YEAR, END_YEAR + 1))\n",
    "    all_inds = list(INDICATORS.keys())\n",
    "    \n",
    "    # 构建透视表并强制重索引，使完全缺失的指标也能在表中显示为“全缺”\n",
    "    pivot = df.pivot_table(index='year', columns='indicator', values='iso', aggfunc='count')\n",
    "    pivot = pivot.reindex(index=all_years, columns=all_inds)\n",
    "    \n",
    "    missing_table = len(target_isos) - pivot.fillna(0)\n",
    "    \n",
    "    # 终端可视化输出\n",
    "    print(f\"\\nMissing Data Report (Target: {len(target_isos)} countries)\")\n",
    "    headers = [h[:7] for h in all_inds]\n",
    "    print(f\"{'Year':<6} | \" + \" | \".join([f\"{h:>7}\" for h in headers]))\n",
    "    print(\"-\" * (10 + 10 * len(all_inds)))\n",
    "    \n",
    "    for year in all_years:\n",
    "        row = [(\"ok\" if m == 0 else (\"!!\" if m == len(target_isos) else str(int(m)))) \n",
    "               for m in missing_table.loc[year]]\n",
    "        print(f\"{year:<6} | \" + \" | \".join([f\"{s:>7}\" for s in row]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    raw_df = fetch_wb_data(JSON_PATH, OUT_FILE, INDICATORS)\n",
    "    diagnose_gaps(raw_df, JSON_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cab2b67",
   "metadata": {},
   "source": [
    "#### 对比填充结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "333f6f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indicator            | Mean Diff    | Max Diff     | Impact %\n",
      "-----------------------------------------------------------------\n",
      "Attr_GDP_PC          | 0.000000     | 0.000000     |    0.00%\n",
      "Attr_GHG_PC          | 0.000000     | 0.000000     |    0.00%\n",
      "Attr_Rent            | 0.000000     | 0.000000     |    0.00%\n",
      "Attr_Fuel_Ex         | 0.001020     | 0.042487     |    0.56%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ================= 配置 =================\n",
    "RAW_FILE = \"../../data_origin/WB_RAW/WB_Raw_Data_Full_Expanded.csv\"\n",
    "JSON_PATH = \"../country_list.json\"\n",
    "OUTPUT_DIR = \"../../data\"\n",
    "YEAR_START, YEAR_END = 2005, 2023\n",
    "\n",
    "def process_attributes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"提取基础指标并计算派生属性\"\"\"\n",
    "    pivot = df.pivot_table(index=['iso', 'year'], columns='indicator', values='value').reset_index()\n",
    "    if 'GHG_Total' in pivot.columns and 'Population' in pivot.columns:\n",
    "        pivot['Attr_GHG_PC'] = (pivot['GHG_Total'] * 1e6) / pivot['Population']\n",
    "    rent_cols = [c for c in ['Coal_Rent', 'Oil_Rent', 'Gas_Rent'] if c in pivot.columns]\n",
    "    pivot['Attr_Rent'] = pivot[rent_cols].fillna(0).sum(axis=1)\n",
    "    rename_map = {'GDP_PerCap': 'Attr_GDP_PC', 'Fuel_Export_Pct': 'Attr_Fuel_Ex'}\n",
    "    return pivot.rename(columns={k: v for k, v in rename_map.items() if k in pivot.columns})\n",
    "\n",
    "def calc_matrix(wide_df: pd.DataFrame, iso_list: List[str], use_nanmean: bool = False) -> np.ndarray:\n",
    "    \"\"\"内部函数：执行年度归一化并计算均值矩阵\"\"\"\n",
    "    yearly_mats = []\n",
    "    for year in range(YEAR_START, YEAR_END + 1):\n",
    "        if year not in wide_df.index: continue\n",
    "        v = wide_df.loc[year].values\n",
    "        # 计算绝对差 |A - B|，若含NaN则结果为NaN\n",
    "        diff = np.abs(v.reshape(-1, 1) - v)\n",
    "        d_min, d_max = np.nanmin(diff), np.nanmax(diff)\n",
    "        norm = (diff - d_min) / (d_max - d_min) if d_max > d_min else np.zeros_like(diff)\n",
    "        yearly_mats.append(norm)\n",
    "    \n",
    "    # 根据参数选择：忽略NaN取平均（剔除逻辑）或直接取平均（填充逻辑）\n",
    "    avg_mat = np.nanmean(yearly_mats, axis=0) if use_nanmean else np.mean(yearly_mats, axis=0)\n",
    "    np.fill_diagonal(avg_mat, 0)\n",
    "    return avg_mat\n",
    "\n",
    "def run_comparison_pipeline(df: pd.DataFrame, iso_list: List[str], output_dir: str) -> None:\n",
    "    \"\"\"生成矩阵并对比填充数据与原始数据的不确定性差异\"\"\"\n",
    "    tasks = [(\"1-6-1-GDP_Diff\", \"Attr_GDP_PC\"), (\"1-6-2-GHG_Diff\", \"Attr_GHG_PC\"), \n",
    "             (\"1-6-3-Rent_Diff\", \"Attr_Rent\"), (\"1-6-4-Fuel_Ex_Diff\", \"Attr_Fuel_Ex\")]\n",
    "\n",
    "    print(f\"{'Indicator':<20} | {'Mean Diff':<12} | {'Max Diff':<12} | {'Impact %'}\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "    for filename, col in tasks:\n",
    "        if col not in df.columns: continue\n",
    "        \n",
    "        # 宽表准备\n",
    "        wide_raw = df.pivot(index='year', columns='iso', values=col).reindex(columns=iso_list)\n",
    "        \n",
    "        # 1. 填充模式：执行 ffill 补齐滞后年份\n",
    "        wide_filled = wide_raw.ffill(limit=3).fillna(0)\n",
    "        mat_filled = calc_matrix(wide_filled, iso_list, use_nanmean=False)\n",
    "        \n",
    "        # 2. 剔除模式：不填充，直接计算含 NaN 的矩阵并用 nanmean 跨年平均\n",
    "        mat_skipped = calc_matrix(wide_raw, iso_list, use_nanmean=True)\n",
    "        \n",
    "        # 3. 差异评估\n",
    "        abs_error = np.abs(mat_filled - mat_skipped)\n",
    "        mean_err, max_err = np.mean(abs_error), np.max(abs_error)\n",
    "        # 影响百分比：差异占总平均水平的比例\n",
    "        impact = (mean_err / np.mean(mat_filled) * 100) if np.mean(mat_filled) > 0 else 0\n",
    "        \n",
    "        print(f\"{col:<20} | {mean_err:<12.6f} | {max_err:<12.6f} | {impact:>7.2f}%\")\n",
    "\n",
    "        # 4. 保存最终矩阵（使用填充后的版本）\n",
    "        res_df = pd.DataFrame(mat_filled, index=iso_list, columns=iso_list).sort_index(axis=0).sort_index(axis=1)\n",
    "        res_df.to_csv(os.path.join(output_dir, f\"{filename}.csv\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    with open(JSON_PATH, 'r', encoding='utf-8') as f:\n",
    "        target_isos = [c['iso'] for c in json.load(f)['countries']]\n",
    "    \n",
    "    attr_data = process_attributes(pd.read_csv(RAW_FILE))\n",
    "    run_comparison_pipeline(attr_data, target_isos, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0196dfb2",
   "metadata": {},
   "source": [
    "#### 直接计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c203690",
   "metadata": {},
   "source": [
    "##### 新的，减一搞的相似度（启用版）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d497d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已生成相似度矩阵: 1-6-1-GDP_Sim.csv\n",
      "已生成相似度矩阵: 1-6-2-GHG_Sim.csv\n",
      "已生成相似度矩阵: 1-6-3-Rent_Sim.csv\n",
      "已生成相似度矩阵: 1-6-4-Fuel_Ex_Sim.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "# ================= 配置 =================\n",
    "RAW_FILE = \"../../data_origin/WB_RAW/WB_Raw_Data_Full_Expanded.csv\"\n",
    "JSON_PATH = \"../country_list.json\"\n",
    "OUTPUT_DIR = \"../../data\"\n",
    "YEAR_START, YEAR_END = 2005, 2023\n",
    "\n",
    "def process_attributes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"提取基础指标并计算派生属性（人均排放与总租金）\"\"\"\n",
    "    pivot = df.pivot_table(index=['iso', 'year'], columns='indicator', values='value').reset_index()\n",
    "    \n",
    "    # 计算人均温室气体 (吨/人)\n",
    "    if 'GHG_Total' in pivot.columns and 'Population' in pivot.columns:\n",
    "        pivot['Attr_GHG_PC'] = (pivot['GHG_Total'] * 1e6) / pivot['Population']\n",
    "    \n",
    "    # 计算化石能源总租金\n",
    "    rent_cols = [c for c in ['Coal_Rent', 'Oil_Rent', 'Gas_Rent'] if c in pivot.columns]\n",
    "    pivot['Attr_Rent'] = pivot[rent_cols].fillna(0).sum(axis=1)\n",
    "    \n",
    "    # 统一列名映射\n",
    "    rename_map = {'GDP_PerCap': 'Attr_GDP_PC', 'Fuel_Export_Pct': 'Attr_Fuel_Ex'}\n",
    "    return pivot.rename(columns={k: v for k, v in rename_map.items() if k in pivot.columns})\n",
    "\n",
    "def generate_average_sim_matrices(df: pd.DataFrame, iso_list: List[str], output_dir: str) -> None:\n",
    "    \"\"\"生成经过年度归一化处理的历年平均【相似度】矩阵\"\"\"\n",
    "    \n",
    "    # 1. 【修改点】文件名后缀改为 _Sim (Sim = Similarity)\n",
    "    tasks = [\n",
    "        (\"1-6-1-GDP_Sim\",     \"Attr_GDP_PC\"),\n",
    "        (\"1-6-2-GHG_Sim\",     \"Attr_GHG_PC\"),\n",
    "        (\"1-6-3-Rent_Sim\",    \"Attr_Rent\"),\n",
    "        (\"1-6-4-Fuel_Ex_Sim\", \"Attr_Fuel_Ex\")\n",
    "    ]\n",
    "\n",
    "    for filename, attr_col in tasks:\n",
    "        if attr_col not in df.columns: continue\n",
    "\n",
    "        # 宽表化\n",
    "        wide = df.pivot(index='year', columns='iso', values=attr_col).reindex(columns=iso_list)\n",
    "        wide = wide.ffill(limit=3).fillna(0)\n",
    "\n",
    "        yearly_normalized_mats = []\n",
    "        for year in range(YEAR_START, YEAR_END + 1):\n",
    "            if year not in wide.index: continue\n",
    "            \n",
    "            vals = wide.loc[year].values\n",
    "            # 计算绝对差异矩阵 |A_i - A_j|\n",
    "            diff_matrix = np.abs(vals.reshape(-1, 1) - vals)\n",
    "            \n",
    "            # 执行年度内 Min-Max 归一化 (0=差异最小, 1=差异最大)\n",
    "            d_min, d_max = diff_matrix.min(), diff_matrix.max()\n",
    "            norm_diff = (diff_matrix - d_min) / (d_max - d_min) if d_max > d_min else np.zeros_like(diff_matrix)\n",
    "            \n",
    "            # 2. 【核心修改】转换为相似度：Sim = 1 - Norm_Diff\n",
    "            # 这样 1 就代表\"完全相同\"（差异最小），0 代表\"最不相同\"\n",
    "            norm_sim = 1 - norm_diff\n",
    "            \n",
    "            yearly_normalized_mats.append(norm_sim)\n",
    "\n",
    "        if yearly_normalized_mats:\n",
    "            # 计算历年平均值\n",
    "            avg_matrix = np.mean(yearly_normalized_mats, axis=0)\n",
    "            \n",
    "            # 3. 【对角线修改】相似度矩阵的对角线强制 0，因为是网络分析中不考虑自环\n",
    "            np.fill_diagonal(avg_matrix, 0)\n",
    "            \n",
    "            # 保存\n",
    "            res_df = pd.DataFrame(avg_matrix, index=iso_list, columns=iso_list)\n",
    "            res_df = res_df.sort_index(axis=0).sort_index(axis=1)\n",
    "            res_df.to_csv(os.path.join(output_dir, f\"{filename}.csv\"))\n",
    "            print(f\"已生成相似度矩阵: {filename}.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    with open(JSON_PATH, 'r', encoding='utf-8') as f:\n",
    "        target_isos = [c['iso'] for c in json.load(f)['countries']]\n",
    "\n",
    "    attr_data = process_attributes(pd.read_csv(RAW_FILE))\n",
    "    # 调用新的生成函数\n",
    "    generate_average_sim_matrices(attr_data, target_isos, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7f1110",
   "metadata": {},
   "source": [
    "##### 旧版本的差异度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4292943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "# ================= 配置 =================\n",
    "RAW_FILE = \"../../data_origin/WB_RAW/WB_Raw_Data_Full_Expanded.csv\"\n",
    "JSON_PATH = \"../country_list.json\"\n",
    "OUTPUT_DIR = \"../../data\"\n",
    "YEAR_START, YEAR_END = 2005, 2023\n",
    "\n",
    "def process_attributes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"提取基础指标并计算派生属性（人均排放与总租金）\"\"\"\n",
    "    pivot = df.pivot_table(index=['iso', 'year'], columns='indicator', values='value').reset_index()\n",
    "    \n",
    "    # 计算人均温室气体 (吨/人): (Mt * 1e6) / Population\n",
    "    if 'GHG_Total' in pivot.columns and 'Population' in pivot.columns:\n",
    "        pivot['Attr_GHG_PC'] = (pivot['GHG_Total'] * 1e6) / pivot['Population']\n",
    "    \n",
    "    # 计算化石能源总租金 (Coal + Oil + Gas)\n",
    "    rent_cols = [c for c in ['Coal_Rent', 'Oil_Rent', 'Gas_Rent'] if c in pivot.columns]\n",
    "    pivot['Attr_Rent'] = pivot[rent_cols].fillna(0).sum(axis=1)\n",
    "    \n",
    "    # 统一列名映射\n",
    "    rename_map = {'GDP_PerCap': 'Attr_GDP_PC', 'Fuel_Export_Pct': 'Attr_Fuel_Ex'}\n",
    "    return pivot.rename(columns={k: v for k, v in rename_map.items() if k in pivot.columns})\n",
    "\n",
    "def generate_average_diff_matrices(df: pd.DataFrame, iso_list: List[str], output_dir: str) -> None:\n",
    "    \"\"\"生成经过年度归一化处理的历年平均差异矩阵\"\"\"\n",
    "    # 定义任务序列：(文件名序号, 属性名)\n",
    "    tasks = [\n",
    "        (\"1-6-1-GDP_Diff\",     \"Attr_GDP_PC\"),\n",
    "        (\"1-6-2-GHG_Diff\",     \"Attr_GHG_PC\"),\n",
    "        (\"1-6-3-Rent_Diff\",    \"Attr_Rent\"),\n",
    "        (\"1-6-4-Fuel_Ex_Diff\", \"Attr_Fuel_Ex\")\n",
    "    ]\n",
    "\n",
    "    for filename, attr_col in tasks:\n",
    "        if attr_col not in df.columns: continue\n",
    "\n",
    "        # 宽表化：处理滞后年份缺口 (ffill) 并重置国家索引\n",
    "        wide = df.pivot(index='year', columns='iso', values=attr_col).reindex(columns=iso_list)\n",
    "        wide = wide.ffill(limit=3).fillna(0)\n",
    "\n",
    "        yearly_normalized_mats = []\n",
    "        for year in range(YEAR_START, YEAR_END + 1):\n",
    "            if year not in wide.index: continue\n",
    "            \n",
    "            vals = wide.loc[year].values\n",
    "            # 计算绝对差异矩阵 |A_i - A_j|\n",
    "            diff_matrix = np.abs(vals.reshape(-1, 1) - vals)\n",
    "            \n",
    "            # 执行年度内 Min-Max 归一化 (防止量级大的年份主导权重)\n",
    "            d_min, d_max = diff_matrix.min(), diff_matrix.max()\n",
    "            norm_matrix = (diff_matrix - d_min) / (d_max - d_min) if d_max > d_min else np.zeros_like(diff_matrix)\n",
    "            yearly_normalized_mats.append(norm_matrix)\n",
    "\n",
    "        if yearly_normalized_mats:\n",
    "            # 计算历年平均值并强制对角线为 0 (自反性)\n",
    "            avg_matrix = np.mean(yearly_normalized_mats, axis=0)\n",
    "            np.fill_diagonal(avg_matrix, 0)\n",
    "            \n",
    "            # 构建 DataFrame 并严格排序索引确保矩阵对齐\n",
    "            res_df = pd.DataFrame(avg_matrix, index=iso_list, columns=iso_list)\n",
    "            res_df = res_df.sort_index(axis=0).sort_index(axis=1)\n",
    "            res_df.to_csv(os.path.join(output_dir, f\"{filename}.csv\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    with open(JSON_PATH, 'r', encoding='utf-8') as f:\n",
    "        target_isos = [c['iso'] for c in json.load(f)['countries']]\n",
    "\n",
    "    attr_data = process_attributes(pd.read_csv(RAW_FILE))\n",
    "    generate_average_diff_matrices(attr_data, target_isos, OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate_policy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
