{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0675d48b",
   "metadata": {},
   "source": [
    "#### 取对数（启用版）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d385fc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理 AeroSCOPE 航空连接数据...\n",
      "处理完成！归一化矩阵已保存至: ../../data/1-5-AeroSCOPE_Flight_Intensity.csv\n",
      "矩阵维度: (49, 49)\n",
      "前5行预览：\n",
      "arrival_country    ARG  AUS       AUT       BEL       BGR\n",
      "departure_country                                        \n",
      "ARG                0.0  0.0  0.000000  0.000000  0.000000\n",
      "AUS                0.0  0.0  0.000000  0.000000  0.000000\n",
      "AUT                0.0  0.0  0.000000  0.680557  0.671199\n",
      "BEL                0.0  0.0  0.680557  0.000000  0.608910\n",
      "BGR                0.0  0.0  0.671199  0.608910  0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 路径配置\n",
    "# 数据来源：AeroSCOPE 2019 原始 CSV\n",
    "AEROSCOPE_PATH = \"../../data_origin/AeroSCOPE_Flights/AeroSCOPE_global_aviation_traffic_dataset_16_11.csv\"\n",
    "# 国家列表（你的 49 国子集，已包含 iso_2 字段）\n",
    "JSON_PATH = \"../country_list.json\"\n",
    "# 输出路径\n",
    "OUT_FILE = \"../../data/1-5-AeroSCOPE_Flight_Intensity.csv\"\n",
    "\n",
    "def get_flight_intensity_matrix(data_path: str, meta_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    基于航班频率计算归一化的国家间航空连接强度矩阵。\n",
    "    逻辑：使用 iso_2 匹配原始数据，最后输出 iso (3位) 的矩阵。\n",
    "    \"\"\"\n",
    "    # 1. 加载 49 国名单和映射\n",
    "    with open(meta_path, 'r', encoding='utf-8') as f:\n",
    "        countries = json.load(f)['countries']\n",
    "        \n",
    "        # 提取用于过滤的 2位代码 (对应 AeroSCOPE 数据)\n",
    "        # 注意：JSON 里的 iso_2 可能带有空格，建议 strip() 清理一下\n",
    "        target_iso2 = [c['iso_2'].strip() for c in countries if c.get('iso_2')]\n",
    "        \n",
    "        # 建立 2位 -> 3位 的映射字典，用于最后改名\n",
    "        # Key: 'CN', Value: 'CHN'\n",
    "        iso2_to_iso3 = {c['iso_2'].strip(): c['iso'] for c in countries if c.get('iso_2')}\n",
    "\n",
    "    # 2. 读取 AeroSCOPE 数据\n",
    "    # 只提取必要的列\n",
    "    df = pd.read_csv(data_path, usecols=['departure_country', 'arrival_country', 'n_flights', 'domestic'])\n",
    "    \n",
    "    # 3. 过滤数据\n",
    "    # 只保留 49 国之间的国际航线 (domestic == 0)\n",
    "    # 使用 iso_2 列表进行筛选\n",
    "    mask = (df['domestic'] == 0) & \\\n",
    "           (df['departure_country'].isin(target_iso2)) & \\\n",
    "           (df['arrival_country'].isin(target_iso2))\n",
    "    df = df[mask]\n",
    "    \n",
    "    # 4. 构建 OD 矩阵 (按国家聚合航班数)\n",
    "    # 此时行和列的索引是 2位代码 (如 CN, US)\n",
    "    m = df.groupby(['departure_country', 'arrival_country'])['n_flights'].sum().unstack(fill_value=0)\n",
    "    \n",
    "    # 确保矩阵是 49x49 的完整矩阵，缺失的国家填充 0\n",
    "    # 使用 target_iso2 进行重索引\n",
    "    m = m.reindex(index=target_iso2, columns=target_iso2, fill_value=0)\n",
    "    \n",
    "    # 5. 对称化处理 (无向网络：A<->B 的连接强度)\n",
    "    m = m + m.T\n",
    "    \n",
    "    # 6. 对数转换 (Log Transformation)\n",
    "    m_log = np.log1p(m)\n",
    "    \n",
    "    # 7. 0-1 归一化 (Local Normalization)\n",
    "    mask_diag = ~np.eye(len(target_iso2), dtype=bool)\n",
    "    v_min = m_log.values[mask_diag].min()\n",
    "    v_max = m_log.values[mask_diag].max()\n",
    "    \n",
    "    # 防止最大值最小值相等导致除以0\n",
    "    if v_max != v_min:\n",
    "        m_norm = (m_log - v_min) / (v_max - v_min)\n",
    "    else:\n",
    "        m_norm = m_log * 0\n",
    "\n",
    "    # 将对角线置为 0\n",
    "    np.fill_diagonal(m_norm.values, 0)\n",
    "    \n",
    "    # 8. 关键步骤：将索引从 ISO2 改回 ISO3\n",
    "    # 这样你的输出文件就是标准的 3位代码，方便和其他数据对齐\n",
    "    m_norm = m_norm.rename(index=iso2_to_iso3, columns=iso2_to_iso3)\n",
    "    \n",
    "    # 9. 按 ISO3 字母顺序排序并返回\n",
    "    return m_norm.sort_index(axis=0).sort_index(axis=1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建输出目录\n",
    "    os.makedirs(os.path.dirname(OUT_FILE), exist_ok=True)\n",
    "    \n",
    "    print(\"正在处理 AeroSCOPE 航空连接数据...\")\n",
    "    if os.path.exists(AEROSCOPE_PATH):\n",
    "        try:\n",
    "            final_res = get_flight_intensity_matrix(AEROSCOPE_PATH, JSON_PATH)\n",
    "            \n",
    "            # 保存结果\n",
    "            final_res.to_csv(OUT_FILE)\n",
    "            print(f\"处理完成！归一化矩阵已保存至: {OUT_FILE}\")\n",
    "            print(f\"矩阵维度: {final_res.shape}\")\n",
    "            print(\"前5行预览：\")\n",
    "            print(final_res.iloc[:5, :5])\n",
    "        except Exception as e:\n",
    "            print(f\"处理过程中发生错误: {e}\")\n",
    "    else:\n",
    "        print(f\"错误：找不到原始数据文件 {AEROSCOPE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66112a34",
   "metadata": {},
   "source": [
    "##### 不取对数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67776c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理 AeroSCOPE 航空连接数据...\n",
      "处理完成！归一化矩阵已保存至: ../../data/1-5-AeroSCOPE_Flight_Intensity.csv\n",
      "矩阵维度: (49, 49)\n",
      "前5行预览：\n",
      "arrival_country    ARG  AUS       AUT       BEL       BGR\n",
      "departure_country                                        \n",
      "ARG                0.0  0.0  0.000000  0.000000  0.000000\n",
      "AUS                0.0  0.0  0.000000  0.000000  0.000000\n",
      "AUT                0.0  0.0  0.000000  0.018532  0.016488\n",
      "BEL                0.0  0.0  0.018532  0.000000  0.007574\n",
      "BGR                0.0  0.0  0.016488  0.007574  0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 路径配置\n",
    "# 数据来源：AeroSCOPE 2019 原始 CSV\n",
    "AEROSCOPE_PATH = \"../../data_origin/AeroSCOPE_Flights/AeroSCOPE_global_aviation_traffic_dataset_16_11.csv\"\n",
    "# 国家列表（你的 49 国子集，已包含 iso_2 字段）\n",
    "JSON_PATH = \"../country_list.json\"\n",
    "# 输出路径\n",
    "OUT_FILE = \"../../data/1-5-AeroSCOPE_Flight_Intensity.csv\"\n",
    "\n",
    "def get_flight_intensity_matrix(data_path: str, meta_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    基于航班频率计算归一化的国家间航空连接强度矩阵。\n",
    "    逻辑：使用 iso_2 匹配原始数据，最后输出 iso (3位) 的矩阵。\n",
    "    \"\"\"\n",
    "    # 1. 加载 49 国名单和映射\n",
    "    with open(meta_path, 'r', encoding='utf-8') as f:\n",
    "        countries = json.load(f)['countries']\n",
    "        \n",
    "        # 提取用于过滤的 2位代码 (对应 AeroSCOPE 数据)\n",
    "        # 注意：JSON 里的 iso_2 可能带有空格，建议 strip() 清理一下\n",
    "        target_iso2 = [c['iso_2'].strip() for c in countries if c.get('iso_2')]\n",
    "        \n",
    "        # 建立 2位 -> 3位 的映射字典，用于最后改名\n",
    "        # Key: 'CN', Value: 'CHN'\n",
    "        iso2_to_iso3 = {c['iso_2'].strip(): c['iso'] for c in countries if c.get('iso_2')}\n",
    "\n",
    "    # 2. 读取 AeroSCOPE 数据\n",
    "    # 只提取必要的列\n",
    "    df = pd.read_csv(data_path, usecols=['departure_country', 'arrival_country', 'n_flights', 'domestic'])\n",
    "    \n",
    "    # 3. 过滤数据\n",
    "    # 只保留 49 国之间的国际航线 (domestic == 0)\n",
    "    # 使用 iso_2 列表进行筛选\n",
    "    mask = (df['domestic'] == 0) & \\\n",
    "           (df['departure_country'].isin(target_iso2)) & \\\n",
    "           (df['arrival_country'].isin(target_iso2))\n",
    "    df = df[mask]\n",
    "    \n",
    "    # 4. 构建 OD 矩阵 (按国家聚合航班数)\n",
    "    # 此时行和列的索引是 2位代码 (如 CN, US)\n",
    "    m = df.groupby(['departure_country', 'arrival_country'])['n_flights'].sum().unstack(fill_value=0)\n",
    "    \n",
    "    # 确保矩阵是 49x49 的完整矩阵，缺失的国家填充 0\n",
    "    # 使用 target_iso2 进行重索引\n",
    "    m = m.reindex(index=target_iso2, columns=target_iso2, fill_value=0)\n",
    "    \n",
    "    # 5. 对称化处理 (无向网络：A<->B 的连接强度)\n",
    "    m = m + m.T\n",
    "    \n",
    "    # 6. 对数转换 (Log Transformation)\n",
    "    # === 修改处：去掉 np.log1p ===\n",
    "    m_log = m\n",
    "    \n",
    "    # 7. 0-1 归一化 (Local Normalization)\n",
    "    mask_diag = ~np.eye(len(target_iso2), dtype=bool)\n",
    "    v_min = m_log.values[mask_diag].min()\n",
    "    v_max = m_log.values[mask_diag].max()\n",
    "    \n",
    "    # 防止最大值最小值相等导致除以0\n",
    "    if v_max != v_min:\n",
    "        m_norm = (m_log - v_min) / (v_max - v_min)\n",
    "    else:\n",
    "        m_norm = m_log * 0\n",
    "\n",
    "    # 将对角线置为 0\n",
    "    np.fill_diagonal(m_norm.values, 0)\n",
    "    \n",
    "    # 8. 关键步骤：将索引从 ISO2 改回 ISO3\n",
    "    # 这样你的输出文件就是标准的 3位代码，方便和其他数据对齐\n",
    "    m_norm = m_norm.rename(index=iso2_to_iso3, columns=iso2_to_iso3)\n",
    "    \n",
    "    # 9. 按 ISO3 字母顺序排序并返回\n",
    "    return m_norm.sort_index(axis=0).sort_index(axis=1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建输出目录\n",
    "    os.makedirs(os.path.dirname(OUT_FILE), exist_ok=True)\n",
    "    \n",
    "    print(\"正在处理 AeroSCOPE 航空连接数据...\")\n",
    "    if os.path.exists(AEROSCOPE_PATH):\n",
    "        try:\n",
    "            final_res = get_flight_intensity_matrix(AEROSCOPE_PATH, JSON_PATH)\n",
    "            \n",
    "            # 保存结果\n",
    "            final_res.to_csv(OUT_FILE)\n",
    "            print(f\"处理完成！归一化矩阵已保存至: {OUT_FILE}\")\n",
    "            print(f\"矩阵维度: {final_res.shape}\")\n",
    "            print(\"前5行预览：\")\n",
    "            print(final_res.iloc[:5, :5])\n",
    "        except Exception as e:\n",
    "            print(f\"处理过程中发生错误: {e}\")\n",
    "    else:\n",
    "        print(f\"错误：找不到原始数据文件 {AEROSCOPE_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate_policy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
