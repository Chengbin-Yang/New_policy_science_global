{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809e8e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Start Fetching | Batch Size: 15 | Path: ../../data_origin/UN-Comtrade_Trade_Fossil/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3cbe53f1f6142d1b1f2739c47fd9b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total Progress:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\28274\\AppData\\Local\\Temp\\ipykernel_23888\\2302477388.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_final = pd.concat(year_dfs, ignore_index=True)\n",
      "C:\\Users\\28274\\AppData\\Local\\Temp\\ipykernel_23888\\2302477388.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_final = pd.concat(year_dfs, ignore_index=True)\n",
      "C:\\Users\\28274\\AppData\\Local\\Temp\\ipykernel_23888\\2302477388.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_final = pd.concat(year_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, Tuple, List\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# ================= Configuration =================\n",
    "SUBSCRIPTION_KEY = \"f75479bbfce9446580b4e27e150a3608\"\n",
    "JSON_PATH = \"../country_list.json\"\n",
    "OUT_DIR = \"../../data_origin/UN-Comtrade_Trade_Fossil/\"\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "YEARS = range(2005, 2024)\n",
    "COMMODITIES = \"2701,2709,2710,2711\"\n",
    "API_URL = \"https://comtradeapi.un.org/data/v1/get/C/A/HS\"\n",
    "BATCH_SIZE = 15 \n",
    "\n",
    "# ================= Helpers =================\n",
    "def load_country_metadata(json_path: str) -> Tuple[List[str], Dict[str, str], str]:\n",
    "    \"\"\"\n",
    "    Load country metadata and generate M49 code lists and mappings.\n",
    "    \n",
    "    Returns:\n",
    "        (List of M49 codes, Dict mapping M49->ISO3, String of all M49 codes for partner query)\n",
    "    \"\"\"\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        countries = json.load(f)['countries']\n",
    "    \n",
    "    mapping = {str(c['UN_M49']): c['iso'] for c in countries}\n",
    "    m49_list = list(mapping.keys())\n",
    "    partner_str = \",\".join(m49_list)\n",
    "    \n",
    "    return m49_list, mapping, partner_str\n",
    "\n",
    "def fetch_batch(year: int, reporters: List[str], partners: str, mapping: Dict[str, str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Execute API request for a batch of reporting countries.\n",
    "    \n",
    "    Args:\n",
    "        year: Target year.\n",
    "        reporters: List of reporter M49 codes.\n",
    "        partners: String of comma-separated partner M49 codes.\n",
    "        mapping: Dictionary to map M49 codes back to ISO3.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed data or empty DataFrame on failure/no data.\n",
    "    \"\"\"\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": SUBSCRIPTION_KEY}\n",
    "    params = {\n",
    "        \"reporterCode\": \",\".join(reporters),\n",
    "        \"partnerCode\": partners,\n",
    "        \"period\": year,\n",
    "        \"cmdCode\": COMMODITIES,\n",
    "        \"flowCode\": \"M\",\n",
    "        \"customsCode\": \"C00\",\n",
    "        \"motCode\": \"0\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(API_URL, params=params, headers=headers, timeout=90)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json().get('data')\n",
    "            if data:\n",
    "                df = pd.DataFrame(data)\n",
    "                # Map M49 codes to ISO3\n",
    "                df['reporterCode'] = df['reporterCode'].astype(str)\n",
    "                df['partnerCode'] = df['partnerCode'].astype(str)\n",
    "                df['iso_i'] = df['reporterCode'].map(mapping)\n",
    "                df['iso_j'] = df['partnerCode'].map(mapping)\n",
    "                return df\n",
    "                \n",
    "    except Exception:\n",
    "        pass # Silently fail for individual batches to keep process running\n",
    "\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# ================= Main Execution =================\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"ğŸš€ Start Fetching | Batch Size: {BATCH_SIZE} | Path: {OUT_DIR}\")\n",
    "    \n",
    "    m49_list, iso_map, all_partners = load_country_metadata(JSON_PATH)\n",
    "    \n",
    "    # Create batches\n",
    "    batches = [m49_list[i:i + BATCH_SIZE] for i in range(0, len(m49_list), BATCH_SIZE)]\n",
    "    \n",
    "    pbar = tqdm(YEARS, desc=\"Total Progress\")\n",
    "    \n",
    "    for yr in pbar:\n",
    "        pbar.set_description(f\"Processing {yr}...\")\n",
    "        year_dfs = []\n",
    "        \n",
    "        for batch in batches:\n",
    "            df = fetch_batch(yr, batch, all_partners, iso_map)\n",
    "            \n",
    "            # Filter empty DFs to prevent FutureWarning in pd.concat\n",
    "            if not df.empty:\n",
    "                year_dfs.append(df)\n",
    "            \n",
    "            time.sleep(1.5) # Rate limiting\n",
    "            \n",
    "        target_file = os.path.join(OUT_DIR, f\"Comtrade_{yr}.csv\")\n",
    "        \n",
    "        if year_dfs:\n",
    "            df_final = pd.concat(year_dfs, ignore_index=True)\n",
    "            df_final.to_csv(target_file, index=False)\n",
    "        else:\n",
    "            # Create empty placeholder if no data found for the year\n",
    "            pd.DataFrame(columns=['year', 'iso_i', 'iso_j', 'value']).to_csv(target_file, index=False)\n",
    "            \n",
    "        time.sleep(2)\n",
    "\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9614db41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¯»å– 19 ä¸ªå¹´ä»½æ–‡ä»¶...\n",
      "çŸ©é˜µå·²ä¿å­˜è‡³: ../../data/1-7-Fossil_Trade_Matrix_Normalized.csv\n",
      "   çŸ©é˜µç»´åº¦: (45, 45)\n",
      "\n",
      "æœ€ç»ˆå½’ä¸€åŒ–çŸ©é˜µé¢„è§ˆ (å‰ 8 è¡Œ/åˆ—):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "iso_i",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ARG",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AUS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "AUT",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BEL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BGR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CAN",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CHL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CHN",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ce4b3eaa-3b83-4a3d-8de0-7bd3480734c9",
       "rows": [
        [
         "ARG",
         "0.0",
         "0.0030603683956508918",
         "3.5021072644034426e-05",
         "0.001650838519194507",
         "2.621548276561896e-08",
         "0.0008908448719414048",
         "0.024248227939340804",
         "0.010567705527414536"
        ],
        [
         "AUS",
         "0.0030603683956508918",
         "0.0",
         "0.000654001912316886",
         "0.006998664310478342",
         "0.00020289070254183908",
         "3.8623733718952185e-05",
         "0.003662210713134768",
         "0.29366454970103123"
        ],
        [
         "AUT",
         "3.5021072644034426e-05",
         "0.000654001912316886",
         "0.0",
         "0.0015434583201588083",
         "0.0003784408670110776",
         "3.9003101197646175e-05",
         "8.257308268257416e-07",
         "1.7291087403012332e-05"
        ],
        [
         "BEL",
         "0.001650838519194507",
         "0.006998664310478342",
         "0.0015434583201588083",
         "0.0",
         "0.0003419338575997876",
         "0.01098644283772964",
         "0.00013610182505885863",
         "0.00198789143877843"
        ],
        [
         "BGR",
         "2.621548276561896e-08",
         "0.00020289070254183908",
         "0.0003784408670110776",
         "0.0003419338575997876",
         "0.0",
         "9.953953238736294e-05",
         "2.1695880024509694e-07",
         "4.7804422917486105e-05"
        ],
        [
         "CAN",
         "0.0008908448719414048",
         "3.8623733718952185e-05",
         "3.9003101197646175e-05",
         "0.01098644283772964",
         "9.953953238736294e-05",
         "0.0",
         "0.004288442389450876",
         "0.033343175740180614"
        ],
        [
         "CHL",
         "0.024248227939340804",
         "0.003662210713134768",
         "8.257308268257416e-07",
         "0.00013610182505885863",
         "2.1695880024509694e-07",
         "0.004288442389450876",
         "0.0",
         "0.0007964505123811244"
        ],
        [
         "CHN",
         "0.010567705527414536",
         "0.29366454970103123",
         "1.7291087403012332e-05",
         "0.00198789143877843",
         "4.7804422917486105e-05",
         "0.033343175740180614",
         "0.0007964505123811244",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>iso_j</th>\n",
       "      <th>ARG</th>\n",
       "      <th>AUS</th>\n",
       "      <th>AUT</th>\n",
       "      <th>BEL</th>\n",
       "      <th>BGR</th>\n",
       "      <th>CAN</th>\n",
       "      <th>CHL</th>\n",
       "      <th>CHN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iso_i</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ARG</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>3.502107e-05</td>\n",
       "      <td>0.001651</td>\n",
       "      <td>2.621548e-08</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>2.424823e-02</td>\n",
       "      <td>0.010568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>3.060368e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.540019e-04</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>2.028907e-04</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>3.662211e-03</td>\n",
       "      <td>0.293665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUT</th>\n",
       "      <td>3.502107e-05</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>3.784409e-04</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>8.257308e-07</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEL</th>\n",
       "      <td>1.650839e-03</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>1.543458e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.419339e-04</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>1.361018e-04</td>\n",
       "      <td>0.001988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BGR</th>\n",
       "      <td>2.621548e-08</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>3.784409e-04</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.169588e-07</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAN</th>\n",
       "      <td>8.908449e-04</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>3.900310e-05</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>9.953953e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.288442e-03</td>\n",
       "      <td>0.033343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHL</th>\n",
       "      <td>2.424823e-02</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>8.257308e-07</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>2.169588e-07</td>\n",
       "      <td>0.004288</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHN</th>\n",
       "      <td>1.056771e-02</td>\n",
       "      <td>0.293665</td>\n",
       "      <td>1.729109e-05</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>4.780442e-05</td>\n",
       "      <td>0.033343</td>\n",
       "      <td>7.964505e-04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "iso_j           ARG       AUS           AUT       BEL           BGR       CAN  \\\n",
       "iso_i                                                                           \n",
       "ARG    0.000000e+00  0.003060  3.502107e-05  0.001651  2.621548e-08  0.000891   \n",
       "AUS    3.060368e-03  0.000000  6.540019e-04  0.006999  2.028907e-04  0.000039   \n",
       "AUT    3.502107e-05  0.000654  0.000000e+00  0.001543  3.784409e-04  0.000039   \n",
       "BEL    1.650839e-03  0.006999  1.543458e-03  0.000000  3.419339e-04  0.010986   \n",
       "BGR    2.621548e-08  0.000203  3.784409e-04  0.000342  0.000000e+00  0.000100   \n",
       "CAN    8.908449e-04  0.000039  3.900310e-05  0.010986  9.953953e-05  0.000000   \n",
       "CHL    2.424823e-02  0.003662  8.257308e-07  0.000136  2.169588e-07  0.004288   \n",
       "CHN    1.056771e-02  0.293665  1.729109e-05  0.001988  4.780442e-05  0.033343   \n",
       "\n",
       "iso_j           CHL       CHN  \n",
       "iso_i                          \n",
       "ARG    2.424823e-02  0.010568  \n",
       "AUS    3.662211e-03  0.293665  \n",
       "AUT    8.257308e-07  0.000017  \n",
       "BEL    1.361018e-04  0.001988  \n",
       "BGR    2.169588e-07  0.000048  \n",
       "CAN    4.288442e-03  0.033343  \n",
       "CHL    0.000000e+00  0.000796  \n",
       "CHN    7.964505e-04  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "RAW_DIR = \"../../data_origin/UN-Comtrade_Trade_Fossil/\"\n",
    "# æœ€ç»ˆè¾“å‡ºçš„çŸ©é˜µæ–‡ä»¶\n",
    "OUT_FILE = \"../../data/1-7-Fossil_Trade_Matrix_Normalized.csv\"\n",
    "\n",
    "# è‡ªåŠ¨åˆ›å»ºè¾“å‡ºç›®å½•\n",
    "os.makedirs(os.path.dirname(OUT_FILE), exist_ok=True)\n",
    "\n",
    "\n",
    "def get_sorted_pair(row: pd.Series) -> str:\n",
    "    \"\"\"ç”Ÿæˆæ— å‘é…å¯¹é”® (e.g., 'AUS_CHN')ï¼Œç”¨äºåˆå¹¶åŒå‘è´¸æ˜“é¢\"\"\"\n",
    "    p = sorted([str(row['iso_i']), str(row['iso_j'])])\n",
    "    return f\"{p[0]}_{p[1]}\"\n",
    "\n",
    "def process_fossil_matrix() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    å¤„ç†æµç¨‹:\n",
    "    1. è¯»å–å¹¶åˆå¹¶åŸå§‹æ•°æ®\n",
    "    2. è®¡ç®—æ— å‘è´¸æ˜“æ€»é¢ (A-B + B-A)\n",
    "    3. æŒ‰å¹´ä»½è¿›è¡Œ 0-1 å½’ä¸€åŒ– (1=æœ€å¼ºä¾èµ–)\n",
    "    4. è®¡ç®—å†å¹´å¹³å‡å€¼å¹¶è½¬æ¢ä¸ºçŸ©é˜µ\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. æ‰¹é‡è¯»å–\n",
    "    all_files = glob.glob(os.path.join(RAW_DIR, \"Comtrade_*.csv\"))\n",
    "    if not all_files:\n",
    "        print(f\"âŒ é”™è¯¯ï¼šåœ¨ {RAW_DIR} æœªæ‰¾åˆ°æ–‡ä»¶\")\n",
    "        return None\n",
    "\n",
    "    print(f\"è¯»å– {len(all_files)} ä¸ªå¹´ä»½æ–‡ä»¶...\")\n",
    "    \n",
    "    df_list = []\n",
    "    for f in all_files:\n",
    "        df = pd.read_csv(f)\n",
    "        # å…¼å®¹åˆ—å (primaryValue æˆ– primary_value)\n",
    "        val_col = 'primaryValue' if 'primaryValue' in df.columns else 'primary_value'\n",
    "        \n",
    "        subset = df[['period', 'iso_i', 'iso_j', val_col]].copy()\n",
    "        subset.columns = ['year', 'iso_i', 'iso_j', 'value']\n",
    "        \n",
    "        # å‰”é™¤è‡ªæˆ‘è´¸æ˜“å’Œç©ºå€¼\n",
    "        subset = subset[subset['iso_i'] != subset['iso_j']]\n",
    "        subset.dropna(subset=['value'], inplace=True)\n",
    "        \n",
    "        if not subset.empty:\n",
    "            df_list.append(subset)\n",
    "\n",
    "    # 2. åŸºç¡€æ•°æ®èšåˆ\n",
    "    # å…ˆåˆå¹¶æ‰€æœ‰å¹´ä»½æ•°æ®\n",
    "    df_all = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # å¯¹æ¯å¯¹å›½å®¶åœ¨æ¯ä¸€å¹´çš„ ç…¤+æ²¹+æ°” è¿›è¡Œæ±‚å’Œ\n",
    "    df_agg = df_all.groupby(['year', 'iso_i', 'iso_j'])['value'].sum().reset_index()\n",
    "\n",
    "    # 3. æ„å»ºæ— å‘ç½‘ç»œ (Symmetrization)\n",
    "    # é€»è¾‘: Sum(A->B) + Sum(B->A)\n",
    "    df_agg['pair_key'] = df_agg.apply(get_sorted_pair, axis=1)\n",
    "    df_undirected = df_agg.groupby(['year', 'pair_key'])['value'].sum().reset_index()\n",
    "\n",
    "    # æ‹†åˆ†å›ä¸¤åˆ—ï¼Œæ„å»ºåŒå‘è®°å½• (ç¡®ä¿çŸ©é˜µå¯¹ç§°)\n",
    "    df_undirected[['iso_A', 'iso_B']] = df_undirected['pair_key'].str.split('_', expand=True)\n",
    "    \n",
    "    # å¯¹ç§°åŒ–ï¼šå°† A-B çš„å€¼èµ‹äºˆ A-B å’Œ B-A\n",
    "    df_sym = pd.concat([\n",
    "        df_undirected.rename(columns={'iso_A': 'iso_i', 'iso_B': 'iso_j'}),\n",
    "        df_undirected.rename(columns={'iso_B': 'iso_i', 'iso_A': 'iso_j'})\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    # 4. [æ ¸å¿ƒæ­¥éª¤] åˆ†å¹´ä»½å½’ä¸€åŒ– (Yearly Normalization)\n",
    "    # è®¡ç®—å½“å¹´çš„æœ€å¤§å€¼å’Œæœ€å°å€¼\n",
    "    grouped = df_sym.groupby('year')['value']\n",
    "    min_vals = grouped.transform('min')\n",
    "    max_vals = grouped.transform('max')\n",
    "    denominator = max_vals - min_vals\n",
    "\n",
    "    # æ‰§è¡Œå½’ä¸€åŒ–: (x - min) / (max - min)\n",
    "    # ç»“æœ: 1 = å½“å¹´æœ€å¤§è´¸æ˜“é¢(æœ€ä¾èµ–), 0 = å½“å¹´æœ€å°\n",
    "    df_sym['norm_score'] = np.where(\n",
    "        denominator == 0,\n",
    "        0.0, \n",
    "        (df_sym['value'] - min_vals) / denominator\n",
    "    )\n",
    "\n",
    "    # 5. è®¡ç®—å†å¹´å¹³å‡ (Average over 2005-2023)\n",
    "    df_avg = df_sym.groupby(['iso_i', 'iso_j'])['norm_score'].mean().reset_index()\n",
    "\n",
    "    # 6. è½¬æ¢ä¸ºçŸ©é˜µ\n",
    "    # è·å–æ‰€æœ‰æ¶‰åŠçš„å›½å®¶åˆ—è¡¨ä»¥ç¡®ä¿çŸ©é˜µå®Œæ•´\n",
    "    all_countries = sorted(list(set(df_avg['iso_i']) | set(df_avg['iso_j'])))\n",
    "    \n",
    "    matrix = df_avg.pivot(index='iso_i', columns='iso_j', values='norm_score')\n",
    "    \n",
    "    # é‡ç´¢å¼•ç¡®ä¿ 49x49 (æˆ–å®é™…å›½å®¶æ•°) å®Œæ•´æ€§ï¼Œå¹¶è¡¥0\n",
    "    matrix = matrix.reindex(index=all_countries, columns=all_countries).fillna(0)\n",
    "    \n",
    "    # å¼ºåˆ¶å¯¹è§’çº¿ä¸º0\n",
    "    np.fill_diagonal(matrix.values, 0)\n",
    "\n",
    "    # ä¿å­˜\n",
    "    matrix.to_csv(OUT_FILE)\n",
    "    print(f\"çŸ©é˜µå·²ä¿å­˜è‡³: {OUT_FILE}\")\n",
    "    print(f\"   çŸ©é˜µç»´åº¦: {matrix.shape}\")\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "# ================= â–¶ï¸ æ‰§è¡Œ =================\n",
    "matrix_result = process_fossil_matrix()\n",
    "\n",
    "if matrix_result is not None:\n",
    "    print(\"\\næœ€ç»ˆå½’ä¸€åŒ–çŸ©é˜µé¢„è§ˆ (å‰ 8 è¡Œ/åˆ—):\")\n",
    "    display(matrix_result.iloc[:8, :8])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate_policy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
