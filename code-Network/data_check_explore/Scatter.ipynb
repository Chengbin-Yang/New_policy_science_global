{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "589dc4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "正在处理 X 轴变量: Breadth\n",
      "============================================================\n",
      "1. 正在绘制热力散点图 (Density Scatter)...\n",
      "2. 正在绘制均值趋势图 (Trend Line)...\n",
      "   - [1/15] norm_ideal_sim_2005_2023\n",
      "   - [2/15] BACI_Trade_Intensity_Avg\n",
      "   - [3/15] norm_geographical_proximity_avg\n",
      "   - [4/15] Common_Official_Language\n",
      "   - [5/15] Common_Ethno_Language\n",
      "   - [6/15] AeroSCOPE_Flight_Intensity\n",
      "   - [7/15] GDP_Diff\n",
      "   - [8/15] GHG_Diff\n",
      "   - [9/15] Rent_Diff\n",
      "   - [10/15] Fuel_Ex_Diff\n",
      "   - [11/15] Total\n",
      "   - [12/15] Climate_Change_Policy_and_Economics\n",
      "   - [13/15] Climate_Communication_and_Perception\n",
      "   - [14/15] Sustainable_Development_and_Env_Policy\n",
      "   - [15/15] Climate_Adaptation_and_Migration\n",
      "--> Saved Scatter Plot: ../../data/Scatter\\Density_Scatter_Breadth.png\n",
      "--> Saved Trend Plot: ../../data/Scatter\\Trend_Lines_Breadth.png\n",
      "3. 正在绘制详细相关性热力图...\n",
      "--> Saved Heatmap: ../../data/Scatter\\Correlation_Matrix_Detailed_Breadth.png\n",
      "\n",
      "============================================================\n",
      "正在处理 X 轴变量: Intensity\n",
      "============================================================\n",
      "1. 正在绘制热力散点图 (Density Scatter)...\n",
      "2. 正在绘制均值趋势图 (Trend Line)...\n",
      "   - [1/15] norm_ideal_sim_2005_2023\n",
      "   - [2/15] BACI_Trade_Intensity_Avg\n",
      "   - [3/15] norm_geographical_proximity_avg\n",
      "   - [4/15] Common_Official_Language\n",
      "   - [5/15] Common_Ethno_Language\n",
      "   - [6/15] AeroSCOPE_Flight_Intensity\n",
      "   - [7/15] GDP_Diff\n",
      "   - [8/15] GHG_Diff\n",
      "   - [9/15] Rent_Diff\n",
      "   - [10/15] Fuel_Ex_Diff\n",
      "   - [11/15] Total\n",
      "   - [12/15] Climate_Change_Policy_and_Economics\n",
      "   - [13/15] Climate_Communication_and_Perception\n",
      "   - [14/15] Sustainable_Development_and_Env_Policy\n",
      "   - [15/15] Climate_Adaptation_and_Migration\n",
      "--> Saved Scatter Plot: ../../data/Scatter\\Density_Scatter_Intensity.png\n",
      "--> Saved Trend Plot: ../../data/Scatter\\Trend_Lines_Intensity.png\n",
      "3. 正在绘制详细相关性热力图...\n",
      "--> Saved Heatmap: ../../data/Scatter\\Correlation_Matrix_Detailed_Intensity.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# ==========================================\n",
    "# 1. 路径与基础设置\n",
    "# ==========================================\n",
    "input_folder_path = '../../data/PDF_data_Visual/Long_dataframe'\n",
    "output_folder_path = '../../data/Scatter'\n",
    "\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "\n",
    "# 定义 X 轴参考文件\n",
    "ref_files_map = {\n",
    "    'Breadth': '4-1-overlapping_cluster_heatmap_Breadth_long.csv',\n",
    "    'Intensity': '4-1-overlapping_cluster_heatmap_Intensity_long.csv'\n",
    "}\n",
    "\n",
    "# 自动获取 Y 轴目标文件\n",
    "all_files = [f for f in os.listdir(input_folder_path) if f.endswith('.csv')]\n",
    "target_files = [f for f in all_files if f not in ref_files_map.values()]\n",
    "target_files.sort()\n",
    "\n",
    "# ==========================================\n",
    "# 2. 辅助函数：清洗文件名\n",
    "# ==========================================\n",
    "def clean_name(filename):\n",
    "    \"\"\"\n",
    "    1. 去掉文件后缀\n",
    "    2. 截取第一个下划线前最后一个横杠后的部分 (去掉数字前缀)\n",
    "    3. 额外删掉 'Paper_collab-'\n",
    "    \"\"\"\n",
    "    name_no_ext = filename.replace('_long.csv', '').replace('.csv', '')\n",
    "    \n",
    "    # 逻辑：找到第一个下划线，取其前面最后一个横杠之后的内容\n",
    "    first_underscore_index = name_no_ext.find('_')\n",
    "    if first_underscore_index != -1:\n",
    "        prefix_part = name_no_ext[:first_underscore_index]\n",
    "        last_hyphen_index = prefix_part.rfind('-')\n",
    "        if last_hyphen_index != -1:\n",
    "            name_no_ext = name_no_ext[last_hyphen_index + 1:]\n",
    "            \n",
    "    # 新增需求：去掉 Paper_collab-\n",
    "    name_no_ext = name_no_ext.replace('Paper_collab-', '')\n",
    "    \n",
    "    return name_no_ext\n",
    "\n",
    "# ==========================================\n",
    "# 3. 核心绘图逻辑\n",
    "# ==========================================\n",
    "def run_full_analysis(x_name, x_filename):\n",
    "    print(f\"\\n{'='*60}\\n正在处理 X 轴变量: {x_name}\\n{'='*60}\")\n",
    "    \n",
    "    # 读取 X 轴数据\n",
    "    x_path = os.path.join(input_folder_path, x_filename)\n",
    "    df_x = pd.read_csv(x_path)\n",
    "    df_x.columns = [c.strip() for c in df_x.columns]\n",
    "    \n",
    "    correlation_results = []\n",
    "    \n",
    "    # 计算布局\n",
    "    num_plots = len(target_files)\n",
    "    cols = 5\n",
    "    rows = math.ceil(num_plots / cols)\n",
    "    \n",
    "    # === 样式参数设置 (超级大尺寸) ===\n",
    "    FIG_WIDTH = 40           # 画布总宽\n",
    "    ROW_HEIGHT = 8           # 每行高度\n",
    "    \n",
    "    FONT_TITLE = 24          # 子图标题字号\n",
    "    FONT_LABEL = 20          # 坐标轴标签字号\n",
    "    FONT_TICK = 16           # 刻度字号\n",
    "    FONT_TEXT = 18           # 图内标注字号\n",
    "    \n",
    "    SCATTER_SIZE = 25        # 散点大小\n",
    "    LINE_WIDTH = 4           # 折线粗细\n",
    "    MARKER_SIZE = 12         # 折线点大小\n",
    "    \n",
    "    PAD_TITLE = 25           # 标题距离图表的间距\n",
    "    \n",
    "    # 创建两个大画布\n",
    "    print(f\"1. 正在绘制热力散点图 (Density Scatter)...\")\n",
    "    fig_scatter, axes_scatter = plt.subplots(rows, cols, figsize=(FIG_WIDTH, ROW_HEIGHT * rows), constrained_layout=True)\n",
    "    axes_scatter = axes_scatter.flatten()\n",
    "    \n",
    "    print(f\"2. 正在绘制均值趋势图 (Trend Line)...\")\n",
    "    fig_trend, axes_trend = plt.subplots(rows, cols, figsize=(FIG_WIDTH, ROW_HEIGHT * rows), constrained_layout=True)\n",
    "    axes_trend = axes_trend.flatten()\n",
    "    \n",
    "    for i, filename in enumerate(target_files):\n",
    "        clean_title = clean_name(filename)\n",
    "        print(f\"   - [{i+1}/{num_plots}] {clean_title}\")\n",
    "        \n",
    "        y_path = os.path.join(input_folder_path, filename)\n",
    "        \n",
    "        try:\n",
    "            # 读取并合并数据\n",
    "            df_y = pd.read_csv(y_path)\n",
    "            df_y.columns = [c.strip() for c in df_y.columns]\n",
    "            merged = pd.merge(df_x, df_y, on=['Source', 'Target'], suffixes=('_X', '_Y'))\n",
    "            \n",
    "            x_data = merged['Weight_X']\n",
    "            y_data = merged['Weight_Y']\n",
    "            \n",
    "            # 设置坐标轴范围\n",
    "            max_x = int(x_data.max()) if not x_data.empty else 15\n",
    "            \n",
    "            # --- 计算相关性 (用于标注) ---\n",
    "            if len(x_data) > 1:\n",
    "                pearson_val, _ = stats.pearsonr(x_data, y_data)\n",
    "                spearman_val, _ = stats.spearmanr(x_data, y_data)\n",
    "                corr_text = f\"Pearson: {pearson_val:.2f}\\nSpearman: {spearman_val:.2f}\"\n",
    "            else:\n",
    "                corr_text = \"N/A\"\n",
    "            \n",
    "            # =========================================\n",
    "            # A. 绘制热力散点图 (Scatter)\n",
    "            # =========================================\n",
    "            ax_s = axes_scatter[i]\n",
    "            \n",
    "            # 数据清洗\n",
    "            mask = ~np.isnan(x_data) & ~np.isnan(y_data)\n",
    "            x_clean = x_data[mask]\n",
    "            y_clean = y_data[mask]\n",
    "            \n",
    "            if len(x_clean) > 0:\n",
    "                try:\n",
    "                    # 如果数据量特别大，采样计算密度以提高速度\n",
    "                    if len(x_clean) > 5000:\n",
    "                        idx_sample = np.random.choice(len(x_clean), 5000, replace=False)\n",
    "                        xy_sample = np.vstack([x_clean.iloc[idx_sample], y_clean.iloc[idx_sample]])\n",
    "                        z_model = gaussian_kde(xy_sample)\n",
    "                        xy_all = np.vstack([x_clean, y_clean])\n",
    "                        z = z_model(xy_all)\n",
    "                    else:\n",
    "                        xy = np.vstack([x_clean, y_clean])\n",
    "                        z = gaussian_kde(xy)(xy)\n",
    "                    \n",
    "                    # 排序让高密度点在上\n",
    "                    idx = z.argsort()\n",
    "                    x_sorted, y_sorted, z_sorted = x_clean.iloc[idx], y_clean.iloc[idx], z[idx]\n",
    "                    \n",
    "                    ax_s.scatter(x_sorted, y_sorted, c=z_sorted, s=SCATTER_SIZE, cmap='Spectral_r', edgecolor='none', alpha=0.8)\n",
    "                except:\n",
    "                    ax_s.scatter(x_clean, y_clean, s=SCATTER_SIZE, c='#3182bd', alpha=0.5)\n",
    "            \n",
    "            ax_s.set_title(clean_title, fontsize=FONT_TITLE, fontweight='bold', pad=PAD_TITLE)\n",
    "            ax_s.set_xlabel(x_name, fontsize=FONT_LABEL)\n",
    "            ax_s.set_ylabel('Value', fontsize=FONT_LABEL)\n",
    "            ax_s.tick_params(axis='both', which='major', labelsize=FONT_TICK)\n",
    "            ax_s.set_xticks(range(0, max_x + 2, max(1, max_x // 10)))\n",
    "            ax_s.set_ylim(-0.05, 1.05)\n",
    "            \n",
    "            # 标注相关性\n",
    "            ax_s.text(0.03, 0.97, corr_text, transform=ax_s.transAxes, fontsize=FONT_TEXT,\n",
    "                      verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "\n",
    "            # =========================================\n",
    "            # B. 绘制均值趋势图 (Trend)\n",
    "            # =========================================\n",
    "            ax_t = axes_trend[i]\n",
    "            grouped = merged.groupby('Weight_X')['Weight_Y'].agg(['mean', 'sem', 'count'])\n",
    "            grouped = grouped[grouped['count'] > 2] \n",
    "            \n",
    "            ax_t.plot(grouped.index, grouped['mean'], marker='o', \n",
    "                      linewidth=LINE_WIDTH, markersize=MARKER_SIZE, \n",
    "                      color='#d73027', label='Mean')\n",
    "            \n",
    "            ax_t.fill_between(grouped.index, \n",
    "                              grouped['mean'] - 1.96 * grouped['sem'], \n",
    "                              grouped['mean'] + 1.96 * grouped['sem'], \n",
    "                              alpha=0.2, color='#d73027')\n",
    "            \n",
    "            ax_t.set_title(clean_title, fontsize=FONT_TITLE, fontweight='bold', pad=PAD_TITLE)\n",
    "            ax_t.set_xlabel(x_name, fontsize=FONT_LABEL)\n",
    "            ax_t.set_ylabel('Mean Value', fontsize=FONT_LABEL)\n",
    "            ax_t.grid(True, linestyle='--', alpha=0.4)\n",
    "            ax_t.tick_params(axis='both', which='major', labelsize=FONT_TICK)\n",
    "            ax_t.set_xticks(range(0, max_x + 2, max(1, max_x // 10)))\n",
    "            \n",
    "            ax_t.text(0.03, 0.97, corr_text, transform=ax_t.transAxes, fontsize=FONT_TEXT,\n",
    "                      verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "\n",
    "            # =========================================\n",
    "            # C. 收集详细相关性数据\n",
    "            # =========================================\n",
    "            res = {'Variable': clean_title}\n",
    "            res['All (Pearson)'] = pearson_val if len(x_data) > 1 else np.nan\n",
    "            res['All (Spearman)'] = spearman_val if len(x_data) > 1 else np.nan\n",
    "            \n",
    "            # 修改处：限制循环范围到 13 (即 k 取 0 到 12，对应的列为 >0 ... >12)\n",
    "            limit_range = min(13, int(max_x))\n",
    "            for k in range(limit_range):\n",
    "                subset = merged[merged['Weight_X'] > k]\n",
    "                col_name = f'>{k}'\n",
    "                if len(subset) > 20 and subset['Weight_X'].std() != 0 and subset['Weight_Y'].std() != 0:\n",
    "                    corr, _ = stats.pearsonr(subset['Weight_X'], subset['Weight_Y'])\n",
    "                    res[col_name] = corr\n",
    "                else:\n",
    "                    res[col_name] = np.nan\n",
    "            correlation_results.append(res)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error on {filename}: {e}\")\n",
    "\n",
    "    # 清理多余子图\n",
    "    for j in range(i + 1, len(axes_scatter)):\n",
    "        fig_scatter.delaxes(axes_scatter[j])\n",
    "        fig_trend.delaxes(axes_trend[j])\n",
    "    \n",
    "    # 保存 Scatter 大图\n",
    "    fig_scatter.suptitle(f'Density Scatter Plots: {x_name}', fontsize=30, fontweight='bold', y=1.03)\n",
    "    save_path_s = os.path.join(output_folder_path, f'Density_Scatter_{x_name}.png')\n",
    "    plt.figure(fig_scatter.number)\n",
    "    plt.savefig(save_path_s, dpi=300, bbox_inches='tight')\n",
    "    print(f\"--> Saved Scatter Plot: {save_path_s}\")\n",
    "    \n",
    "    # 保存 Trend 大图\n",
    "    fig_trend.suptitle(f'Trend Analysis (Mean & 95% CI): {x_name}', fontsize=30, fontweight='bold', y=1.03)\n",
    "    save_path_t = os.path.join(output_folder_path, f'Trend_Lines_{x_name}.png')\n",
    "    plt.figure(fig_trend.number)\n",
    "    plt.savefig(save_path_t, dpi=300, bbox_inches='tight')\n",
    "    print(f\"--> Saved Trend Plot: {save_path_t}\")\n",
    "\n",
    "    # =========================================\n",
    "    # D. 绘制详细相关性热力图\n",
    "    # =========================================\n",
    "    if correlation_results:\n",
    "        print(f\"3. 正在绘制详细相关性热力图...\")\n",
    "        df_corr = pd.DataFrame(correlation_results)\n",
    "        df_corr.set_index('Variable', inplace=True)\n",
    "        \n",
    "        cols = list(df_corr.columns)\n",
    "        subset_cols = [c for c in cols if c.startswith('>')]\n",
    "        subset_cols.sort(key=lambda x: int(x.replace('>', '')))\n",
    "        final_cols = ['All (Pearson)', 'All (Spearman)'] + subset_cols\n",
    "        final_cols = [c for c in final_cols if c in df_corr.columns]\n",
    "        df_corr = df_corr[final_cols]\n",
    "        \n",
    "        plt.figure(figsize=(24, len(df_corr) * 1.2 + 3))\n",
    "        \n",
    "        ax = sns.heatmap(df_corr, annot=True, fmt=\".2f\", cmap='RdBu_r', center=0, \n",
    "                    linewidths=1, cbar_kws={'label': 'Correlation Coefficient'},\n",
    "                    annot_kws={\"size\": 14})\n",
    "        \n",
    "        ax.set_xticklabels(ax.get_xticklabels(), fontsize=14, rotation=45, ha='right')\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), fontsize=16)\n",
    "        \n",
    "        cbar = ax.collections[0].colorbar\n",
    "        cbar.ax.tick_params(labelsize=14)\n",
    "        cbar.set_label('Correlation Coefficient', fontsize=16)\n",
    "\n",
    "        # 修改处：标题从 >15 改为 >12\n",
    "        plt.title(f'Comprehensive Correlation Analysis ({x_name})\\nSubset Analysis from >0 to >12', fontsize=24, pad=40)\n",
    "        plt.xlabel('Correlation Threshold (Subset: Overlap > k)', fontsize=18)\n",
    "        plt.ylabel('')\n",
    "        \n",
    "        save_path_c = os.path.join(output_folder_path, f'Correlation_Matrix_Detailed_{x_name}.png')\n",
    "        plt.savefig(save_path_c, dpi=300, bbox_inches='tight')\n",
    "        print(f\"--> Saved Heatmap: {save_path_c}\")\n",
    "        plt.close('all')\n",
    "\n",
    "# ==========================================\n",
    "# 4. 执行所有分析\n",
    "# ==========================================\n",
    "for name, fname in ref_files_map.items():\n",
    "    run_full_analysis(name, fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate_policy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
